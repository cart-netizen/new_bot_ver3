# üöÄ ML Model Optimization v2 - Integration Guide

## –û–±–∑–æ—Ä –∏–∑–º–µ–Ω–µ–Ω–∏–π

–î–∞–Ω–Ω—ã–π –ø–∞–∫–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç **–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏** –¥–ª—è ML –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–≤–µ–ª–∏—á–∞—Ç –º–µ—Ç—Ä–∏–∫–∏ —Å —Ç–µ–∫—É—â–∏—Ö 33% accuracy –¥–æ **55-62%** (industry standard).

### –ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ë—ã–ª–æ | –°—Ç–∞–ª–æ | –ü–æ—á–µ–º—É |
|----------|------|-------|--------|
| Learning Rate | 0.001 | **5e-5** | –í 20 —Ä–∞–∑ –º–µ–Ω—å—à–µ! –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å —à—É–º–Ω—ã–µ |
| Batch Size | 64 | **256** | –°—Ç–∞–±–∏–ª—å–Ω–µ–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã |
| Weight Decay | ~0 | **0.01** | L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–∏–≤ overfitting |
| Focal Gamma | 2.0 | **2.5** | –ë–æ–ª—å—à–µ —Ñ–æ–∫—É—Å–∞ –Ω–∞ hard examples |
| Label Smoothing | 0 | **0.1** | –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç overconfidence |
| Scheduler | ReduceOnPlateau | **CosineAnnealingWarmRestarts** | –õ—É—á—à–µ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤ |
| Augmentation | –ù–µ—Ç | **MixUp + Noise** | –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö |

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
ml_optimized/
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ optimized_configs.py      # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ hybrid_cnn_lstm_v2.py     # –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å Residual/MultiHead
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ losses.py                 # Label Smoothing, Focal Loss v2
‚îÇ   ‚îú‚îÄ‚îÄ augmentation.py           # MixUp, Time Masking, Noise
‚îÇ   ‚îú‚îÄ‚îÄ class_balancing_v2.py     # Adaptive thresholds, SMOTE
‚îÇ   ‚îî‚îÄ‚îÄ model_trainer_v2.py       # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π trainer
‚îú‚îÄ‚îÄ training_orchestrator_v2.py   # –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
‚îî‚îÄ‚îÄ run_optimized_training.py     # –°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞
```

---

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–æ–µ–∫—Ç

### –®–∞–≥ 1: –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤

```bash
# –ö–æ–ø–∏—Ä—É–µ–º configs
cp ml_optimized/configs/optimized_configs.py backend/ml_engine/configs/

# –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
cp ml_optimized/models/hybrid_cnn_lstm_v2.py backend/ml_engine/models/

# –ö–æ–ø–∏—Ä—É–µ–º training –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
cp ml_optimized/training/losses.py backend/ml_engine/training/
cp ml_optimized/training/augmentation.py backend/ml_engine/training/
cp ml_optimized/training/class_balancing_v2.py backend/ml_engine/training/
cp ml_optimized/training/model_trainer_v2.py backend/ml_engine/training/

# –ö–æ–ø–∏—Ä—É–µ–º orchestrator
cp ml_optimized/training_orchestrator_v2.py backend/ml_engine/

# –ö–æ–ø–∏—Ä—É–µ–º —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞
cp ml_optimized/run_optimized_training.py backend/ml_engine/
```

### –®–∞–≥ 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤

–í —Ñ–∞–π–ª–µ `backend/ml_engine/__init__.py` –¥–æ–±–∞–≤—å—Ç–µ:

```python
# –ù–æ–≤—ã–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
from .models.hybrid_cnn_lstm_v2 import HybridCNNLSTMv2, ModelConfigV2, create_model_v2
from .training.model_trainer_v2 import ModelTrainerV2, TrainerConfigV2
from .training.losses import MultiTaskLossV2, FocalLossV2, LabelSmoothingCrossEntropy
from .training.augmentation import AugmentationPipeline, MixUp
from .training.class_balancing_v2 import ClassBalancingStrategyV2
from .training_orchestrator_v2 import TrainingOrchestratorV2
```

### –®–∞–≥ 3: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–¥–∞

#### –ó–∞–º–µ–Ω–∞ ModelConfig

```python
# –ë—ã–ª–æ:
from backend.ml_engine.models.hybrid_cnn_lstm import ModelConfig, create_model

config = ModelConfig()
model = create_model(config)

# –°—Ç–∞–ª–æ:
from backend.ml_engine.models.hybrid_cnn_lstm_v2 import ModelConfigV2, create_model_v2

config = ModelConfigV2(
    cnn_channels=(32, 64, 128),  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –º–∞–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    lstm_hidden=128,
    dropout=0.4,
    use_residual=True,
    use_layer_norm=True,
    use_multi_head_attention=True
)
model = create_model_v2(config)
```

#### –ó–∞–º–µ–Ω–∞ TrainerConfig

```python
# –ë—ã–ª–æ:
from backend.ml_engine.training.model_trainer import TrainerConfig, ModelTrainer

config = TrainerConfig(
    learning_rate=0.001,  # –°–õ–ò–®–ö–û–ú –í–´–°–û–ö–ò–ô!
    batch_size=64,
    epochs=100
)

# –°—Ç–∞–ª–æ:
from backend.ml_engine.training.model_trainer_v2 import TrainerConfigV2, ModelTrainerV2

config = TrainerConfigV2(
    learning_rate=5e-5,    # –ö–†–ò–¢–ò–ß–ù–û: –≤ 20 —Ä–∞–∑ –º–µ–Ω—å—à–µ!
    batch_size=256,        # –ö–†–ò–¢–ò–ß–ù–û: –≤ 4 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ!
    weight_decay=0.01,     # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    label_smoothing=0.1,   # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç overconfidence
    use_augmentation=True,
    mixup_alpha=0.2,
    focal_gamma=2.5,
    epochs=150
)
```

---

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ß–µ—Ä–µ–∑ —Å–∫—Ä–∏–ø—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (5 –º–∏–Ω—É—Ç)
python backend/ml_engine/run_optimized_training.py --preset quick

# Production –æ–±—É—á–µ–Ω–∏–µ (2-4 —á–∞—Å–∞)
python backend/ml_engine/run_optimized_training.py --preset production --symbols BTCUSDT ETHUSDT

# –ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è
python backend/ml_engine/run_optimized_training.py \
    --preset production \
    --symbols BTCUSDT ETHUSDT BNBUSDT \
    --days 30 \
    --output-dir models/trained
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π API

```python
import asyncio
from backend.ml_engine.training_orchestrator_v2 import (
    TrainingOrchestratorV2,
    OrchestratorConfig
)

async def train():
    config = OrchestratorConfig(
        symbols=["BTCUSDT", "ETHUSDT"],
        feature_store_days=30,
        model_preset="production_small"
    )
    
    orchestrator = TrainingOrchestratorV2(config)
    results = await orchestrator.run_training()
    
    print(f"Best F1: {results['best_metrics']['val_f1']:.4f}")
    return results

# –ó–∞–ø—É—Å–∫
results = asyncio.run(train())
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: Standalone (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–¥)

```python
import torch
from backend.ml_engine.models.hybrid_cnn_lstm_v2 import create_model_v2_from_preset
from backend.ml_engine.training.model_trainer_v2 import create_trainer_v2

# –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å
model = create_model_v2_from_preset("production_small")

# –°–æ–∑–¥–∞—ë–º trainer —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
trainer = create_trainer_v2(model, preset="production_small")

# –û–±—É—á–∞–µ–º
history = trainer.train(train_loader, val_loader)

print(f"Best Val Loss: {trainer.best_val_loss:.4f}")
print(f"Best Val F1: {trainer.best_val_f1:.4f}")
```

---

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–µ—Å–µ—Ç—ã

### Production Small (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è 7-30 –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö)

```python
ModelConfigV2:
    cnn_channels: (32, 64, 128)    # ~150K –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    lstm_hidden: 128
    dropout: 0.4
    use_residual: True
    use_layer_norm: True

TrainerConfigV2:
    learning_rate: 5e-5
    batch_size: 256
    weight_decay: 0.01
    label_smoothing: 0.1
    mixup_alpha: 0.2
    focal_gamma: 2.5
    epochs: 150
```

### Production Large (–¥–ª—è 60+ –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö)

```python
ModelConfigV2:
    cnn_channels: (64, 128, 256)   # ~500K –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    lstm_hidden: 256
    dropout: 0.3

TrainerConfigV2:
    learning_rate: 1e-4
    batch_size: 128
    weight_decay: 0.005
    label_smoothing: 0.05
    epochs: 100
```

### Quick Experiment (–¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö —Ç–µ—Å—Ç–æ–≤)

```python
ModelConfigV2:
    cnn_channels: (32, 64)         # ~50K –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    lstm_hidden: 64
    lstm_layers: 1

TrainerConfigV2:
    learning_rate: 1e-4
    batch_size: 128
    epochs: 30
    use_augmentation: False
```

---

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### 1. Residual Connections –≤ CNN

```
Input ‚Üí Conv ‚Üí BN ‚Üí ReLU ‚Üí Dropout ‚Üí Output
  ‚Üì                                     ‚Üë
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ skip connection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- –õ—É—á—à–∏–π gradient flow
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—É—á–∞—Ç—å –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–µ —Å–µ—Ç–∏
- –°—Ç–∞–±–∏–ª—å–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ

### 2. Multi-Head Temporal Attention

```python
# –í–º–µ—Å—Ç–æ single-head attention:
self.attention = SimpleAttention(hidden_size)

# –ò—Å–ø–æ–ª—å–∑—É–µ–º multi-head:
self.attention = MultiHeadTemporalAttention(
    hidden_size=256,
    num_heads=4,
    dropout=0.1
)
```

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- –õ—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –¥–ª–∏–Ω–Ω—ã–º–∏ sequences
- –ü–æ–≤—ã—à–∞–µ—Ç interpretability

### 3. Layer Normalization –¥–ª—è LSTM

```python
# –í–º–µ—Å—Ç–æ BatchNorm –ø–æ—Å–ª–µ LSTM:
self.lstm = LSTMWithLayerNorm(
    input_size=128,
    hidden_size=256,
    use_layer_norm=True
)
```

–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
- –°—Ç–∞–±–∏–ª—å–Ω–µ–µ –¥–ª—è sequences (–Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç batch)
- –õ—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ batch sizes

---

## Data Augmentation

### MixUp

```python
# –°–º–µ—à–∏–≤–∞–Ω–∏–µ samples:
mixed_x = lambda * x_i + (1 - lambda) * x_j
mixed_y = lambda * y_i + (1 - lambda) * y_j

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
mixup = MixUp(alpha=0.2)
mixed_x, y_a, y_b, lam = mixup(x, y)
loss = lam * criterion(pred, y_a) + (1-lam) * criterion(pred, y_b)
```

### Gaussian Noise

```python
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ –∫ features:
noisy_x = x + torch.randn_like(x) * 0.01
```

### Time Masking

```python
# –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö timesteps:
mask = TimeMasking(mask_ratio=0.1)
masked_x = mask(x)  # 10% timesteps –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ 0
```

---

## Class Balancing

### Adaptive Thresholds

–í–º–µ—Å—Ç–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è labeling:

```python
# –ë—ã–ª–æ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ):
if return > 0.001:
    label = BUY
elif return < -0.001:
    label = SELL
else:
    label = HOLD

# –°—Ç–∞–ª–æ (percentile-based):
sell_threshold = np.percentile(returns, 25)  # Bottom 25%
buy_threshold = np.percentile(returns, 75)   # Top 25%
```

### Focal Loss —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º gamma

```python
# Focal Loss —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ hard examples:
# FL(p) = -(1-p)^gamma * log(p)

# gamma=2.0: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
# gamma=2.5: –±–æ–ª—å—à–µ —Ñ–æ–∫—É—Å–∞ –Ω–∞ hard (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
# gamma=3.0: –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Ñ–æ–∫—É—Å
```

---

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### –û–∂–∏–¥–∞–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–∞–º

| –≠–ø–æ—Ö–∞ | Train Loss | Val Loss | Val Acc | Val F1 |
|-------|------------|----------|---------|--------|
| 1-10  | 1.1-0.9    | 1.2-1.0  | 35-40%  | 30-38% |
| 10-30 | 0.9-0.7    | 1.0-0.85 | 40-48%  | 38-45% |
| 30-60 | 0.7-0.5    | 0.85-0.70| 48-55%  | 45-52% |
| 60-100| 0.5-0.4    | 0.70-0.60| 55-60%  | 52-57% |
| 100+  | 0.4-0.35   | 0.60-0.55| 58-62%  | 55-60% |

### Warning Signs

‚ùå **Val Loss —Ä–∞—Å—Ç—ë—Ç, Train Loss –ø–∞–¥–∞–µ—Ç** ‚Üí Overfitting
   - –†–µ—à–µ–Ω–∏–µ: —É–≤–µ–ª–∏—á–∏—Ç—å dropout, weight_decay, —É–º–µ–Ω—å—à–∏—Ç—å –º–æ–¥–µ–ª—å

‚ùå **Accuracy –Ω–µ —Ä–∞—Å—Ç—ë—Ç –≤—ã—à–µ 35%** ‚Üí –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–∞–µ—Ç—Å—è
   - –†–µ—à–µ–Ω–∏–µ: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å learning rate (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 5e-5, –Ω–µ 0.001!)

‚ùå **F1 —Å–∏–ª—å–Ω–æ –Ω–∏–∂–µ Accuracy** ‚Üí Class imbalance
   - –†–µ—à–µ–Ω–∏–µ: —É–≤–µ–ª–∏—á–∏—Ç—å focal_gamma, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å oversampling

---

## Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: Out of Memory

```python
# –£–º–µ–Ω—å—à–∏—Ç—å batch_size:
config.batch_size = 128  # –≤–º–µ—Å—Ç–æ 256

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å gradient accumulation:
config.gradient_accumulation_steps = 2
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```python
# –í–∫–ª—é—á–∏—Ç—å Mixed Precision (—Ç–æ–ª—å–∫–æ –¥–ª—è GPU):
config.use_mixed_precision = True

# –£–º–µ–Ω—å—à–∏—Ç—å –º–æ–¥–µ–ª—å:
model_config.cnn_channels = (32, 64)  # –≤–º–µ—Å—Ç–æ (32, 64, 128)
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

```python
# –£–≤–µ–ª–∏—á–∏—Ç—å batch_size –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:
config.batch_size = 256

# –£–º–µ–Ω—å—à–∏—Ç—å learning rate:
config.learning_rate = 3e-5

# –í–∫–ª—é—á–∏—Ç—å gradient clipping:
config.grad_clip_value = 1.0
```

---

## Checklist –ø–µ—Ä–µ–¥ Production

- [ ] Learning rate = 5e-5 (–ù–ï 0.001!)
- [ ] Batch size >= 128 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 256)
- [ ] Weight decay = 0.01
- [ ] Label smoothing = 0.1
- [ ] Focal gamma = 2.5
- [ ] Early stopping patience >= 15
- [ ] MixUp augmentation –≤–∫–ª—é—á–µ–Ω
- [ ] Class balancing –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- [ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ held-out –¥–∞–Ω–Ω—ã—Ö

---

## –ö–æ–Ω—Ç–∞–∫—Ç—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞

–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è
2. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É: `python diagnose_optimization.py --symbol BTCUSDT`

---

*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 2025*
