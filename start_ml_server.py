#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ ML Model Server –Ω–∞ –ø–æ—Ä—Ç—É 8001.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python start_ml_server.py
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

if __name__ == "__main__":
    import uvicorn

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º app –∏–∑ model_server_v2
    from backend.ml_engine.inference.model_server_v2 import app

    print("=" * 80)
    print("üöÄ –ó–∞–ø—É—Å–∫ ML Model Server")
    print("=" * 80)
    print()
    print("üìç URL: http://localhost:8001")
    print("üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8001/docs")
    print("üîç Health check: http://localhost:8001/health")
    print("ü§ñ Predict endpoint: POST http://localhost:8001/predict")
    print()
    print("–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
    print("=" * 80)
    print()

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info"
    )
