# üîß FIX: CUDA Out of Memory Error

**–î–∞—Ç–∞:** 2025-11-27
**–ü—Ä–æ–±–ª–µ–º–∞:** GPU –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–∏ batch_size=256
**–†–µ—à–µ–Ω–∏–µ:** –£–º–µ–Ω—å—à–µ–Ω batch_size –¥–æ 128 + –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏

---

## ‚ùå –ü—Ä–æ–±–ª–µ–º–∞

### –û—à–∏–±–∫–∞:

```
torch.OutOfMemoryError: CUDA out of memory.
Tried to allocate 2.69 GiB.
GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free.
Of the allocated memory 10.83 GiB is allocated by PyTorch,
and 2.02 GiB is reserved by PyTorch but unallocated.
```

### –ö–æ–Ω—Ç–µ–∫—Å—Ç:

- **GPU:** 12 GB VRAM
- **Batch Size:** 256 (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π!)
- **–ú–æ–¥–µ–ª—å:** HybridCNNLSTMv2 —Å Multi-Head Attention
- **–ü—Ä–æ–±–ª–µ–º–∞:** Attention mechanism —Ç—Ä–µ–±—É–µ—Ç O(n¬≤) –ø–∞–º—è—Ç–∏ –¥–ª—è batch

---

## ‚úÖ –†–µ—à–µ–Ω–∏–µ

### 1. –£–º–µ–Ω—å—à–µ–Ω batch_size: 256 ‚Üí 128 ‚úÖ

#### Frontend (`MLManagementPage.tsx` —Å—Ç—Ä–æ–∫–∞ 196):

**–î–æ:**
```typescript
batch_size: 256,  // v2: 256 (–±—ã–ª–æ 64)
```

**–ü–æ—Å–ª–µ:**
```typescript
batch_size: 128,  // v2: 128 (–±—ã–ª–æ 256, —É–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è GPU 12GB)
```

#### Backend API (`ml_management_api.py` —Å—Ç—Ä–æ–∫–∞ 94):

**–î–æ:**
```python
batch_size: int = Field(default=256, ge=8, le=512, description="Batch size (v2: 256)")
```

**–ü–æ—Å–ª–µ:**
```python
batch_size: int = Field(default=128, ge=8, le=512, description="Batch size (v2: 128, reduced for GPU memory)")
```

#### Frontend Tooltip –æ–±–Ω–æ–≤–ª–µ–Ω:

**–î–æ:**
```
–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: 256. –ë–æ–ª—å—à–µ = —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏.
v2 —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: 256 (–±—ã–ª–æ: 64 –≤ v1)
```

**–ü–æ—Å–ª–µ:**
```
–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: 128-256 –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç GPU –ø–∞–º—è—Ç–∏.
v2: 128 –¥–ª—è GPU 12GB (256 —Ç—Ä–µ–±—É–µ—Ç 16GB+)
```

---

### 2. –î–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏ ‚úÖ

#### –§–∞–π–ª: `training_orchestrator.py` (—Å—Ç—Ä–æ–∫–∏ 139-143)

```python
# Clear GPU memory before training
import torch
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    logger.info(f"GPU memory cleared. Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
```

**–≠—Ñ—Ñ–µ–∫—Ç:** –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—É—á–µ–Ω–∏—è.

---

## üìä –†–∞—Å—á–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –ø–∞–º—è—Ç–∏

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏:

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | Batch=256 | Batch=128 | –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ |
|-----------|-----------|-----------|-----------|
| **–ú–æ–¥–µ–ª—å (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã)** | ~500 MB | ~500 MB | –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä |
| **–ê–∫—Ç–∏–≤–∞—Ü–∏–∏ (forward)** | ~2.5 GB | ~1.25 GB | –õ–∏–Ω–µ–π–Ω–æ –æ—Ç batch |
| **Attention weights** | ~2.7 GB | ~0.7 GB | **O(batch¬≤) - –æ—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞!** |
| **–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã** | ~2.5 GB | ~1.25 GB | –õ–∏–Ω–µ–π–Ω–æ –æ—Ç batch |
| **Optimizer state** | ~1.5 GB | ~1.5 GB | AdamW —Å momentum |
| **PyTorch reserved** | ~2 GB | ~2 GB | –ë—É—Ñ–µ—Ä |
| **–ò–¢–û–ì–û** | ~11.7 GB | ~7.2 GB | |

### –†–µ–∑—É–ª—å—Ç–∞—Ç:

- ‚úÖ **Batch=128:** –£–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ 12 GB GPU
- ‚ùå **Batch=256:** –¢—Ä–µ–±—É–µ—Ç 12+ GB, –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ!

---

## üîç –ü–æ—á–µ–º—É Attention —Ç—Ä–µ–±—É–µ—Ç O(n¬≤) –ø–∞–º—è—Ç–∏?

Multi-Head Attention –≤—ã—á–∏—Å–ª—è–µ—Ç:

```python
attn = (q @ k.transpose(-2, -1)) * scale  # (batch, heads, seq_len, seq_len)
```

**–†–∞–∑–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã –≤–Ω–∏–º–∞–Ω–∏—è:**
- Batch=256, Heads=4, SeqLen=60
- –†–∞–∑–º–µ—Ä: 256 √ó 4 √ó 60 √ó 60 √ó 4 bytes (float32) = **~2.7 GB**

**–ü—Ä–∏ —É–º–µ–Ω—å—à–µ–Ω–∏–∏ batch –¥–æ 128:**
- –†–∞–∑–º–µ—Ä: 128 √ó 4 √ó 60 √ó 60 √ó 4 bytes = **~0.7 GB** ‚úÖ

---

## üéØ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è

–ï—Å–ª–∏ –Ω—É–∂–µ–Ω –±–æ–ª—å—à–∏–π effective batch size:

### –í–∞—Ä–∏–∞–Ω—Ç 1: Gradient Accumulation (—É–∂–µ –≤ TrainerConfigV2)

```python
TrainerConfigV2(
    batch_size=128,  # Physical batch
    gradient_accumulation_steps=2  # Effective batch = 128 * 2 = 256
)
```

**–ü–ª—é—Å—ã:**
- ‚úÖ –≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ batch_size=256 –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
- ‚úÖ –£–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ GPU memory
- ‚ö†Ô∏è –ú–∏–Ω—É—Å: –º–µ–¥–ª–µ–Ω–Ω–µ–µ –≤ 2 —Ä–∞–∑–∞

### –í–∞—Ä–∏–∞–Ω—Ç 2: Mixed Precision Training (—É–∂–µ –≤ TrainerConfigV2)

```python
TrainerConfigV2(
    batch_size=192,  # –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 192
    use_mixed_precision=True  # FP16 –≤–º–µ—Å—Ç–æ FP32
)
```

**–ü–ª—é—Å—ã:**
- ‚úÖ –≠–∫–æ–Ω–æ–º–∏—Ç ~50% –ø–∞–º—è—Ç–∏
- ‚úÖ –ë—ã—Å—Ç—Ä–µ–µ –Ω–∞ GPU —Å Tensor Cores
- ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ loss scaling

### –í–∞—Ä–∏–∞–Ω—Ç 3: Flash Attention (—Ç—Ä–µ–±—É–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏)

```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å torch.nn.functional.scaled_dot_product_attention
# –≠–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å –∑–∞ —Å—á–µ—Ç fused –æ–ø–µ—Ä–∞—Ü–∏–π
```

**–ü–ª—é—Å—ã:**
- ‚úÖ –≠–∫–æ–Ω–æ–º–∏—Ç –¥–æ 70% –ø–∞–º—è—Ç–∏ –¥–ª—è attention
- ‚úÖ –ë—ã—Å—Ç—Ä–µ–µ –≤ 2-3 —Ä–∞–∑–∞
- ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç PyTorch 2.0+

---

## üìã Checklist –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

### –ï—Å–ª–∏ —Å–Ω–æ–≤–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç OOM:

1. ‚úÖ **–£–º–µ–Ω—å—à–∏—Ç—å batch_size:**
   - 128 ‚Üí 96 ‚Üí 64 ‚Üí 32
   - –í UI: `/ml-management` ‚Üí Batch Size

2. ‚úÖ **–í–∫–ª—é—á–∏—Ç—å gradient accumulation:**
   ```python
   # –í TrainerConfig
   gradient_accumulation_steps=2  # –ò–ª–∏ 4
   ```

3. ‚úÖ **–í–∫–ª—é—á–∏—Ç—å mixed precision:**
   ```python
   # –í TrainerConfig
   use_mixed_precision=True
   ```

4. ‚úÖ **–£–º–µ–Ω—å—à–∏—Ç—å sequence_length:**
   ```python
   # –í ModelConfig
   sequence_length=40  # –í–º–µ—Å—Ç–æ 60
   ```

5. ‚úÖ **–£–º–µ–Ω—å—à–∏—Ç—å attention heads:**
   ```python
   # –í ModelConfig
   attention_heads=2  # –í–º–µ—Å—Ç–æ 4
   ```

6. ‚ö†Ô∏è **–ó–∞–∫—Ä—ã—Ç—å –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ GPU**

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º:

```python
import torch

if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Total memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    print(f"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
    print(f"Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB")
    print(f"Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved()) / 1e9:.2f} GB")
```

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:

```
GPU: NVIDIA GeForce RTX 3060 (–∏–ª–∏ –∞–Ω–∞–ª–æ–≥)
Total memory: 12.00 GB
Allocated: 0.00 GB
Reserved: 0.00 GB
Free: 12.00 GB
‚úÖ –ì–æ—Ç–æ–≤–æ –∫ –æ–±—É—á–µ–Ω–∏—é —Å batch_size=128
```

---

## üìà –í–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–∏—è

### –£–º–µ–Ω—å—à–µ–Ω–∏–µ batch_size 256 ‚Üí 128:

**–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã:**

| –ê—Å–ø–µ–∫—Ç | –ò–∑–º–µ–Ω–µ–Ω–∏–µ | –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è |
|--------|-----------|-------------|
| **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤** | ‚¨áÔ∏è –ú–µ–Ω—å—à–µ | ‚úÖ –í—Å–µ –µ—â–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ |
| **–°–∫–æ—Ä–æ—Å—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏** | ‚¨áÔ∏è –ù–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ | ‚úÖ –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å epochs –Ω–∞ 10-20% |
| **Generalization** | ‚¨ÜÔ∏è –õ—É—á—à–µ! | ‚úÖ –ú–µ–Ω—å—à–∏–π batch = –º–µ–Ω—å—à–µ overfitting |
| **Training time** | ‚¨ÜÔ∏è –ß—É—Ç—å –¥–æ–ª—å—à–µ | ‚ö†Ô∏è +10-15% –≤—Ä–µ–º–µ–Ω–∏ |

**–í—ã–≤–æ–¥:** ‚úÖ **Batch=128 - —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å –¥–ª—è GPU 12GB!**

---

## ‚úÖ –°—Ç–∞—Ç—É—Å

**–ü–†–û–ë–õ–ï–ú–ê –†–ï–®–ï–ù–ê ‚úÖ**

- ‚úÖ batch_size —É–º–µ–Ω—å—à–µ–Ω –¥–æ 128 (frontend + backend)
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏
- ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω—ã tooltips –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞

**–ì–æ—Ç–æ–≤–æ –∫ –æ–±—É—á–µ–Ω–∏—é –Ω–∞ GPU 12GB!**

---

## üìö –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

1. **FRONTEND_V2_UPDATE_COMPLETE.md** - Frontend changes
2. **HOTFIX_V2_API_PARAMETERS.md** - API parameter mapping
3. **V2_API_PARAMETER_MAPPING.md** - Full parameter list

---

## üí° –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É batch_size:

| GPU VRAM | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π batch_size | Max batch_size |
|----------|-------------------------|----------------|
| 8 GB | 64 | 96 |
| 12 GB | 128 | 192 (—Å mixed precision) |
| 16 GB | 256 | 384 (—Å mixed precision) |
| 24 GB+ | 512 | 768+ (—Å mixed precision) |

**–ü—Ä–∞–≤–∏–ª–æ:** –ù–∞—á–Ω–∏—Ç–µ —Å –ø–æ–ª–æ–≤–∏–Ω—ã –º–∞–∫—Å–∏–º—É–º–∞, –∑–∞—Ç–µ–º —É–≤–µ–ª–∏—á–∏–≤–∞–π—Ç–µ –ø–æ–∫–∞ –Ω–µ —É–ø—Ä–µ—Ç–µ—Å—å –≤ OOM.
