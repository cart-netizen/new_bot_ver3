# üöÄ Performance Optimization Guide –¥–ª—è ML Training

## ‚úÖ –£–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ (–¢–µ–∫—É—â–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å: ~1.33 batch/s ‚Üí –û–∂–∏–¥–∞–µ–º ~3-4 batch/s)

### 1. **Mixed Precision Training (FP16)** ‚ö°
- –í–∫–ª—é—á–µ–Ω–æ `use_mixed_precision=True`
- RTX 3060 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Tensor Cores
- **–£—Å–∫–æ—Ä–µ–Ω–∏–µ: 2-3x**
- –ú–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏ GPU ‚Üí –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å batch size

### 2. **Non-deterministic Mode**
- –û—Ç–∫–ª—é—á–µ–Ω–æ `deterministic=False`
- PyTorch –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ CUDA –∞–ª–≥–æ—Ä–∏—Ç–º—ã
- **–£—Å–∫–æ—Ä–µ–Ω–∏–µ: 5-10%**

### 3. **Data Loading Optimization**
- `num_workers=8` (–±—ã–ª–æ 4)
- `pin_memory=True` (—É–∂–µ –±—ã–ª–æ)
- **–£—Å–∫–æ—Ä–µ–Ω–∏–µ: 10-20%**

---

## üéØ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)

### –í–∞—Ä–∏–∞–Ω—Ç A: –£–≤–µ–ª–∏—á–∏—Ç—å Batch Size (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç—å)

–ü–æ—Å–ª–µ –≤–∫–ª—é—á–µ–Ω–∏—è mixed precision –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç—Å—è ~40% GPU –ø–∞–º—è—Ç–∏.

**–ò–∑–º–µ–Ω–∏—Ç—å –≤ `TrainerConfigV2`:**
```python
batch_size: int = 384  # –ë—ã–ª–æ 256, –ø—Ä–∏—Ä–æ—Å—Ç ~30%
# –∏–ª–∏
batch_size: int = 512  # –ë—ã–ª–æ 256, –ø—Ä–∏—Ä–æ—Å—Ç ~50%
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏:**
```bash
# –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç—å:
nvidia-smi
```

### –í–∞—Ä–∏–∞–Ω—Ç B: Gradient Accumulation (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ —É–≤–µ–ª–∏—á–µ–Ω–∏—é batch)

–ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏ –¥–ª—è –±–æ–ª—å—à–æ–≥–æ batch:

```python
gradient_accumulation_steps: int = 2  # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch = 256*2 = 512
```

### –í–∞—Ä–∏–∞–Ω—Ç C: –£–º–µ–Ω—å—à–∏—Ç—å Data Augmentation

**–î–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (–∂–µ—Ä—Ç–≤—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ–º —Ä–∞–¥–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏):**
```python
mixup_prob: float = 0.2  # –ë—ã–ª–æ 0.5, MixUp –Ω–∞ 20% –±–∞—Ç—á–µ–π
# –∏–ª–∏ —Å–æ–≤—Å–µ–º –æ—Ç–∫–ª—é—á–∏—Ç—å:
use_augmentation: bool = False
```

**–ü—Ä–∏—Ä–æ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏: 10-15%**

### –í–∞—Ä–∏–∞–Ω—Ç D: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

**1. –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏–µ–º–ª–µ–º–∞):**
```python
# –í ModelConfig:
cnn_channels: Tuple[int, ...] = (32, 64, 128)  # –ë—ã–ª–æ (64, 128, 256)
lstm_hidden: int = 128  # –ë—ã–ª–æ 256
```

**2. –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å —á–∞—Å—Ç—å —Å–ª–æ–µ–≤ (transfer learning):**
```python
# –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å CNN —Å–ª–æ–∏:
for param in model.cnn_blocks.parameters():
    param.requires_grad = False
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### GPU Utilization
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:
nvidia-smi -l 1  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
```

**–¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:**
- GPU Utilization: 95-100% ‚úÖ
- GPU Memory: 80-90% (–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞–ø–∞—Å –¥–ª—è –ø–∏–∫–æ–≤)
- Temperature: <80¬∞C

### PyTorch Profiler (–¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)

–î–æ–±–∞–≤–∏—Ç—å –≤ trainer:
```python
from torch.profiler import profile, ProfilerActivity

with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:
    train_one_epoch()

print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
```

---

## üéÆ –¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª—è RTX 3060)

```python
TrainerConfigV2(
    # Training
    epochs=150,
    learning_rate=5e-5,
    batch_size=256,  # –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 384-512
    weight_decay=0.01,

    # Speed optimizations
    use_mixed_precision=True,  # ‚úÖ FP16
    deterministic=False,        # ‚úÖ –ë—ã—Å—Ç—Ä—ã–µ CUDA –æ–ø–µ—Ä–∞—Ü–∏–∏

    # Data Augmentation
    use_augmentation=True,
    mixup_prob=0.5,  # –ú–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –¥–æ 0.2

    # DataLoader (—á–µ—Ä–µ–∑ OptimizedDataConfig)
    num_workers=8,    # ‚úÖ –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 4
    pin_memory=True,  # ‚úÖ –ë—ã—Å—Ç—Ä–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ CPU‚ÜíGPU
)
```

---

## üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —É–∑–∫–∏—Ö –º–µ—Å—Ç

### –ï—Å–ª–∏ GPU Utilization < 90%:
1. **–ü—Ä–æ–±–ª–µ–º–∞:** CPU –Ω–µ —É—Å–ø–µ–≤–∞–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
   - **–†–µ—à–µ–Ω–∏–µ:** –£–≤–µ–ª–∏—á–∏—Ç—å `num_workers` –¥–æ 12-16
   - **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–µ —Ç–æ—Ä–º–æ–∑–∏—Ç –ª–∏ Feature Store

2. **–ü—Ä–æ–±–ª–µ–º–∞:** –ú–Ω–æ–≥–æ –º–µ–ª–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –Ω–∞ CPU
   - **–†–µ—à–µ–Ω–∏–µ:** –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å augmentation –Ω–∞ GPU
   - **–†–µ—à–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `torch.compile()` (PyTorch 2.0+)

### –ï—Å–ª–∏ Out of Memory (OOM):
1. –£–º–µ–Ω—å—à–∏—Ç—å `batch_size`
2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `gradient_accumulation_steps`
3. –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏

### –ï—Å–ª–∏ Loss —Ä–∞—Å—Ç–µ—Ç/–Ω–µ—Å—Ç–∞–±–∏–ª–µ–Ω —Å mixed precision:
```python
# –£–≤–µ–ª–∏—á–∏—Ç—å gradient scaling:
from torch.cuda.amp import GradScaler
scaler = GradScaler(growth_interval=100)  # –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π scaling
```

---

## üìà –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è | Baseline | –£—Å–∫–æ—Ä–µ–Ω–∏–µ | –ò—Ç–æ–≥–æ–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å |
|-------------|----------|-----------|-------------------|
| Baseline (v1) | 4.0 batch/s | - | 4.0 batch/s |
| V2 –º–æ–¥–µ–ª—å (—Å–ª–æ–∂–Ω–µ–µ) | 1.33 batch/s | - | 1.33 batch/s |
| + Mixed Precision | 1.33 batch/s | 2-3x | 2.7-4.0 batch/s |
| + Deterministic=False | 2.7 batch/s | 1.1x | ~3.0 batch/s |
| + num_workers=8 | 3.0 batch/s | 1.1x | ~3.3 batch/s |
| + batch_size=384 | 3.3 batch/s | 1.3x | ~4.3 batch/s |

**–ò—Ç–æ–≥–æ–≤–∞—è —Ü–µ–ª—å: 3-4 batch/s** (–±–ª–∏–∑–∫–æ –∫ v1, –Ω–æ —Å –±–æ–ª–µ–µ –º–æ—â–Ω–æ–π –º–æ–¥–µ–ª—å—é)

---

## üõ†Ô∏è –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞ 5 —ç–ø–æ—Ö–∞—Ö:
```python
config = TrainerConfigV2(
    epochs=5,
    early_stopping_patience=999,  # –û—Ç–∫–ª—é—á–∏—Ç—å early stopping
    save_every_n_epochs=999,      # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ checkpoint
)
```

---

## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

- **Mixed precision** —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ –≤—Å–µ–≥–æ –Ω–∞ RTX 20xx/30xx/40xx
- **Deterministic mode** –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è debug/reproducibility
- **Batch size** –æ–≥—Ä–∞–Ω–∏—á–µ–Ω GPU –ø–∞–º—è—Ç—å—é (RTX 3060 = 12GB)
- **num_workers** –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU —è–¥–µ—Ä (–Ω–æ –Ω–µ –±–æ–ª—å—à–µ 16)

---

–°–æ–∑–¥–∞–Ω–æ: 2025-11-27
–í–∏–¥–µ–æ–∫–∞—Ä—Ç–∞: RTX 3060 12GB
Baseline: 1.33 batch/s ‚Üí Target: 3-4 batch/s
