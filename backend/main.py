"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –∏ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞.
"""

import asyncio
import signal
import time
import traceback
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Any, List
from contextlib import asynccontextmanager
import gc  # –ù–û–í–û–ï: –î–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π —Å–±–æ—Ä–∫–∏ –º—É—Å–æ—Ä–∞
import os
import psutil
import uvicorn
import subprocess
from fastapi import WebSocket, WebSocketDisconnect

# from analysis_loop_ml_data_collection import ml_data_collection_loop
from backend.config import settings
from backend.core.dynamic_symbols import DynamicSymbolsManager
from backend.core.logger import get_logger, setup_logging
from backend.core.exceptions import log_exception, OrderBookSyncError, OrderBookError
from backend.core.trace_context import trace_operation
from backend.database.connection import db_manager
from backend.domain.services.fsm_registry import fsm_registry
from backend.exchange.rest_client import rest_client
from backend.exchange.websocket_manager import BybitWebSocketManager
from backend.infrastructure.repositories.position_repository import position_repository
from backend.infrastructure.resilience.recovery_service import recovery_service
from backend.ml_engine.detection.layering_detector import LayeringConfig, LayeringDetector
from backend.ml_engine.detection.spoofing_detector import SpoofingConfig, SpoofingDetector
from backend.ml_engine.detection.sr_level_detector import SRLevelConfig, SRLevelDetector, SRLevel
from backend.ml_engine.integration.ml_signal_validator import ValidationConfig, MLSignalValidator
from backend.ml_engine.monitoring.drift_detector import DriftDetector
from backend.models.orderbook import OrderBookSnapshot
from backend.models.market_data import MarketTrade
# from models.signal import TradingSignal, SignalType, SignalStrength, SignalSource
from backend.screener.screener_manager import ScreenerManager
from backend.strategies.adaptive import OptimizationMethod, \
  RegimeDetectorConfig, PerformanceTrackerConfig
from backend.strategies.strategy_manager import ExtendedStrategyManagerConfig, ExtendedStrategyManager
from backend.strategy.candle_manager import CandleManager
from backend.strategy.correlation_manager import correlation_manager
from backend.strategy.daily_loss_killer import daily_loss_killer
from backend.strategy.orderbook_manager import OrderBookManager
from backend.strategy.trade_manager import TradeManager
from backend.strategy.analyzer import MarketAnalyzer, OrderBookAnalyzer
from backend.strategy.position_monitor import PositionMonitor
from backend.strategy.reversal_detector import reversal_detector
from backend.strategy.risk_manager_ml_enhanced import RiskManagerMLEnhanced
from backend.strategy.risk_models import ReversalSignal
from backend.strategy.strategy_engine import StrategyEngine
from backend.strategy.risk_manager import RiskManager
from backend.execution.execution_manager import ExecutionManager
from backend.strategy.trailing_stop_manager import trailing_stop_manager
from backend.utils.balance_tracker import balance_tracker
from backend.utils.constants import BotStatus
from backend.api.websocket import manager as ws_manager, handle_websocket_messages
from backend.tasks.cleanup_tasks import cleanup_tasks
from backend.utils.helpers import safe_enum_value, get_timestamp_ms  # Added get_timestamp_ms
# ML FEATURE PIPELINE - –ù–û–í–û–ï
from backend.ml_engine.features import (
  MultiSymbolFeaturePipeline,
  FeatureVector, Candle
)
from backend.ml_engine.data_collection import MLDataCollector  # –ù–û–í–û–ï

# –§–∞–∑–∞ 2: Adaptive Consensus
from backend.strategies.adaptive import (
    AdaptiveConsensusManager,
    AdaptiveConsensusConfig,

    WeightOptimizerConfig
)

# –§–∞–∑–∞ 3: Multi-Timeframe
from backend.strategies.mtf import (
  MultiTimeframeManager,
  MTFManagerConfig,
  MultiTimeframeConfig,
  AlignmentConfig,
  SynthesizerConfig,
  SynthesisMode,
  Timeframe, DivergenceType
)

# –§–∞–∑–∞ 4: Integrated Engine
from backend.engine.integrated_analysis_engine import (
    IntegratedAnalysisEngine,
    IntegratedAnalysisConfig,
    AnalysisMode
)

from backend.models.signal import TradingSignal, SignalType, SignalStrength, SignalSource

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π __post_init__
_original_tradingsignal_post_init = TradingSignal.__post_init__


def _patched_tradingsignal_post_init(self):
  """
  –ü–∞—Ç—á –¥–ª—è TradingSignal –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ Enum.

  –≠—Ç–æ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∫–æ–≥–¥–∞ signal_type/strength/source –ø—Ä–∏—Ö–æ–¥—è—Ç –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏,
  –Ω–æ –∫–æ–¥ –æ–∂–∏–¥–∞–µ—Ç Enum –∏ –ø—ã—Ç–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .value
  """
  # –í—ã–∑—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π __post_init__
  _original_tradingsignal_post_init(self)

  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ Enum –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
  if isinstance(self.signal_type, str):
    try:
      self.signal_type = SignalType(self.signal_type)
    except (ValueError, KeyError):
      # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
      pass

  if isinstance(self.strength, str):
    try:
      self.strength = SignalStrength(self.strength)
    except (ValueError, KeyError):
      pass

  if isinstance(self.source, str):
    try:
      self.source = SignalSource(self.source)
    except (ValueError, KeyError):
      pass


# –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á
TradingSignal.__post_init__ = _patched_tradingsignal_post_init

print("‚úì TradingSignal –ø–∞—Ç—á –ø—Ä–∏–º–µ–Ω–µ–Ω - –≤—Å–µ .value –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")

original_post_init = TradingSignal.__post_init__


def patched_post_init(self):
  original_post_init(self)
  if isinstance(self.signal_type, str):
    self.signal_type = SignalType(self.signal_type)
  if isinstance(self.strength, str):
    self.strength = SignalStrength(self.strength)
  if isinstance(self.source, str):
    self.source = SignalSource(self.source)


TradingSignal.__post_init__ = patched_post_init

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
setup_logging()
logger = get_logger(__name__)

# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ verbose –ª–æ–≥–æ–≤ —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
logging.getLogger('mlflow').setLevel(logging.WARNING)
logging.getLogger('alembic').setLevel(logging.WARNING)
logging.getLogger('sqlalchemy.engine').setLevel(logging.WARNING)

# ============================================================
# –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –ü–ê–ú–Ø–¢–ò
# ============================================================

def get_memory_usage() -> float:
  """
  –ü–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ —Ç–µ–∫—É—â–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º –≤ –ú–ë.

  Returns:
      float: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ –ú–ë
  """
  try:
    process = psutil.Process(os.getpid())
    memory_mb = process.memory_info().rss / (1024 * 1024)
    return memory_mb
  except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
    return 0.0


class BotController:
  """–ì–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –±–æ—Ç–∞."""

  def __init__(self):
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö —Ñ–∞–∑.

    –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
    - –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (WebSocket, OrderBook, Candles)
    - Strategy Manager (–§–∞–∑–∞ 1)
    - Adaptive Consensus (–§–∞–∑–∞ 2)
    - MTF Manager (–§–∞–∑–∞ 3)
    - Integrated Engine (–§–∞–∑–∞ 4)
    - ML Components
    - Execution & Risk Management
    """
    self.status = BotStatus.STOPPED
    self.symbols = settings.get_trading_pairs_list()
    self.initialized = False

    # ==================== –ë–ê–ó–û–í–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ ====================
    self.websocket_manager: Optional[BybitWebSocketManager] = None
    self.orderbook_managers: Dict[str, OrderBookManager] = {}
    self.trade_managers: Dict[str, TradeManager] = {}  # Market trades tracking
    self.orderbook_analyzer: Optional[OrderBookAnalyzer] = None
    self.candle_managers: Dict[str, CandleManager] = {}

    # Tracking –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
    # MEMORY OPTIMIZATION: Use OrderedDict as LRU cache with max size
    # Previously: unlimited Dict that kept growing (15 symbols √ó continuous updates)
    # Now: Limited to MAX_PREV_SNAPSHOTS (20) with automatic eviction of oldest
    from collections import OrderedDict
    self.prev_orderbook_snapshots: OrderedDict[str, OrderBookSnapshot] = OrderedDict()
    self.prev_candles: Dict[str, Candle] = {}
    self.MAX_PREV_SNAPSHOTS = 20  # Maximum prev snapshots to keep (1-2 per symbol)

    # Timestamps –¥–ª—è tracking –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
    self.last_snapshot_update: Dict[str, int] = {}
    self.last_candle_update: Dict[str, int] = {}

    self.market_analyzer: Optional[MarketAnalyzer] = None
    self.strategy_engine: Optional[StrategyEngine] = None
    self.risk_manager: Optional[RiskManager] = None
    self.execution_manager: Optional[ExecutionManager] = None
    self.balance_tracker = balance_tracker


    # ==================== ML –ö–û–ú–ü–û–ù–ï–ù–¢–´ ====================
    self.ml_feature_pipeline: Optional[MultiSymbolFeaturePipeline] = None
    self.ml_data_collector: Optional[MLDataCollector] = None
    self.latest_features: Dict[str, FeatureVector] = {}

    # ==================== –§–ê–ó–ê 1: EXTENDED STRATEGY MANAGER ====================
    self.strategy_manager: Optional[ExtendedStrategyManager] = None

    # –§–ª–∞–≥–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è/–æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    self.enable_orderbook_strategies = settings.ENABLE_ORDERBOOK_STRATEGIES if hasattr(settings,
                                                                                       'ENABLE_ORDERBOOK_STRATEGIES') else True
    self.enable_adaptive_consensus = settings.ENABLE_ADAPTIVE_CONSENSUS if hasattr(settings,
                                                                                   'ENABLE_ADAPTIVE_CONSENSUS') else True
    self.enable_mtf_analysis = settings.ENABLE_MTF_ANALYSIS if hasattr(settings, 'ENABLE_MTF_ANALYSIS') else True
    self.enable_ml_validation = settings.ENABLE_ML_VALIDATION if hasattr(settings, 'ENABLE_ML_VALIDATION') else True
    self.enable_paper_trading = settings.PAPER_TRADING if hasattr(settings, 'PAPER_TRADING') else False

    # ==================== –§–ê–ó–ê 2: ADAPTIVE CONSENSUS ====================
    self.adaptive_consensus: Optional[AdaptiveConsensusManager] = None
    # Alias for API compatibility
    self.adaptive_consensus_manager: Optional[AdaptiveConsensusManager] = None

    # ==================== –§–ê–ó–ê 3: MULTI-TIMEFRAME ====================
    self.mtf_manager: Optional[MultiTimeframeManager] = None

    # ==================== –§–ê–ó–ê 4: INTEGRATED ENGINE ====================
    self.integrated_engine: Optional[IntegratedAnalysisEngine] = None

    # ==================== ML SIGNAL VALIDATOR ====================
    # –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è ML Validator
    logger.info("ü§ñ –°–æ–∑–¥–∞–Ω–∏–µ ML Signal Validator...")
    try:
      ml_validator_config = ValidationConfig(
        model_server_url=settings.ML_SERVER_URL,
        model_version="latest",
        request_timeout=5.0,
        health_check_enabled=True,
        health_check_interval=30,
        health_check_timeout=2.0,
        min_ml_confidence=settings.ML_MIN_CONFIDENCE,
        confidence_boost_factor=1.2,
        confidence_penalty_factor=0.7,
        ml_weight=settings.ML_WEIGHT,
        strategy_weight=settings.STRATEGY_WEIGHT,
        use_fallback_on_error=True,
        fallback_to_strategy=True,
        cache_predictions=True,
        cache_ttl_seconds=30,
        enable_mae_prediction=True,
        enable_manipulation_detection=True,
        enable_regime_detection=True,
        enable_feature_quality_check=True
      )
      self.ml_validator = MLSignalValidator(config=ml_validator_config)
      logger.info(f"‚úì ML Signal Validator —Å–æ–∑–¥–∞–Ω: server={settings.ML_SERVER_URL}")
    except Exception as e:
      logger.warning(f"‚ö†Ô∏è ML Signal Validator creation failed: {e}. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ ML –≤–∞–ª–∏–¥–∞—Ü–∏–∏.")
      self.ml_validator = None

    # ==================== DETECTION SYSTEMS ====================
    # Drift Detector
    self.drift_detector = DriftDetector(
      window_size=10000,
      baseline_window_size=50000,
      drift_threshold=0.1
    )

    # Spoofing Detector
    spoofing_config = SpoofingConfig(
      large_order_threshold_usdt=50000.0,
      suspicious_ttl_seconds=10.0,
      cancel_rate_threshold=0.7
    )
    self.spoofing_detector = SpoofingDetector(spoofing_config)

    # Layering Detector (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø–æ—Å–ª–µ TradeManagers –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)
    self.layering_config = LayeringConfig(
      min_orders_in_layer=3,
      max_price_spread_pct=0.005,
      min_layer_volume_btc=0.5  # FIXED: Changed from min_layer_volume_usdt to min_layer_volume_btc
    )
    self.layering_detector = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ–∑–∂–µ —Å trade_managers

    # S/R Level Detector
    sr_config = SRLevelConfig(
      min_touches=2,
      lookback_candles=200,
      max_age_hours=24
    )
    self.sr_detector = SRLevelDetector(sr_config)

    # ==================== –ó–ê–î–ê–ß–ò ====================
    self.websocket_task: Optional[asyncio.Task] = None
    self.analysis_task: Optional[asyncio.Task] = None
    self.candle_update_task: Optional[asyncio.Task] = None
    self.ml_stats_task: Optional[asyncio.Task] = None
    self.layering_save_task: Optional[asyncio.Task] = None
    self.screener_broadcast_task: Optional[asyncio.Task] = None
    self.symbols_refresh_task: Optional[asyncio.Task] = None
    self.correlation_update_task: Optional[asyncio.Task] = None
    self.position_monitor_task: Optional[asyncio.Task] = None

    # ==================== –î–†–£–ì–ò–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ ====================
    self.screener_manager: Optional[ScreenerManager] = None
    self.dynamic_symbols_manager: Optional[DynamicSymbolsManager] = None
    self.position_monitor: Optional[PositionMonitor] = None
    self.weight_optimization_task: Optional[asyncio.Task] = None
    self.mtf_update_task: Optional[asyncio.Task] = None



    self.running = False

    # ========== STATISTICS & DIAGNOSTICS ==========
    self.stats = {
      'signals_generated': 0,
      'signals_executed': 0,
      'orders_placed': 0,
      'positions_opened': 0,
      'positions_closed': 0,
      'total_pnl': 0.0,
      'consensus_achieved': 0,
      'consensus_failed': 0,
      'mtf_signals': 0,
      'adaptive_weight_updates': 0,
      'ml_validations': 0,
      'ml_data_collected': 0,
      'manipulations_detected': 0,
      'drift_detections': 0,
      'analysis_cycles': 0,
      'errors': 0,
      'warnings': 0
    }

    logger.info("‚úÖ BotController –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –§–∞–∑ 1-4")

  async def initialize(self):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –±–æ—Ç–∞."""
    try:
      logger.info("=" * 80)
      logger.info("–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–û–ú–ü–û–ù–ï–ù–¢–û–í –ë–û–¢–ê (ML-ENHANCED)")
      logger.info("=" * 80)

      initialization_start = time.time()

      # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º REST –∫–ª–∏–µ–Ω—Ç
      await rest_client.initialize()
      logger.info("‚úì REST –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

      # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä—ã–Ω–∫–∞ (–ø–æ–∫–∞ –±–µ–∑ —Å–∏–º–≤–æ–ª–æ–≤)
      self.market_analyzer = MarketAnalyzer()
      logger.info("‚úì –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä—ã–Ω–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")



      # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∏—Ä–∂–µ
      server_time = await rest_client.get_server_time()
      logger.info(f"‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Bybit —É—Å–ø–µ—à–Ω–æ. –°–µ—Ä–≤–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: {server_time}")

      # ===== SCREENER MANAGER - –°–†–ê–ó–£ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º =====
      if settings.SCREENER_ENABLED:
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Screener Manager...")
        self.screener_manager = ScreenerManager()
        logger.info("‚úì Screener Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
      else:
        self.screener_manager = None
        logger.info("Screener Manager –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

      # ===== DYNAMIC SYMBOLS - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä =====
      if settings.DYNAMIC_SYMBOLS_ENABLED:
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Dynamic Symbols Manager...")
        self.dynamic_symbols_manager = DynamicSymbolsManager(
          min_volume=settings.DYNAMIC_MIN_VOLUME,
          max_volume_pairs=settings.DYNAMIC_MAX_VOLUME_PAIRS,
          top_gainers=settings.DYNAMIC_TOP_GAINERS,
          top_losers=settings.DYNAMIC_TOP_LOSERS
        )
        logger.info("‚úì Dynamic Symbols Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")


      # ===== ML DATA COLLECTOR =====
      if settings.ML_DATA_COLLECTION_ENABLED:
        self.ml_data_collector = MLDataCollector(
          storage_path="../data/ml_training",
          max_samples_per_file=60,   # OPTIMIZED: 100 ‚Üí 60 –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ ~3 —Å–µ–∫ (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ ~15 –º–∏–Ω)
          collection_interval=5,     # OPTIMIZED: 10 ‚Üí 5 –¥–ª—è –±–æ–ª–µ–µ —á–∞—Å—Ç–æ–≥–æ —Å–±–æ—Ä–∞ (4 —Å–µ–º–ø–ª–∞/–º–∏–Ω)
          # auto_save_interval_seconds = 300  # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
          max_buffer_memory_mb=20,   # OPTIMIZED: 30 ‚Üí 20 (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ~1%)
          # Feature Store integration
          enable_feature_store=True,  # ‚úÖ –ó–∞–ø–∏—Å—ã–≤–∞—Ç—å –≤ Feature Store (parquet)
          use_legacy_format=False,     # MEMORY FIX: False to save CPU/memory
          feature_store_group="training_features"
        )
        await self.ml_data_collector.initialize()
        logger.info("‚úì ML Data Collector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Feature Store only, optimized buffers)")
      else:
        self.ml_data_collector = None
        logger.info("‚ö†Ô∏è  ML Data Collection –û–¢–ö–õ–Æ–ß–ï–ù (–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ ML_DATA_COLLECTION_ENABLED=false)")

      # ========== –≠–¢–ê–ü 5: STRATEGY MANAGER (–§–ê–ó–ê 1) ==========
      logger.info("üéØ [5/10] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ExtendedStrategyManager (–§–∞–∑–∞ 1)...")

      from backend.strategies.strategy_manager import StrategyPriority

      # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Extended Strategy Manager
      strategy_config = ExtendedStrategyManagerConfig(
        consensus_mode="weighted",  # weighted / majority / unanimous
        min_strategies_for_signal=2,
        min_consensus_confidence=0.6,

        # –í–µ—Å–∞ CANDLE —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        candle_strategy_weights={
          'momentum': 0.20,
          'sar_wave': 0.15,
          'supertrend': 0.20,
          'volume_profile': 0.15
        },

        # –í–µ—Å–∞ ORDERBOOK —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        orderbook_strategy_weights={
          'imbalance': 0.10,
          'volume_flow': 0.10,
          'liquidity_zone': 0.10
        } if self.enable_orderbook_strategies else {},

        # –í–µ—Å–∞ HYBRID —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        hybrid_strategy_weights={
          'smart_money': 0.15
        } if self.enable_orderbook_strategies else {},

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        strategy_priorities={
          'momentum': StrategyPriority.HIGH,
          'supertrend': StrategyPriority.HIGH,
          'liquidity_zone': StrategyPriority.HIGH,
          'smart_money': StrategyPriority.HIGH,
          'sar_wave': StrategyPriority.MEDIUM,
          'volume_profile': StrategyPriority.MEDIUM,
          'imbalance': StrategyPriority.MEDIUM,
          'volume_flow': StrategyPriority.MEDIUM
        },

        # –í–∫–ª—é—á–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        enable_orderbook_strategies=self.enable_orderbook_strategies,
        enable_hybrid_strategies=self.enable_orderbook_strategies
      )

      # self.strategy_manager = ExtendedStrategyManager(strategy_config)
      # logger.info("‚úÖ ExtendedStrategyManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
      # logger.info(f"üìä –ê–∫—Ç–∏–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {list(self.strategy_manager.all_strategies.keys())}")

      # ========== –≠–¢–ê–ü 6: ADAPTIVE CONSENSUS (–§–ê–ó–ê 2) ==========
      if self.enable_adaptive_consensus:
        logger.info("üîÑ [6/10] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Adaptive Consensus Manager (–§–∞–∑–∞ 2)...")

        try:
          adaptive_config = AdaptiveConsensusConfig(
            # Enable/disable –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            enable_performance_tracking=True,
            enable_regime_detection=True,
            enable_weight_optimization=True,

            # Performance Tracker Config
            performance_tracker_config=PerformanceTrackerConfig(
              data_dir="data/strategy_performance",
              enable_persistence=True,
              short_term_hours=24,
              medium_term_days=7,
              long_term_days=30,
              min_signals_for_metrics=settings.ADAPTIVE_MIN_SIGNALS_FOR_EVALUATION if hasattr(settings,
                                                                                              'ADAPTIVE_MIN_SIGNALS_FOR_EVALUATION') else 20,
              min_closed_signals_for_metrics=10
            ),

            # Regime Detector Config
            regime_detector_config=RegimeDetectorConfig(
              adx_strong_threshold=25.0,
              adx_weak_threshold=15.0,
              update_frequency_seconds=300  # 5 –º–∏–Ω—É—Ç
            ),

            # Weight Optimizer Config
            weight_optimizer_config=WeightOptimizerConfig(
              optimization_method=OptimizationMethod.HYBRID,  # Performance + Regime
              min_weight=0.05,
              max_weight=0.40,
              update_frequency_seconds=settings.ADAPTIVE_WEIGHT_UPDATE_FREQUENCY_SECONDS if hasattr(settings,
                                                                                                    'ADAPTIVE_WEIGHT_UPDATE_FREQUENCY_SECONDS') else 21600,
              regime_weight_blend=0.6,  # 60% performance, 40% regime
              min_signals_for_optimization=30
            ),

            # Consensus Config
            consensus_mode="adaptive_weighted",
            min_consensus_confidence=0.6,
            conflict_resolution_mode="performance_priority",
            enable_quality_metrics=True,
            min_consensus_quality=0.6
          )

          # self.adaptive_consensus = AdaptiveConsensusManager(
          #   config=adaptive_config,
          #   strategy_manager=self.strategy_manager
          # )

          logger.info("‚úÖ Adaptive Consensus Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
          logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Adaptive Consensus: {e}")
          logger.warning("‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ Adaptive Consensus")
          self.adaptive_consensus = None
          self.adaptive_consensus_manager = None  # Update alias
      else:
        logger.info("‚ÑπÔ∏è [6/10] Adaptive Consensus –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")

      # ========== –≠–¢–ê–ü 7: MTF MANAGER (–§–ê–ó–ê 3) ==========
      if self.enable_mtf_analysis:
        logger.info("‚è±Ô∏è [7/10] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Multi-Timeframe Manager (–§–∞–∑–∞ 3)...")

        try:
          # –ü–∞—Ä—Å–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
          mtf_active_tfs = settings.MTF_ACTIVE_TIMEFRAMES if hasattr(settings,
                                                                     'MTF_ACTIVE_TIMEFRAMES') else "1m,5m,15m,1h"
          mtf_primary_tf = settings.MTF_PRIMARY_TIMEFRAME if hasattr(settings, 'MTF_PRIMARY_TIMEFRAME') else "1h"
          mtf_execution_tf = settings.MTF_EXECUTION_TIMEFRAME if hasattr(settings, 'MTF_EXECUTION_TIMEFRAME') else "1m"
          mtf_synthesis_mode = settings.MTF_SYNTHESIS_MODE if hasattr(settings, 'MTF_SYNTHESIS_MODE') else "top_down"
          mtf_min_quality = settings.MTF_MIN_QUALITY if hasattr(settings, 'MTF_MIN_QUALITY') else 0.60
          mtf_staggered_interval = settings.MTF_STAGGERED_UPDATE_INTERVAL if hasattr(settings,
                                                                                     'MTF_STAGGERED_UPDATE_INTERVAL') else 5

          active_tfs_str = mtf_active_tfs.split(',')
          active_timeframes = [Timeframe(tf.strip()) for tf in active_tfs_str]
          primary_tf = Timeframe(mtf_primary_tf)
          execution_tf = Timeframe(mtf_execution_tf)

          logger.info(f"üìä MTF –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {[tf.value for tf in active_timeframes]}")
          logger.info(f"üéØ Primary TF: {primary_tf.value}, Execution TF: {execution_tf.value}")



          logger.info("‚úÖ Multi-Timeframe Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
          logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MTF Manager: {e}")
          logger.warning("‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ MTF Analysis")
          self.mtf_manager = None
      else:
        logger.info("‚ÑπÔ∏è [7/10] Multi-Timeframe Analysis –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")

      # ========== –≠–¢–ê–ü 8: INTEGRATED ENGINE (–§–ê–ó–ê 4) ==========
      logger.info("üéØ [8/10] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Integrated Analysis Engine (–§–∞–∑–∞ 4)...")

      try:
        integrated_mode = settings.INTEGRATED_ANALYSIS_MODE if hasattr(settings,
                                                                       'INTEGRATED_ANALYSIS_MODE') else "hybrid"
        hybrid_mtf_priority = settings.HYBRID_MTF_PRIORITY if hasattr(settings, 'HYBRID_MTF_PRIORITY') else 0.6
        hybrid_min_agreement = settings.HYBRID_MIN_AGREEMENT if hasattr(settings, 'HYBRID_MIN_AGREEMENT') else True
        hybrid_conflict_resolution = settings.HYBRID_CONFLICT_RESOLUTION if hasattr(settings,
                                                                                    'HYBRID_CONFLICT_RESOLUTION') else "highest_quality"
        min_combined_quality = settings.MIN_COMBINED_QUALITY if hasattr(settings, 'MIN_COMBINED_QUALITY') else 0.65

        # integrated_config = IntegratedAnalysisConfig(
        #   # –†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞
        #   analysis_mode=AnalysisMode(integrated_mode),
        #
        #   # –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        #   enable_adaptive_consensus=(self.adaptive_consensus is not None),
        #   enable_mtf_analysis=(self.mtf_manager is not None),
        #
        #   # Hybrid —Ä–µ–∂–∏–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        #   hybrid_mtf_priority=hybrid_mtf_priority,
        #   hybrid_min_agreement=hybrid_min_agreement,
        #   hybrid_conflict_resolution=hybrid_conflict_resolution,
        #
        #   # Quality control
        #   min_combined_quality=min_combined_quality,
        #
        #
        #   # Fallback
        #
        # )
        active_tfs_str = settings.MTF_ACTIVE_TIMEFRAMES.split(',')
        active_timeframes = [Timeframe(tf.strip()) for tf in active_tfs_str]
        primary_tf = Timeframe(settings.MTF_PRIMARY_TIMEFRAME)
        execution_tf = Timeframe(settings.MTF_EXECUTION_TIMEFRAME)

        integrated_config = IntegratedAnalysisConfig(
          analysis_mode=AnalysisMode.HYBRID,

          # Strategy Manager Config
          strategy_manager_config=ExtendedStrategyManagerConfig(
            enable_orderbook_strategies=True,
            enable_hybrid_strategies=True,
            consensus_mode="weighted"
          ),

          # Adaptive Consensus Config
          adaptive_consensus_config=AdaptiveConsensusConfig(
            # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º enable_*, –ù–ï enabled
            enable_performance_tracking=settings.PERFORMANCE_TRACKING_ENABLED,
            enable_regime_detection=settings.REGIME_DETECTION_ENABLED,
            enable_weight_optimization=settings.WEIGHT_OPTIMIZATION_ENABLED,

            # ‚úÖ –í–ª–æ–∂–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            performance_tracker_config=PerformanceTrackerConfig(),
            regime_detector_config=RegimeDetectorConfig(),
            weight_optimizer_config=WeightOptimizerConfig(
              # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º OptimizationMethod[value], –ù–ï WeightOptimizationMethod
              optimization_method=OptimizationMethod[settings.WEIGHT_OPTIMIZATION_METHOD],
              update_frequency_seconds=settings.WEIGHT_UPDATE_FREQUENCY_SECONDS
            )
          ),

          # MTF Config
          mtf_config=MTFManagerConfig(
            enabled=settings.ENABLE_MTF_ANALYSIS,
            coordinator_config=MultiTimeframeConfig(
              active_timeframes=active_timeframes,  # ‚úÖ –¢–µ–ø–µ—Ä—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
              primary_timeframe=primary_tf,  # ‚úÖ –¢–µ–ø–µ—Ä—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
              execution_timeframe=execution_tf  # ‚úÖ –¢–µ–ø–µ—Ä—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
            ),
            aligner_config=AlignmentConfig(
              timeframe_weights={
                Timeframe.H1: 0.50,
                Timeframe.M15: 0.30,
                Timeframe.M5: 0.15,
                Timeframe.M1: 0.05
              },
              min_alignment_score=0.65,
              confluence_price_tolerance_percent=0.5,
              min_timeframes_for_confluence=1,
              allow_trend_counter_signals=False
            ),
            synthesizer_config=SynthesizerConfig(
              mode=SynthesisMode(settings.MTF_SYNTHESIS_MODE),
              min_signal_quality=settings.MTF_MIN_QUALITY,
              min_timeframes_required=2,
              enable_dynamic_position_sizing=True,
              max_position_multiplier=1.5,
              min_position_multiplier=0.3,
              use_higher_tf_for_stops=True,
              atr_multiplier_for_stops=2.0
            ),
            fallback_to_single_tf=True
          ),

          # Hybrid config
          hybrid_conflict_resolution=settings.HYBRID_CONFLICT_RESOLUTION,  # –ù–ï ConflictResolutionMode!
          hybrid_mtf_priority=settings.HYBRID_MTF_PRIORITY,
          hybrid_min_agreement=settings.HYBRID_MIN_AGREEMENT,
          min_combined_quality=settings.MIN_COMBINED_QUALITY
        )

        self.integrated_engine = IntegratedAnalysisEngine(integrated_config)

        self.strategy_manager = self.integrated_engine.strategy_manager
        self.adaptive_consensus = self.integrated_engine.adaptive_consensus
        self.adaptive_consensus_manager = self.adaptive_consensus  # Update alias
        self.mtf_manager = self.integrated_engine.mtf_manager

        # –ù–û–í–û–ï: –ü–µ—Ä–µ–¥–∞–µ–º trade_managers –≤ Strategy Manager –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö market trades —Ñ–∏—á–µ–π
        if self.strategy_manager and self.trade_managers:
          self.strategy_manager.trade_managers = self.trade_managers
          logger.info(
            f"‚úÖ TradeManagers –ø–µ—Ä–µ–¥–∞–Ω—ã –≤ Strategy Manager –¥–ª—è {len(self.trade_managers)} —Å–∏–º–≤–æ–ª–æ–≤"
          )

        if hasattr(self, 'ml_validator') and self.ml_validator is not None:
          logger.info("üîó –ü—Ä–∏–≤—è–∑–∫–∞ ML Validator –∫ TimeframeAnalyzer...")

          # –î–æ—Å—Ç—É–ø –∫ analyzer —á–µ—Ä–µ–∑ mtf_manager
          self.mtf_manager.analyzer.ml_validator = self.ml_validator

          # –î–æ—Å—Ç—É–ø –∫ feature_pipeline (–µ—Å–ª–∏ –µ—Å—Ç—å)
          if hasattr(self, 'feature_pipeline') and self.ml_feature_pipeline is not None:
            self.mtf_manager.analyzer.feature_pipeline = self.feature_pipeline
            logger.info("‚úÖ ML Validator –∏ Feature Pipeline –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ TimeframeAnalyzer")
          else:
            logger.warning(
              "‚ö†Ô∏è Feature Pipeline –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - "
              "ML predictions –±—É–¥—É—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã"
            )
        else:
          logger.info(
            "‚ÑπÔ∏è ML Validator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - "
            "TimeframeAnalyzer —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ ML"
          )

        # # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–º–≤–æ–ª–æ–≤ –≤ Integrated Engine
        # for symbol in self.symbols:
        #   await self.integrated_engine.initialize_symbol(symbol)
        #   logger.info(f"‚úÖ {symbol}: Integrated Engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        logger.info("‚úÖ Integrated Analysis Engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"üìä –†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞: {integrated_mode}")



        # ========== CONFIGURATION SNAPSHOT ==========
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        self.config_snapshot = {
          'trading_pairs': settings.TRADING_PAIRS,
          'default_leverage': settings.DEFAULT_LEVERAGE,
          'analysis_interval': settings.ANALYSIS_INTERVAL,
          'candle_limit': settings.CANDLE_LIMIT,
          'enable_orderbook_strategies': self.enable_orderbook_strategies,
          'enable_adaptive_consensus': self.enable_adaptive_consensus,
          'enable_mtf_analysis': self.enable_mtf_analysis,
          'enable_ml_validation': self.enable_ml_validation,
          'paper_trading': self.enable_paper_trading,
          'mtf_timeframes': settings.MTF_ACTIVE_TIMEFRAMES if self.enable_mtf_analysis else None,
          'mtf_synthesis_mode': settings.MTF_SYNTHESIS_MODE if self.enable_mtf_analysis else None,
          'integrated_analysis_mode': settings.INTEGRATED_ANALYSIS_MODE,
          'timestamp': datetime.now().isoformat()
        }


      except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Integrated Engine: {e}")
        raise  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ - –ø—Ä–µ—Ä—ã–≤–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é


      # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
      self.strategy_engine = StrategyEngine()
      logger.info("‚úì –¢–æ—Ä–≥–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

      # # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ—Ä–≥—É–µ–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
      # await correlation_manager.initialize(self.symbols)


      logger.info("=" * 80)
      logger.info("–ë–ê–ó–û–í–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–´ (–ë–ï–ó WEBSOCKET)")
      logger.info("=" * 80)
      self.initialized = True
      self.startup_timestamp = datetime.now()

      initialization_time = time.time() - initialization_start
      logger.info("=" * 80)
      logger.info(f"‚úÖ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –∑–∞ {initialization_time:.2f}—Å")
      logger.info("=" * 80)
      logger.info(f"üìä –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã:")
      logger.info(f"   - –ë–∞–∑–æ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã: ‚úÖ")
      logger.info(f"   - Market Data Managers: ‚úÖ ({len(self.symbols)} –ø–∞—Ä)")
      logger.info(f"   - Strategy Manager: ‚úÖ")
      logger.info(f"   - Adaptive Consensus: {'‚úÖ' if self.adaptive_consensus else '‚ùå'}")
      logger.info(f"   - MTF Manager: {'‚úÖ' if self.mtf_manager else '‚ùå'}")
      logger.info(f"   - Integrated Engine: ‚úÖ")
      logger.info(f"   - ML Components: {'‚úÖ' if self.ml_validator else '‚ö†Ô∏è'}")
      logger.info(f"   - Execution & Risk: ‚è≥ (–≤ start())")
      logger.info("=" * 80)

    except Exception as e:
      logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò: {e}")
      logger.error(traceback.format_exc())
      log_exception(logger, e, "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞")

      # Cleanup —á–∞—Å—Ç–∏—á–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
      await self._cleanup_on_error()

      raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å BotController: {e}") from e

  async def start(self):
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
    –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–¨:
    1. ML Signal Validator - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è HTTP —Å–µ—Å—Å–∏–∏
    2. Risk Manager - –ø–æ–ª—É—á–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    3. Execution Manager - —Å–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫
    4. Balance Tracker - –∑–∞–ø—É—Å–∫
    5. Daily Loss Killer - –∑–∞–ø—É—Å–∫
    6. Screener Manager (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –∑–∞–ø—É—Å–∫
    7. Dynamic Symbols (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) - –≤—ã–±–æ—Ä –ø–∞—Ä
    8. Correlation Manager - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    9. ML Feature Pipeline - —Å–æ–∑–¥–∞–Ω–∏–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    10. OrderBook/Candle Managers - —Å–æ–∑–¥–∞–Ω–∏–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    11. Market Analyzer - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤
    12. Position Monitor - —Å–æ–∑–¥–∞–Ω–∏–µ
    13. WebSocket Manager - —Å–æ–∑–¥–∞–Ω–∏–µ –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    14. Historical Candles - –∑–∞–≥—Ä—É–∑–∫–∞
    15. Analysis Loop - –∑–∞–ø—É—Å–∫
    16. Position Monitor - –∑–∞–ø—É—Å–∫
    17. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ - –∑–∞–ø—É—Å–∫

    """
    if self.status == BotStatus.RUNNING:
      logger.warning("–ë–æ—Ç —É–∂–µ –∑–∞–ø—É—â–µ–Ω")
      return

    try:
      self.status = BotStatus.STARTING
      logger.info("=" * 80)
      logger.info("–ó–ê–ü–£–°–ö –¢–û–†–ì–û–í–û–ì–û –ë–û–¢–ê (ML-ENHANCED)")
      logger.info("=" * 80)

      # CRITICAL: Set aggressive GC thresholds for better memory management
      # Default: (700, 10, 10) - Standard
      # Aggressive: (500, 5, 5) - Collects more frequently
      gc.set_threshold(500, 5, 5)
      logger.info("üßπ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ GC: (500, 5, 5)")

      # ========== 1. ML SIGNAL VALIDATOR - –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ==========
      # –í–ê–ñ–ù–û: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º HTTP —Å–µ—Å—Å–∏—é –∏ health check
      if self.ml_validator:
        logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML Signal Validator...")
        try:
          await self.ml_validator.initialize()
          logger.info("‚úÖ ML Signal Validator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
          logger.error(
            f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ML Validator: {e}. "
            f"ML validator –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
          )
          # –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ—Ç–∞, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
      else:
        logger.warning("‚ö†Ô∏è ML Signal Validator –Ω–µ —Å–æ–∑–¥–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")

      # ========== 2. RISK MANAGER - –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ==========

      # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º –±–∞–ª–∞–Ω—Å–æ–º
      await self._initialize_risk_manager()

      # ========== 3. EXECUTION MANAGER - –°–û–ó–î–ê–ù–ò–ï –ò –ó–ê–ü–£–°–ö ==========

      self.execution_manager = ExecutionManager(self.risk_manager)
      logger.info("‚úì –ú–µ–Ω–µ–¥–∂–µ—Ä –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

      # –ó–∞–ø—É—Å–∫–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
      await self.execution_manager.start()
      logger.info("‚úì –ú–µ–Ω–µ–¥–∂–µ—Ä –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω")

      # ========== 4. BALANCE TRACKER - –ó–ê–ü–£–°–ö ==========

      # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–µ–∫–µ—Ä –±–∞–ª–∞–Ω—Å–∞
      await self.balance_tracker.start()
      logger.info("‚úì –¢—Ä–µ–∫–µ—Ä –±–∞–ª–∞–Ω—Å–∞ –∑–∞–ø—É—â–µ–Ω")

      # ========== 5. DAILY LOSS KILLER - –ó–ê–ü–£–°–ö ===========
      # –ü–µ—Ä–µ–¥–∞–µ–º ExecutionManager –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–π –ø—Ä–∏ emergency shutdown
      daily_loss_killer.execution_manager = self.execution_manager
      await daily_loss_killer.start()
      logger.info("‚úì Daily Loss Killer –∑–∞–ø—É—â–µ–Ω —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π ExecutionManager")

      # ========== 6. SCREENER MANAGER (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) - –ó–ê–ü–£–°–ö ==========
      if self.screener_manager:
        logger.info("–ó–∞–ø—É—Å–∫ Screener Manager...")
        await self.screener_manager.start()

        # –ó–∞–ø—É—Å–∫–∞–µ–º broadcast –∑–∞–¥–∞—á—É
        self.screener_broadcast_task = asyncio.create_task(
          self._screener_broadcast_loop()
        )
        logger.info("–û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ä –æ—Ç screener...")
        await asyncio.sleep(6)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö

        logger.info("‚úì Screener Manager –∑–∞–ø—É—â–µ–Ω")

        # ========== 7. DYNAMIC SYMBOLS (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) - –í–´–ë–û–† –ü–ê–† ==========
        if settings.DYNAMIC_SYMBOLS_ENABLED and self.dynamic_symbols_manager:
          logger.info("–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –æ—Ç–±–æ—Ä —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä...")

          # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç screener
          screener_pairs = self.screener_manager.get_all_pairs()

          # –û—Ç–±–∏—Ä–∞–µ–º –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
          self.symbols = self.dynamic_symbols_manager.select_symbols(screener_pairs)

          logger.info(f"‚úì –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –æ—Ç–æ–±—Ä–∞–Ω–æ {len(self.symbols)} –ø–∞—Ä –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
        else:
          # Fallback –Ω–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
          self.symbols = settings.get_trading_pairs_list()
          logger.info(f"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫: {len(self.symbols)} –ø–∞—Ä")
      else:
        # –ï—Å–ª–∏ screener –≤—ã–∫–ª—é—á–µ–Ω - —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
        self.symbols = settings.get_trading_pairs_list()
        logger.info(f"‚úì Screener –æ—Ç–∫–ª—é—á–µ–Ω, —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫: {len(self.symbols)} –ø–∞—Ä")

      # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç–∞–∫–∞–Ω–∞
      self.orderbook_analyzer = OrderBookAnalyzer(self.symbols)
      logger.info("‚úì –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç–∞–∫–∞–Ω–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

      # ========== 7.5 –ù–û–í–ê–Ø –°–ï–ö–¶–ò–Ø: –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –î–õ–Ø –§–ò–ù–ê–õ–¨–ù–´–• –ü–ê–† ==========
      logger.info("=" * 80)
      logger.info(f"–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–û–ú–ü–û–ù–ï–ù–¢–û–í –î–õ–Ø {len(self.symbols)} –ü–ê–†")
      logger.info("=" * 80)

      # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Integrated Engine –¥–ª—è –≤—Å–µ—Ö –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø–∞—Ä
      initialized_count = 0
      failed_count = 0

      for symbol in self.symbols:
        try:
          logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è {symbol}...")

          # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Integrated Engine (–≤–∫–ª—é—á–∞–µ—Ç MTF)
          success = await self.integrated_engine.initialize_symbol(symbol)

          if success:
            initialized_count += 1
            logger.info(f"‚úÖ {symbol}: –£—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
          else:
            failed_count += 1
            logger.warning(f"‚ö†Ô∏è {symbol}: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")

        except Exception as e:
          failed_count += 1
          logger.error(f"‚ùå {symbol}: –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ - {e}")

      logger.info("=" * 80)
      logger.info(
        f"–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê: "
        f"‚úÖ {initialized_count} —É—Å–ø–µ—à–Ω–æ, "
        f"‚ùå {failed_count} –æ—à–∏–±–æ–∫"
      )
      logger.info("=" * 80)

      # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–∞—Ä–∞
      if initialized_count == 0:
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã")

      # ========== 8. CORRELATION MANAGER - –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ==========

      logger.info("=" * 80)
      logger.info("–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø CORRELATION MANAGER")
      logger.info("=" * 80)

      await correlation_manager.initialize(self.symbols)

      logger.info(
        f"‚úì CorrelationManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {len(self.symbols)} —Å–∏–º–≤–æ–ª–æ–≤: "
        f"–≥—Ä—É–ø–ø={len(correlation_manager.group_manager.groups)}, "
        f"–ø–æ–∫—Ä—ã—Ç–æ={len(correlation_manager.group_manager.symbol_to_group)} —Å–∏–º–≤–æ–ª–æ–≤"
      )


      # ========== 9. ORDERBOOK/CANDLE MANAGERS - –°–û–ó–î–ê–ù–ò–ï –î–õ–Ø –§–ò–ù–ê–õ–¨–ù–´–• –ü–ê–† ==========
      logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ —Å—Ç–∞–∫–∞–Ω–∞ –¥–ª—è {len(self.symbols)} –ø–∞—Ä...")
      for symbol in self.symbols:
        self.orderbook_managers[symbol] = OrderBookManager(symbol)
      logger.info(f"‚úì –°–æ–∑–¥–∞–Ω–æ {len(self.orderbook_managers)} –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ —Å—Ç–∞–∫–∞–Ω–∞")

      # ===== –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä—ã market trades –¥–ª—è –§–ò–ù–ê–õ–¨–ù–´–• –ø–∞—Ä =====
      logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ market trades –¥–ª—è {len(self.symbols)} –ø–∞—Ä...")
      for symbol in self.symbols:
        self.trade_managers[symbol] = TradeManager(
          symbol=symbol,
          max_history=5000,  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5000 —Å–¥–µ–ª–æ–∫ (~5-10 –º–∏–Ω—É—Ç)
          enable_statistics=True
        )
      logger.info(f"‚úì –°–æ–∑–¥–∞–Ω–æ {len(self.trade_managers)} –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ market trades")

      # ===== –°–æ–∑–¥–∞–µ–º Advanced ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è LayeringDetector =====
      logger.info("=" * 80)
      logger.info("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Advanced ML Components –¥–ª—è Layering Detection")
      logger.info("=" * 80)

      # 1. Quote Stuffing Detector (HFT manipulation detection)
      try:
        from backend.ml_engine.detection.quote_stuffing_detector import (
          QuoteStuffingDetector, QuoteStuffingConfig
        )

        quote_stuffing_config = QuoteStuffingConfig()
        self.quote_stuffing_detector = QuoteStuffingDetector(quote_stuffing_config)
        logger.info("‚úÖ QuoteStuffingDetector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
      except Exception as e:
        logger.warning(f"‚ö†Ô∏è  QuoteStuffingDetector –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        self.quote_stuffing_detector = None

      # 2. Historical Pattern Database (PostgreSQL)
      try:
        from backend.ml_engine.detection.pattern_database import HistoricalPatternDatabase

        self.pattern_database = HistoricalPatternDatabase()
        # Initialize async (load cache from DB)
        await self.pattern_database.initialize()
        logger.info("‚úÖ HistoricalPatternDatabase –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (PostgreSQL)")
      except Exception as e:
        logger.warning(f"‚ö†Ô∏è  HistoricalPatternDatabase –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        self.pattern_database = None

      # 3. Layering Data Collector (for ML training)
      try:
        from backend.ml_engine.detection.layering_data_collector import LayeringDataCollector

        # Enable in both ONLY_TRAINING and full mode
        data_collection_enabled = True  # Always collect data
        data_collector_path = "data/ml_training/layering"

        self.layering_data_collector = LayeringDataCollector(
          data_dir=data_collector_path,
          enabled=data_collection_enabled,
          auto_save_interval=100
        )

        if settings.ONLY_TRAINING:
          logger.info("‚úÖ LayeringDataCollector –∞–∫—Ç–∏–≤–µ–Ω (ONLY_TRAINING mode)")
        else:
          logger.info("‚úÖ LayeringDataCollector –∞–∫—Ç–∏–≤–µ–Ω (full trading mode)")

      except Exception as e:
        logger.warning(f"‚ö†Ô∏è  LayeringDataCollector –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        self.layering_data_collector = None

      # 4. Adaptive ML Model (load if exists)
      try:
        from backend.ml_engine.detection.adaptive_layering_model import AdaptiveLayeringModel

        model_path = "data/models/layering_adaptive_v1.pkl"
        self.adaptive_layering_model = AdaptiveLayeringModel(
          model_path=model_path if Path(model_path).exists() else None,
          enabled=True
        )

        if self.adaptive_layering_model.enabled:
          model_info = self.adaptive_layering_model.get_info()
          if model_info['trained']:
            logger.info(
              f"‚úÖ AdaptiveLayeringModel –∑–∞–≥—Ä—É–∂–µ–Ω: "
              f"samples={model_info['training_samples']}, "
              f"trained_at={model_info['trained_at']}"
            )
          else:
            logger.info("‚úÖ AdaptiveLayeringModel –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (untrained)")
        else:
          logger.info("‚ö†Ô∏è  AdaptiveLayeringModel –æ—Ç–∫–ª—é—á–µ–Ω (sklearn not available)")

      except Exception as e:
        logger.warning(f"‚ö†Ô∏è  AdaptiveLayeringModel –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        self.adaptive_layering_model = None

      logger.info("=" * 80)

      # ===== –°–æ–∑–¥–∞–µ–º LayeringDetector —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π =====
      logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Professional LayeringDetector —Å full ML integration...")
      self.layering_detector = LayeringDetector(
        config=self.layering_config,
        trade_managers=self.trade_managers,  # ‚Üê Execution analysis
        pattern_database=self.pattern_database,  # ‚Üê Historical learning
        data_collector=self.layering_data_collector,  # ‚Üê ML training data
        adaptive_model=self.adaptive_layering_model,  # ‚Üê Adaptive thresholds
        enable_ml_features=True
      )
      logger.info("‚úÖ LayeringDetector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –ø–æ–ª–Ω–æ–π ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π")

      # ========== 10. ML FEATURE PIPELINE - –°–û–ó–î–ê–ù–ò–ï –î–õ–Ø –§–ò–ù–ê–õ–¨–ù–´–• –°–ò–ú–í–û–õ–û–í ==========
      # –í–ê–ñ–ù–û: –°–æ–∑–¥–∞–µ—Ç—Å—è –ü–û–°–õ–ï trade_managers –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö market trades
      logger.info("–°–æ–∑–¥–∞–Ω–∏–µ ML Feature Pipeline —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π market trades...")
      self.ml_feature_pipeline = MultiSymbolFeaturePipeline(
        symbols=self.symbols,  # ‚Üê –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã!
        normalize=True,
        cache_enabled=True,
        trade_managers=self.trade_managers  # ‚Üê –ü–µ—Ä–µ–¥–∞–µ–º TradeManagers –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö trades
      )
      logger.info(f"‚úì ML Feature Pipeline —Å–æ–∑–¥–∞–Ω –¥–ª—è {len(self.symbols)} —Å–∏–º–≤–æ–ª–æ–≤ —Å real trades support")

      # ===== –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä—ã —Å–≤–µ—á–µ–π –¥–ª—è –§–ò–ù–ê–õ–¨–ù–´–• –ø–∞—Ä =====
      logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ —Å–≤–µ—á–µ–π –¥–ª—è {len(self.symbols)} –ø–∞—Ä...")
      for symbol in self.symbols:
        self.candle_managers[symbol] = CandleManager(
          symbol=symbol,
          timeframe="1m",
          max_candles=200
        )
      logger.info(f"‚úì –°–æ–∑–¥–∞–Ω–æ {len(self.candle_managers)} –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ —Å–≤–µ—á–µ–π")

      # ========== 11. MARKET ANALYZER - –î–û–ë–ê–í–õ–ï–ù–ò–ï –°–ò–ú–í–û–õ–û–í ==========
      for symbol in self.symbols:
        self.market_analyzer.add_symbol(symbol)
      logger.info(f"‚úì {len(self.symbols)} —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä")

      # ========== 12. POSITION MONITOR - –°–û–ó–î–ê–ù–ò–ï ==========

      # –ù–û–í–û–ï: –°–æ–∑–¥–∞–Ω–∏–µ Position Monitor (–ü–û–°–õ–ï —Å–æ–∑–¥–∞–Ω–∏—è –≤—Å–µ—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤)
      # –í–ê–ñ–ù–û: –°–æ–∑–¥–∞–µ–º –ü–û–°–õ–ï —Ç–æ–≥–æ, –∫–∞–∫ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã:
      # - risk_manager ‚úì (—Å–æ–∑–¥–∞–Ω –≤ –Ω–∞—á–∞–ª–µ start)
      # - execution_manager ‚úì (—Å–æ–∑–¥–∞–Ω –≤ –Ω–∞—á–∞–ª–µ start)
      # - orderbook_managers ‚úì (—Å–æ–∑–¥–∞–Ω—ã –≤—ã—à–µ)
      # - candle_managers ‚úì (—Å–æ–∑–¥–∞–Ω—ã –≤—ã—à–µ)
      logger.info("–°–æ–∑–¥–∞–Ω–∏–µ Position Monitor...")

      # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
      if not self.risk_manager:
        raise RuntimeError("RiskManager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
      if not self.execution_manager:
        raise RuntimeError("ExecutionManager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
      if not self.orderbook_managers:
        raise RuntimeError("OrderBookManagers –Ω–µ —Å–æ–∑–¥–∞–Ω—ã")
      if not self.candle_managers:
        raise RuntimeError("CandleManagers –Ω–µ —Å–æ–∑–¥–∞–Ω—ã")

      self.position_monitor = PositionMonitor(
        risk_manager=self.risk_manager,
        candle_managers=self.candle_managers,
        orderbook_managers=self.orderbook_managers,
        execution_manager=self.execution_manager,
        trade_managers=self.trade_managers
      )

      logger.info(
        f"‚úì Position Monitor —Å–æ–∑–¥–∞–Ω —Å {len(self.candle_managers)} candle managers, "
        f"{len(self.orderbook_managers)} orderbook managers –∏ "
        f"{len(self.trade_managers)} trade managers"
      )

      # ========== 13. WEBSOCKET MANAGER - –°–û–ó–î–ê–ù–ò–ï –ò –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï ==========

      logger.info("–°–æ–∑–¥–∞–Ω–∏–µ WebSocket Manager...")
      logger.info(f"–°–∏–º–≤–æ–ª—ã –¥–ª—è WebSocket: {self.symbols[:5]}..." if len(
        self.symbols) > 5 else f"–°–∏–º–≤–æ–ª—ã –¥–ª—è WebSocket: {self.symbols}")

      self.websocket_manager = BybitWebSocketManager(
        symbols=self.symbols,  # ‚Üê –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã!
        on_message=self._handle_websocket_message  # Unified handler for orderbook & trades
      )
      logger.info("‚úì WebSocket –º–µ–Ω–µ–¥–∂–µ—Ä —Å–æ–∑–¥–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏")

      # ========== 14. HISTORICAL CANDLES - –ó–ê–ì–†–£–ó–ö–ê ==========

      await self._load_historical_candles()
      logger.info("‚úì –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

      # ========== 15. WEBSOCKET CONNECTIONS - –ó–ê–ü–£–°–ö ==========

      self.websocket_task = asyncio.create_task(
        self.websocket_manager.start()
      )
      logger.info("‚úì WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω—ã")

      # ========== 16. CANDLE UPDATE LOOP - –ó–ê–ü–£–°–ö ==========

      self.candle_update_task = asyncio.create_task(
        self._candle_update_loop()
      )
      logger.info("‚úì –¶–∏–∫–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π –∑–∞–ø—É—â–µ–Ω")

      # ========== 17. ML STATS LOOP - –ó–ê–ü–£–°–ö ==========

      self.ml_stats_task = asyncio.create_task(
        self._ml_stats_loop()
      )

      # ========== 17a. LAYERING ML DATA SAVE LOOP - –ó–ê–ü–£–°–ö ==========
      if hasattr(self, 'layering_data_collector') and self.layering_data_collector:
        self.layering_save_task = asyncio.create_task(
          self._layering_ml_save_loop()
        )
        logger.info("‚úì –¶–∏–∫–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Layering ML data –∑–∞–ø—É—â–µ–Ω")

      self.running = True  # ‚úÖ –£–°–¢–ê–ù–û–í–ò–¢–¨ –§–õ–ê–ì
      logger.info("‚úÖ Running flag —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: True")

      # ========== 18. ANALYSIS LOOP - –ó–ê–ü–£–°–ö ==========

      self.analysis_task = asyncio.create_task(
        self._analysis_loop_ml_enhanced()
      )
      logger.info("‚úì –¶–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ (ML-Enhanced) –∑–∞–ø—É—â–µ–Ω")
      # try:
      #   await ml_data_collection_loop(
      #     bot_controller=self,
      #     symbols=self.symbols,
      #     analysis_interval=settings.ANALYSIS_INTERVAL
      #   )
      # except Exception as e:
      #   logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
      # finally:
      #   await self.stop()

      # ========== 19. POSITION MONITOR - –ó–ê–ü–£–°–ö ==========

      # ========== –ó–ê–ü–£–°–ö POSITION MONITOR ==========
      # –í–ê–ñ–ù–û: –ó–∞–ø—É—Å–∫–∞–µ–º –ü–û–°–õ–ï analysis_task, —Ç–∞–∫ –∫–∞–∫:
      # 1. analysis_loop –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã
      # 2. execution_manager –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –ø–æ–∑–∏—Ü–∏–∏
      # 3. position_monitor –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç –æ—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏

      if self.position_monitor:
        await self.position_monitor.start()
        logger.info("‚úì Position Monitor –∑–∞–ø—É—â–µ–Ω")

      # ========== 20. FSM CLEANUP TASK - –ó–ê–ü–£–°–ö ==========

      asyncio.create_task(fsm_cleanup_task())
      logger.info("‚úì FSM Cleanup Task –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω")

      # ========== 21. SYMBOLS REFRESH (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) - –ó–ê–ü–£–°–ö ==========
      if settings.DYNAMIC_SYMBOLS_ENABLED and self.dynamic_symbols_manager:
        logger.info("–ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –ø–∞—Ä...")
        self.symbols_refresh_task = asyncio.create_task(
          self._symbols_refresh_loop()
        )
        logger.info("‚úì –ó–∞–¥–∞—á–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –ø–∞—Ä –∑–∞–ø—É—â–µ–Ω–∞")

      # ========== 22. CORRELATION UPDATE - –ó–ê–ü–£–°–ö ==========
      if correlation_manager.enabled:
        logger.info("–ó–∞–ø—É—Å–∫ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π...")
        self.correlation_update_task = asyncio.create_task(
          self._correlation_update_loop()
        )
        logger.info("‚úì Correlation update task –∑–∞–ø—É—â–µ–Ω")

      logger.info("‚úì –ó–∞–ø—É—â–µ–Ω–æ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π")

      # ========== 23. TRAILING STOP MANAGER - –ó–ê–ü–£–°–ö ==========

      logger.info("–ó–∞–ø—É—Å–∫ Trailing Stop Manager...")
      # –û–±–Ω–æ–≤–ª—è–µ–º trailing_stop_manager —Å trade_managers –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π –ª–æ–≥–∏–∫–∏
      from backend.strategy.trailing_stop_manager import TrailingStopManager
      global trailing_stop_manager
      trailing_stop_manager.__init__(trade_managers=self.trade_managers)
      logger.info(f"‚úì Trailing Stop Manager –æ–±–Ω–æ–≤–ª–µ–Ω —Å {len(self.trade_managers)} trade managers")

      await trailing_stop_manager.start()

      # ===========23/5 –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ò–ú–í–û–õ–û–í –í MTF ==========
      logger.info("=" * 80)
      logger.info("–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ò–ú–í–û–õ–û–í –í MTF MANAGER")
      logger.info("=" * 80)

      success_count = 0
      failed_symbols = []

      for symbol in self.symbols:
        try:
          logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MTF –¥–ª—è {symbol}...")
          success = await self.mtf_manager.initialize_symbol(symbol)

          if success:
            success_count += 1
            logger.info(f"‚úÖ {symbol}: MTF –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
          else:
            failed_symbols.append(symbol)
            logger.error(f"‚ùå {symbol}: –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MTF")

        except Exception as e:
          failed_symbols.append(symbol)
          logger.error(f"‚ùå {symbol}: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MTF: {e}")

      logger.info("=" * 80)
      logger.info(
        f"MTF –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê: "
        f"‚úÖ {success_count} —É—Å–ø–µ—à–Ω–æ, ‚ùå {len(failed_symbols)} –æ—à–∏–±–æ–∫"
      )
      if failed_symbols:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {failed_symbols}")
      logger.info("=" * 80)

      # –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
      logger.info("üîç –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è MTF Manager:")
      logger.info(f"   - Initialized symbols: {self.mtf_manager._initialized_symbols}")
      logger.info(f"   - Symbols in coordinator: {list(self.mtf_manager.coordinator.candle_managers.keys())}")

      # ========== 24. –ó–ê–ü–£–°–ö ADAPTIVE WEIGHT OPTIMIZATION ==========

      # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
      self.weight_optimization_task = asyncio.create_task(
        self._weight_optimization_loop(),
        name="weight_optimization"
      )
      logger.info("‚úÖ Adaptive Weight Optimization –∑–∞–ø—É—â–µ–Ω")

      # ========== 25. –ó–ê–ü–£–°–ö MTF UPDATES ==========

      # Staggered –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
      self.mtf_update_task = asyncio.create_task(
        self._mtf_update_loop(),
        name="mtf_updates"
      )

      # –£–≤–µ–¥–æ–º–ª—è–µ–º —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥
      from backend.api.websocket import broadcast_bot_status
      await broadcast_bot_status("running", {
        "symbols": self.symbols,
        "integrated_mode": True,
        "adaptive_consensus_enabled": self.adaptive_consensus is not None,
        "mtf_enabled": self.mtf_manager is not None,
        "ml_enabled": True,
        "position_monitor_enabled": self.position_monitor.enabled if self.position_monitor else False,
        "message": "–ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω —Å ML –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π"
      })

      # ========== –í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø MTF –°–û–°–¢–û–Ø–ù–ò–Ø ==========
      logger.info("üîç –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è MTF Manager:")

      # –ü–æ–ª—É—á–∞–µ–º –æ–±–∞ —Å–ø–∏—Å–∫–∞
      initialized = self.mtf_manager._initialized_symbols
      coordinator_symbols = set(self.mtf_manager.coordinator.candle_managers.keys())

      logger.info(f"   - Initialized symbols: {initialized}")
      logger.info(f"   - Coordinator symbols: {coordinator_symbols}")

      # ‚úÖ –î–û–ë–ê–í–ò–¢–¨: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
      if initialized != coordinator_symbols:
        logger.critical("üö® –ù–ï–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –°–ü–ò–°–ö–û–í –°–ò–ú–í–û–õ–û–í!")

        only_in_initialized = initialized - coordinator_symbols
        only_in_coordinator = coordinator_symbols - initialized

        if only_in_initialized:
          logger.error(f"   ‚ùå –¢–æ–ª—å–∫–æ –≤ _initialized_symbols: {only_in_initialized}")

        if only_in_coordinator:
          logger.error(f"   ‚ùå –¢–æ–ª—å–∫–æ –≤ coordinator: {only_in_coordinator}")

        # –ú–æ–∂–Ω–æ –ª–∏–±–æ raise, –ª–∏–±–æ –æ—á–∏—Å—Ç–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        logger.warning("‚ö†Ô∏è –û—á–∏—Å—Ç–∫–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π...")

        # –£–¥–∞–ª—è–µ–º –∏–∑ _initialized_symbols —Å–∏–º–≤–æ–ª—ã –±–µ–∑ CandleManager
        for symbol in only_in_initialized:
          self.mtf_manager._initialized_symbols.remove(symbol)
          logger.warning(f"   üóëÔ∏è –£–¥–∞–ª–µ–Ω {symbol} –∏–∑ _initialized_symbols")

      else:
        logger.info("‚úÖ –°–ø–∏—Å–∫–∏ —Å–∏–º–≤–æ–ª–æ–≤ —Å–æ–≤–ø–∞–¥–∞—é—Ç!")

      self.watchdog_task = asyncio.create_task(
        self._analysis_loop_watchdog()
      )
      logger.info("‚úì Analysis Loop Watchdog –∑–∞–ø—É—â–µ–Ω")

      self.status = BotStatus.RUNNING
      logger.info("=" * 80)
      logger.info("–ë–û–¢ –£–°–ü–ï–®–ù–û –ó–ê–ü–£–©–ï–ù (ML-READY)")
      logger.info("=" * 80)

    except Exception as e:
      self.status = BotStatus.ERROR
      logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞: {e}")
      log_exception(logger, e, "–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞")
      raise

  async def _symbols_refresh_loop(self):
    """
    –¶–∏–∫–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä.
    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ DYNAMIC_REFRESH_INTERVAL —Å–µ–∫—É–Ω–¥.
    """
    interval = settings.DYNAMIC_REFRESH_INTERVAL
    logger.info(f"–ó–∞–ø—É—â–µ–Ω symbols refresh loop (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {interval}s)")

    # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—é
    await asyncio.sleep(interval)

    while self.status == BotStatus.RUNNING:
      try:
        logger.info("=" * 60)
        logger.info("–û–ë–ù–û–í–õ–ï–ù–ò–ï –°–ü–ò–°–ö–ê –¢–û–†–ì–û–í–´–• –ü–ê–†")

        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç screener
        screener_pairs = self.screener_manager.get_all_pairs()

        # –û—Ç–±–∏—Ä–∞–µ–º –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        new_symbols = self.dynamic_symbols_manager.select_symbols(screener_pairs)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        changes = self.dynamic_symbols_manager.get_changes(new_symbols)
        added = changes['added']
        removed = changes['removed']

        if not added and not removed:
          logger.info("‚úì –°–ø–∏—Å–æ–∫ –ø–∞—Ä –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è")
        else:
          logger.info(f"–ò–∑–º–µ–Ω–µ–Ω–∏—è: +{len(added)} -{len(removed)}")

          # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –ø–∞—Ä—ã
          for symbol in added:
            logger.info(f"  + –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä—ã: {symbol}")
            self.orderbook_managers[symbol] = OrderBookManager(symbol)
            self.trade_managers[symbol] = TradeManager(symbol, max_history=5000, enable_statistics=True)
            self.candle_managers[symbol] = CandleManager(symbol, "1m", 200)
            self.market_analyzer.add_symbol(symbol)

          # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –ø–∞—Ä—ã
          for symbol in removed:
            logger.info(f"  - –£–¥–∞–ª–µ–Ω–∏–µ –ø–∞—Ä—ã: {symbol}")
            if symbol in self.orderbook_managers:
              del self.orderbook_managers[symbol]
            if symbol in self.trade_managers:
              del self.trade_managers[symbol]
            if symbol in self.candle_managers:
              del self.candle_managers[symbol]

          # –û–±–Ω–æ–≤–ª—è–µ–º LayeringDetector trade_managers –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
          if self.layering_detector and (added or removed):
            self.layering_detector.trade_managers = self.trade_managers
            logger.info(f"‚úÖ LayeringDetector –æ–±–Ω–æ–≤–ª–µ–Ω: {len(self.trade_managers)} TradeManagers")

          # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫
          self.symbols = new_symbols

          # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
          logger.info("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ WebSocket —Å –Ω–æ–≤—ã–º —Å–ø–∏—Å–∫–æ–º –ø–∞—Ä...")
          if self.websocket_task:
            self.websocket_task.cancel()
            try:
              await self.websocket_task
            except asyncio.CancelledError:
              pass

          # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º WebSocket –º–µ–Ω–µ–¥–∂–µ—Ä
          self.websocket_manager = BybitWebSocketManager(
            symbols=self.symbols,
            on_message=self._handle_websocket_message  # Unified handler
          )
          self.websocket_task = asyncio.create_task(
            self.websocket_manager.start()
          )
          logger.info("‚úì WebSocket –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω")

        logger.info("=" * 60)
        await asyncio.sleep(interval)

      except asyncio.CancelledError:
        logger.info("Symbols refresh loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        break
      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ symbols refresh loop: {e}")
        import traceback
        logger.error(f"Traceback:\n{traceback.format_exc()}")
        await asyncio.sleep(interval)

  async def _load_historical_candles(self):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–≤–µ—á–µ–π –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤.

    –£–ª—É—á—à–µ–Ω–∏—è:
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º concurrency
    - Timeout –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    - –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    - Retry logic –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    - Graceful degradation (–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–∞–∂–µ –µ—Å–ª–∏ –∫–∞–∫–∏–µ-—Ç–æ —Å–∏–º–≤–æ–ª—ã –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å)
    """
    logger.info("=" * 80)
    logger.info("–ó–ê–ì–†–£–ó–ö–ê –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –°–í–ï–ß–ï–ô")
    logger.info(f"–í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(self.symbols)}")
    logger.info("=" * 80)

    # –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    # Bybit API –∏–º–µ–µ—Ç rate limit ~50 requests/second
    semaphore = asyncio.Semaphore(5)  # –ú–∞–∫—Å–∏–º—É–º 5 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

    # –°—á–µ—Ç—á–∏–∫–∏
    loaded_count = 0
    failed_symbols = []

    async def load_symbol_candles(symbol: str, index: int) -> bool:
      """
      –ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–µ—á–µ–π –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.

      Returns:
          True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
      """
      nonlocal loaded_count

      async with semaphore:
        retry_count = 0
        max_retries = 3

        while retry_count < max_retries:
          try:
            # Timeout –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ - 10 —Å–µ–∫—É–Ω–¥
            candles_data = await asyncio.wait_for(
              rest_client.get_kline(
                symbol=symbol,
                interval="1",
                limit=200
              ),
              timeout=10.0
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ
            if not candles_data or len(candles_data) == 0:
              logger.warning(
                f"[{index + 1}/{len(self.symbols)}] {symbol} | "
                f"‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API"
              )
              return False

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ CandleManager
            candle_manager = self.candle_managers[symbol]
            await candle_manager.load_historical_data(candles_data)

            # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—Ö
            loaded_count += 1
            logger.info(
              f"[{index + 1}/{len(self.symbols)}] {symbol} | "
              f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(candles_data)} —Å–≤–µ—á–µ–π "
              f"(–ø—Ä–æ–≥—Ä–µ—Å—Å: {loaded_count}/{len(self.symbols)})"
            )

            return True

          except asyncio.TimeoutError:
            retry_count += 1
            logger.warning(
              f"[{index + 1}/{len(self.symbols)}] {symbol} | "
              f"‚è±Ô∏è  Timeout (–ø–æ–ø—ã—Ç–∫–∞ {retry_count}/{max_retries})"
            )

            if retry_count < max_retries:
              # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: 1s, 2s, 4s
              await asyncio.sleep(2 ** (retry_count - 1))

          except Exception as e:
            retry_count += 1
            logger.warning(
              f"[{index + 1}/{len(self.symbols)}] {symbol} | "
              f"‚ùå –û—à–∏–±–∫–∞: {e} (–ø–æ–ø—ã—Ç–∫–∞ {retry_count}/{max_retries})"
            )

            if retry_count < max_retries:
              await asyncio.sleep(2)

        # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        logger.error(
          f"[{index + 1}/{len(self.symbols)}] {symbol} | "
          f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫"
        )
        failed_symbols.append(symbol)
        return False

    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
    tasks = [
      load_symbol_candles(symbol, i)
      for i, symbol in enumerate(self.symbols)
    ]

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    try:
      # –û–±—â–∏–π timeout –¥–ª—è –≤—Å–µ–π –∑–∞–≥—Ä—É–∑–∫–∏ - 2 –º–∏–Ω—É—Ç—ã
      results = await asyncio.wait_for(
        asyncio.gather(*tasks, return_exceptions=True),
        timeout=120.0
      )

      # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
      success_count = sum(1 for r in results if r is True)

      logger.info("=" * 80)
      logger.info(f"‚úì –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê: {success_count}/{len(self.symbols)} —É—Å–ø–µ—à–Ω–æ")

      if failed_symbols:
        logger.warning(
          f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {len(failed_symbols)} —Å–∏–º–≤–æ–ª–æ–≤: "
          f"{', '.join(failed_symbols[:5])}"
          f"{'...' if len(failed_symbols) > 5 else ''}"
        )

      logger.info("=" * 80)

    except asyncio.TimeoutError:
      logger.error(
        f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û–±—â–∏–π timeout –∑–∞–≥—Ä—É–∑–∫–∏ (120s) –∏—Å—Ç–µ–∫! "
        f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {loaded_count}/{len(self.symbols)}"
      )

      # –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ—Ç–∞ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Ç–µ–º, —á—Ç–æ –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å
      logger.warning("‚ö†Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")

    except Exception as e:
      logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –∑–∞–≥—Ä—É–∑–∫–∏ —Å–≤–µ—á–µ–π: {e}")
      import traceback
      logger.error(f"Traceback:\n{traceback.format_exc()}")

      # –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ—Ç–∞ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Ç–µ–º, —á—Ç–æ –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å
      logger.warning("‚ö†Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")

  async def _candle_update_loop(self):
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–µ—á–µ–π —á–µ—Ä–µ–∑ REST API.
    –û–±–Ω–æ–≤–ª—è–µ—Ç CandleManager –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å–≤–µ—á—É.

    –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    1. –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ (str ‚Üí float)
    2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ load_historical_data –≤–º–µ—Å—Ç–æ update_candle
    3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –æ—à–∏–±–æ–∫ –±–µ–∑ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ü–∏–∫–ª–∞
    """
    logger.info("–ó–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π (–∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥)")

    error_counts = {}  # –°—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
    max_errors = 5  # –ú–∞–∫—Å–∏–º—É–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫
    cycle_number = 0


    while self.running:
      cycle_number += 1

      try:
        symbols = list(self.candle_managers.keys())

        for symbol in symbols:
          # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á–µ—Ç—á–∏–∫–∞ –æ—à–∏–±–æ–∫
          if symbol not in error_counts:
            error_counts[symbol] = 0

          # –ü—Ä–æ–ø—É—Å–∫ —Å–∏–º–≤–æ–ª–∞ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –æ—à–∏–±–∫–∞–º–∏
          if error_counts[symbol] >= max_errors:
            if cycle_number % 20 == 0:  # –õ–æ–≥ –∫–∞–∂–¥—ã–µ 20 —Ü–∏–∫–ª–æ–≤
              logger.warning(
                f"‚ö†Ô∏è [{symbol}] –ü—Ä–æ–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: "
                f"{error_counts[symbol]} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫"
              )
            continue

          try:
            # ============================================================
            # 1. –°–û–•–†–ê–ù–ï–ù–ò–ï –ü–†–ï–î–´–î–£–©–ï–ô –°–í–ï–ß–ò (–î–û –û–ë–ù–û–í–õ–ï–ù–ò–Ø)
            # ============================================================
            candle_manager = self.candle_managers[symbol]

            candles = candle_manager.get_candles()
            if candles and len(candles) >= 2:
              # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–∫—Ä—ã—Ç—É—é —Å–≤–µ—á—É (–ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω—é—é)
              prev_candle = candles[-2]
              self.prev_candles[symbol] = prev_candle
              self.last_candle_update[symbol] = prev_candle.timestamp

              logger.debug(
                f"[{symbol}] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Å–≤–µ—á–∞: "
                f"close={prev_candle.close:.2f}"
              )

            # ============================================================
            # 2. –ü–û–õ–£–ß–ï–ù–ò–ï –°–í–ï–ñ–ò–• –î–ê–ù–ù–´–• –° –ë–ò–†–ñ–ò
            # ============================================================
            candles_data = await rest_client.get_kline(
              symbol=symbol,
              interval="1",  # 1 –º–∏–Ω—É—Ç–∞
              limit=2  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Å–≤–µ—á–∏
            )

            if not candles_data or len(candles_data) < 2:
              logger.warning(f"[{symbol}] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π –æ—Ç –±–∏—Ä–∂–∏")
              continue

            # ============================================================
            # 3. –ë–ï–ó–û–ü–ê–°–ù–û–ï –û–ë–ù–û–í–õ–ï–ù–ò–ï –ß–ï–†–ï–ó load_historical_data
            # ============================================================
            # ‚úÖ –ò–°–ü–û–õ–¨–ó–£–ï–ú load_historical_data - –û–ù –£–ñ–ï –û–ë–†–ê–ë–ê–¢–´–í–ê–ï–¢ –í–°–ï –§–û–†–ú–ê–¢–´
            await candle_manager.load_historical_data(candles_data)

            # ============================================================
            # 4. –ë–ï–ó–û–ü–ê–°–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï (—Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º —Ç–∏–ø–æ–≤)
            # ============================================================
            closed_candle = candles_data[-2]
            current_candle = candles_data[-1]

            try:
              # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö
              if isinstance(closed_candle, list):
                # –§–æ—Ä–º–∞—Ç: [timestamp, open, high, low, close, volume, turnover]
                if len(closed_candle) > 4:
                  # ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û–ï –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ float
                  closed_price = float(closed_candle[4])
                  current_price = float(current_candle[4])

                  logger.debug(
                    f"[{symbol}] –°–≤–µ—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã (list): "
                    f"closed={closed_price:.2f}, "
                    f"current={current_price:.2f}"
                  )

              elif isinstance(closed_candle, dict):
                # –§–æ—Ä–º–∞—Ç: {'timestamp': ..., 'close': ...}
                # ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û–ï –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: str ‚Üí float
                closed_value = closed_candle.get('close', '0')
                current_value = current_candle.get('close', '0')

                closed_price = float(closed_value)
                current_price = float(current_value)

                logger.debug(
                  f"[{symbol}] –°–≤–µ—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã (dict): "
                  f"closed={closed_price:.2f}, "
                  f"current={current_price:.2f}"
                )
              else:
                logger.debug(
                  f"[{symbol}] –°–≤–µ—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã "
                  f"(–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {type(closed_candle)})"
                )

            except (ValueError, TypeError) as e:
              # –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
              logger.debug(
                f"[{symbol}] –°–≤–µ—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã "
                f"(–æ—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ª–æ–≥–∞: {e})"
              )

            # ‚úÖ –£–°–ü–ï–• - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
            error_counts[symbol] = 0

          except Exception as e:
            # ============================================================
            # –û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–ö–ò –î–õ–Ø –ö–û–ù–ö–†–ï–¢–ù–û–ì–û –°–ò–ú–í–û–õ–ê
            # ============================================================
            error_counts[symbol] += 1

            logger.error(
              f"‚ùå [{symbol}] –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π "
              f"(#{error_counts[symbol]}/{max_errors}): {e}"
            )

            # –î–µ—Ç–∞–ª—å–Ω—ã–π traceback —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–π –æ—à–∏–±–∫–∏
            if error_counts[symbol] == 1:
              logger.error(f"Traceback:\n{traceback.format_exc()}")

            # ‚úÖ –ü–†–û–î–û–õ–ñ–ê–ï–ú –†–ê–ë–û–¢–£ (–ù–ï –û–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú –¶–ò–ö–õ)
            continue

        # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–µ–π
        await asyncio.sleep(5)

      except asyncio.CancelledError:
        # Graceful shutdown
        logger.info("üõë –¶–∏–∫–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (CancelledError)")
        break

      except Exception as e:
        # ============================================================
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê - –ù–û –ü–†–û–î–û–õ–ñ–ê–ï–ú –†–ê–ë–û–¢–£
        # ============================================================
        logger.error(
          f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –æ—à–∏–±–∫–∞ –≤ candle_update_loop: {e}",
          exc_info=True
        )
        # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
        await asyncio.sleep(10)

    logger.warning("‚ö†Ô∏è –¶–∏–∫–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω")

  async def _analysis_loop_ml_enhanced(self):
    """
    === –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ü–¢–ò–ú–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø ===

    –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π —Å–∏—Å—Ç–µ–º—ã.

    –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ò–ù–¢–ï–ì–†–ê–¶–ò–ò:
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    –§–∞–∑–∞ 1: OrderBook-Aware Strategies
    ‚îú‚îÄ‚îÄ ExtendedStrategyManager
    ‚îú‚îÄ‚îÄ CANDLE strategies (momentum, sar_wave, supertrend, volume_profile)
    ‚îú‚îÄ‚îÄ ORDERBOOK strategies (imbalance, volume_flow, liquidity_zone)
    ‚îî‚îÄ‚îÄ HYBRID strategies (smart_money)

    –§–∞–∑–∞ 2: Adaptive Consensus Management
    ‚îú‚îÄ‚îÄ StrategyPerformanceTracker - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    ‚îú‚îÄ‚îÄ MarketRegimeDetector - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
    ‚îú‚îÄ‚îÄ WeightOptimizer - –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
    ‚îî‚îÄ‚îÄ Continuous learning —á–µ—Ä–µ–∑ signal outcomes

    –§–∞–∑–∞ 3: Multi-Timeframe Analysis
    ‚îú‚îÄ‚îÄ TimeframeCoordinator - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–≤–µ—á–∞–º–∏ –Ω–∞ 4+ TF
    ‚îú‚îÄ‚îÄ TimeframeAnalyzer - –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ TF –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
    ‚îú‚îÄ‚îÄ TimeframeAligner - –ø—Ä–æ–≤–µ—Ä–∫–∞ alignment –∏ confluence
    ‚îî‚îÄ‚îÄ TimeframeSignalSynthesizer - —Å–∏–Ω—Ç–µ–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞

    –§–∞–∑–∞ 4: Integrated Analysis Engine
    ‚îú‚îÄ‚îÄ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∞–∑
    ‚îú‚îÄ‚îÄ 4 —Ä–µ–∂–∏–º–∞: SINGLE_TF_ONLY, MTF_ONLY, HYBRID, ADAPTIVE
    ‚îú‚îÄ‚îÄ Intelligent fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã
    ‚îî‚îÄ‚îÄ Comprehensive quality control

    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    WORKFLOW (Per Symbol):
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ 1. Market Data Collection                                          ‚îÇ
    ‚îÇ    ‚îú‚îÄ OrderBook Snapshot                                           ‚îÇ
    ‚îÇ    ‚îú‚îÄ Candles (Single TF + MTF if enabled)                        ‚îÇ
    ‚îÇ    ‚îú‚îÄ OrderBook Metrics                                            ‚îÇ
    ‚îÇ    ‚îî‚îÄ Market Metrics                                               ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 2. Manipulation Detection (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)                          ‚îÇ
    ‚îÇ    ‚îú‚îÄ Spoofing Detector                                            ‚îÇ
    ‚îÇ    ‚îî‚îÄ Layering Detector                                            ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 3. S/R Levels Detection & Update (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)                   ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 4. ML Feature Extraction                                           ‚îÇ
    ‚îÇ    ‚îî‚îÄ 110+ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤                            ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 5. üéØ INTEGRATED ANALYSIS (–Ø–î–†–û –°–ò–°–¢–ï–ú–´)                          ‚îÇ
    ‚îÇ    ‚îî‚îÄ IntegratedEngine.analyze()                                   ‚îÇ
    ‚îÇ       ‚îú‚îÄ Single-TF Analysis (–§–∞–∑–∞ 1 + –§–∞–∑–∞ 2)                     ‚îÇ
    ‚îÇ       ‚îÇ   ‚îú‚îÄ ExtendedStrategyManager                               ‚îÇ
    ‚îÇ       ‚îÇ   ‚îî‚îÄ AdaptiveConsensusManager (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)               ‚îÇ
    ‚îÇ       ‚îú‚îÄ MTF Analysis (–§–∞–∑–∞ 3, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)                      ‚îÇ
    ‚îÇ       ‚îÇ   ‚îî‚îÄ MultiTimeframeManager                                 ‚îÇ
    ‚îÇ       ‚îî‚îÄ Signal Synthesis (–§–∞–∑–∞ 4)                                 ‚îÇ
    ‚îÇ           ‚îú‚îÄ Conflict Resolution                                   ‚îÇ
    ‚îÇ           ‚îú‚îÄ Quality Scoring                                       ‚îÇ
    ‚îÇ           ‚îî‚îÄ Risk Assessment                                       ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 6. ML Validation —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)                ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 7. Quality & Risk Checks                                           ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 8. Signal Metadata Enrichment                                      ‚îÇ
    ‚îÇ    ‚îî‚îÄ S/R context, contributing strategies, timestamps             ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 9. Execution Submission                                            ‚îÇ
    ‚îÇ    ‚îî‚îÄ ExecutionManager.submit_signal()                             ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 10. Drift Monitoring (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)                               ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 11. ML Data Collection –¥–ª—è –æ–±—É—á–µ–Ω–∏—è                                ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 12. Real-time Broadcasting –∫ UI (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)                    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    ERROR HANDLING:
    - Per-symbol error counter —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º skip
    - Fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ
    - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–æ–≤
    - Graceful degradation (—Ä–∞–±–æ—Ç–∞ –¥–∞–∂–µ –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö –º–æ–¥—É–ª—è—Ö)

    PERFORMANCE:
    - –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤
    - Intelligent caching
    - Performance tracking –∏ warning –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–æ–≤
    - –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–∫–∞–∂–¥—ã–µ 100 —Ü–∏–∫–ª–æ–≤)

    –ü–†–ò–ú–ï–ß–ê–ù–ò–ï:
    - –§—É–Ω–∫—Ü–∏—è —Å–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã –¥–∞–∂–µ –ø—Ä–∏ —á–∞—Å—Ç–∏—á–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö –º–æ–¥—É–ª—è—Ö
    - Feature flags –ø–æ–∑–≤–æ–ª—è—é—Ç –≥–∏–±–∫–æ —É–ø—Ä–∞–≤–ª—è—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
    - –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏–º–µ—é—Ç try-catch –æ–±—Ä–∞–±–æ—Ç–∫—É
    """
    # –î–ï–ë–ê–ì: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ –º–µ—Ç–æ–¥–∞
    try:
      logger.info("=" * 80)
      logger.info("üöÄ ANALYSIS LOOP –ú–ï–¢–û–î –í–´–ó–í–ê–ù - –ù–ê–ß–ê–õ–û –í–´–ü–û–õ–ù–ï–ù–ò–Ø")
      logger.info(f"   self.status = {self.status}")
      logger.info(f"   self.symbols = {len(self.symbols) if hasattr(self, 'symbols') else '–ù–ï–¢'}")
      logger.info("=" * 80)
    except Exception as init_error:
      logger.error(f"–û–®–ò–ë–ö–ê –ü–†–ò –ù–ê–ß–ê–õ–¨–ù–û–ú –õ–û–ì–ò–†–û–í–ê–ù–ò–ò: {init_error}", exc_info=True)
      return

    try:
      from backend.models.signal import TradingSignal, SignalType, SignalStrength, SignalSource
      from datetime import datetime
      import traceback

      logger.info("‚úÖ –ò–º–ø–æ—Ä—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
    except Exception as import_error:
      logger.error(f"–û–®–ò–ë–ö–ê –ü–†–ò –ò–ú–ü–û–†–¢–ï: {import_error}", exc_info=True)
      return
    import traceback

    # ========================================================================
    # –ë–õ–û–ö 1: –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ü–û–î–ì–û–¢–û–í–ö–ê
    # ========================================================================

    logger.info("=" * 80)
    logger.info("üöÄ ANALYSIS LOOP –ó–ê–ü–£–©–ï–ù (–§–ò–ù–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø)")
    logger.info("=" * 80)
    logger.info(f"üìä –†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞: {settings.INTEGRATED_ANALYSIS_MODE}")
    logger.info(f"üéì –†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è (ONLY_TRAINING): {'‚úÖ –í–ö–õ–Æ–ß–ï–ù - —Ç–æ–ª—å–∫–æ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö' if settings.ONLY_TRAINING else '‚ùå –í–´–ö–õ–Æ–ß–ï–ù - –ø–æ–ª–Ω–∞—è —Ä–∞–±–æ—Ç–∞'}")
    logger.info(f"‚è±Ô∏è –ò–Ω—Ç–µ—Ä–≤–∞–ª –∞–Ω–∞–ª–∏–∑–∞: {settings.ANALYSIS_INTERVAL}—Å")
    logger.info(
      f"üìà –¢–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ä—ã: {len(self.symbols)} ({', '.join(self.symbols[:5])}{'...' if len(self.symbols) > 5 else ''})")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    has_strategy_manager = self.strategy_manager is not None
    has_adaptive_consensus = self.adaptive_consensus is not None
    has_mtf_manager = self.mtf_manager is not None
    has_integrated_engine = self.integrated_engine is not None
    has_ml_validator = self.ml_validator is not None
    has_ml_feature_pipeline = self.ml_feature_pipeline is not None
    has_ml_data_collector = self.ml_data_collector is not None
    has_sr_detector = self.sr_detector is not None
    has_spoofing_detector = hasattr(self, 'spoofing_detector') and self.spoofing_detector
    has_layering_detector = hasattr(self, 'layering_detector') and self.layering_detector
    has_drift_detector = hasattr(self, 'drift_detector') and self.drift_detector

    logger.info("üì¶ –°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:")
    logger.info(f"   ‚îú‚îÄ Strategy Manager: {'‚úÖ' if has_strategy_manager else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ Adaptive Consensus: {'‚úÖ' if has_adaptive_consensus else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ MTF Manager: {'‚úÖ' if has_mtf_manager else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ Integrated Engine: {'‚úÖ' if has_integrated_engine else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ ML Validator: {'‚úÖ' if has_ml_validator else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ ML Feature Pipeline: {'‚úÖ' if has_ml_feature_pipeline else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ ML Data Collector: {'‚úÖ' if has_ml_data_collector else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ S/R Detector: {'‚úÖ' if has_sr_detector else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ Spoofing Detector: {'‚úÖ' if has_spoofing_detector else '‚ùå'}")
    logger.info(f"   ‚îú‚îÄ Layering Detector: {'‚úÖ' if has_layering_detector else '‚ùå'}")
    logger.info(f"   ‚îî‚îÄ Drift Detector: {'‚úÖ' if has_drift_detector else '‚ùå'}")
    logger.info("=" * 80)

    # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: IntegratedEngine –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω (–∫—Ä–æ–º–µ —Ä–µ–∂–∏–º–∞ ONLY_TRAINING)
    if not has_integrated_engine and not settings.ONLY_TRAINING:
      logger.critical(
        "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: IntegratedEngine –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω! "
        "Analysis loop –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –Ω–µ–≥–æ (–µ—Å–ª–∏ –Ω–µ —Ä–µ–∂–∏–º ONLY_TRAINING)."
      )
      if settings.ENABLE_CRITICAL_ALERTS:
        await self._send_critical_alert(
          "IntegratedEngine –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
          "Analysis loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"
        )
      return

    # –í —Ä–µ–∂–∏–º–µ ONLY_TRAINING IntegratedEngine –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
    if settings.ONLY_TRAINING and not has_integrated_engine:
      logger.info("‚ÑπÔ∏è –†–µ–∂–∏–º ONLY_TRAINING: IntegratedEngine –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è, —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ —Å–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á–µ—Ç—á–∏–∫–æ–≤ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    error_count = {}  # –°—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
    max_consecutive_errors = 5  # –ú–∞–∫—Å–∏–º—É–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫ –ø–µ—Ä–µ–¥ skip
    cycle_number = 0
    cleanup_counter = 0  # –ù–û–í–û–ï: –°—á–µ—Ç—á–∏–∫ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞)
    if not hasattr(self, 'stats') or not self.stats:
      self.stats = {
        'analysis_cycles': 0,
        'signals_generated': 0,
        'signals_executed': 0,
        'orders_placed': 0,
        'positions_opened': 0,
        'positions_closed': 0,
        'total_pnl': 0.0,
        'consensus_achieved': 0,
        'consensus_failed': 0,
        'adaptive_weight_updates': 0,
        'mtf_signals': 0,
        'ml_validations': 0,
        'ml_data_collected': 0,
        'manipulations_detected': 0,
        'drift_detections': 0,
        'warnings': 0,
        'errors': 0
      }

    logger.info("‚úÖ Analysis Loop –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")

    # ========================================================================
    # –ë–õ–û–ö 2: –ì–õ–ê–í–ù–´–ô –¶–ò–ö–õ –ê–ù–ê–õ–ò–ó–ê
    # ========================================================================
    logger.info(
      f"üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –ø–µ—Ä–µ–¥ —Ü–∏–∫–ª–æ–º: self.status = {self.status}, BotStatus.RUNNING = {BotStatus.RUNNING}")
    logger.info(f"üîÑ –°—Ç–∞—Ç—É—Å —Å–æ–≤–ø–∞–¥–∞–µ—Ç: {self.status == BotStatus.RUNNING}")

    while self.status == BotStatus.RUNNING:
      cycle_start = time.time()
      cycle_number += 1

      cleanup_counter += 1

      # CRITICAL MEMORY FIX: Balanced cleanup to prevent memory growth while allowing ML data accumulation
      # Optimized for REAL cycle time (~3 sec, not 0.5 sec from config)
      # 360 cycles √ó 3 sec = 1080 sec = ~18 minutes
      # This allows ML buffers to accumulate ~60 samples (~15 min) before cleanup
      # Cleanup runs shortly after auto-save, providing additional safety
      if cleanup_counter >= 360:  # 360 cycles √ó ~3 sec = ~18 min
        logger.info("üßπ –ó–∞–ø—É—Å–∫ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏ (–∫–∞–∂–¥—ã–µ 360 —Ü–∏–∫–ª–æ–≤ = ~18 –º–∏–Ω)")
        await self._cleanup_memory()
        cleanup_counter = 0

      # –î–ï–ë–ê–ì: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —Ü–∏–∫–ª–∞ (–ø–µ—Ä–≤—ã–µ 5 —Ü–∏–∫–ª–æ–≤)
      if cycle_number <= 5:
        logger.info(f"üîÑ –¶–∏–∫–ª #{cycle_number} –Ω–∞—á–∞–ª—Å—è")

      if not self.websocket_manager.is_all_connected():
        if cycle_number <= 5:
          logger.info(f"‚è≥ –¶–∏–∫–ª #{cycle_number}: WebSocket –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω, –∂–¥—ë–º...")
        await asyncio.sleep(1)
        continue

      # –î–ï–ë–ê–ì: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —É—Å–ø–µ—à–Ω–æ–º –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ WebSocket
      if cycle_number == 1 or (cycle_number <= 5):
        logger.info(f"‚úÖ –¶–∏–∫–ª #{cycle_number}: WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ {len(self.symbols)} —Å–∏–º–≤–æ–ª–æ–≤")

      try:
        # async with self.analysis_lock:

        # –ñ–¥–µ–º –ø–æ–∫–∞ –≤—Å–µ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è
        # if not self.websocket_manager.is_all_connected():
        #   await asyncio.sleep(1)
        #   continue

        should_collect_ml_data_this_cycle = (
            has_ml_data_collector and
            self.ml_data_collector.should_collect()
        )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –ø–∞—Ä—É
        for symbol in self.symbols:
          symbol_start = time.time()

          if cycle_number <= 5:
            logger.info(f"  üîç [{symbol}] –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ü–∏–∫–ª–µ #{cycle_number}")

          # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è error counter –¥–ª—è —Å–∏–º–≤–æ–ª–∞
          if symbol not in error_count:
            error_count[symbol] = 0

          # –ü—Ä–æ–ø—É—Å–∫ —Å–∏–º–≤–æ–ª–∞ –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥
          if error_count[symbol] >= max_consecutive_errors:
            if cycle_number % 10 == 0:  # –õ–æ–≥ –∫–∞–∂–¥—ã–µ 10 —Ü–∏–∫–ª–æ–≤
              logger.warning(
                f"‚ö†Ô∏è [{symbol}] –ü—Ä–æ–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞: {error_count[symbol]} "
                f"–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫ (–ª–∏–º–∏—Ç: {max_consecutive_errors})"
              )
            continue

          try:
            # ============================================================
            # –®–ê–ì 1: –ü–û–õ–£–ß–ï–ù–ò–ï MARKET DATA
            # ============================================================

            # ob_manager = self.orderbook_managers[symbol]
            ob_manager = self.orderbook_managers.get(symbol)
            candle_manager = self.candle_managers[symbol]

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
            if not ob_manager.snapshot_received:
              if cycle_number <= 5:
                logger.info(f"  ‚è≠Ô∏è  [{symbol}] OrderBook snapshot –Ω–µ –ø–æ–ª—É—á–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
              continue

            # –ü–æ–ª—É—á–∞–µ–º —Å–Ω–∏–º–æ–∫ —Å—Ç–∞–∫–∞–Ω–∞
            orderbook_snapshot = ob_manager.get_snapshot()
            if not orderbook_snapshot:
              if cycle_number <= 5:
                logger.info(f"  ‚è≠Ô∏è  [{symbol}] OrderBook –Ω–µ –≥–æ—Ç–æ–≤ –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
              continue

            # –î–ï–ë–ê–ì: –ü—Ä–æ–≤–µ—Ä–∏–º snapshot –¥–µ—Ç–∞–ª—å–Ω–æ
            if cycle_number <= 5:
              best_bid = orderbook_snapshot.best_bid
              best_ask = orderbook_snapshot.best_ask
              mid_price_val = orderbook_snapshot.mid_price

              logger.info(
                f"  üîç [{symbol}] OrderBook snapshot debug: "
                f"bids_len={len(orderbook_snapshot.bids)}, "
                f"asks_len={len(orderbook_snapshot.asks)}"
              )
              logger.info(
                f"  üîç [{symbol}] Prices: "
                f"best_bid={best_bid}, "
                f"best_ask={best_ask}, "
                f"mid_price={mid_price_val}"
              )

              # –ü—Ä–æ–≤–µ—Ä–∏–º –ª–æ–≥–∏–∫—É –≤—Ä—É—á–Ω—É—é
              if best_bid and best_ask:
                manual_mid = (best_bid + best_ask) / 2
                logger.info(f"  üîç [{symbol}] Manual mid_price calculation: {manual_mid}")
              else:
                logger.warning(f"  ‚ö†Ô∏è  [{symbol}] best_bid or best_ask is falsy!")
                logger.warning(f"  ‚ö†Ô∏è  [{symbol}] best_bid bool: {bool(best_bid)}, best_ask bool: {bool(best_ask)}")

            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏
            candles = candle_manager.get_candles()
            if not candles or len(candles) < 50:
              if cycle_number <= 5:
                logger.info(
                  f"  ‚è≠Ô∏è  [{symbol}] –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–µ—á–µ–π: "
                  f"{len(candles) if candles else 0}/50"
                )
              continue

            current_price = orderbook_snapshot.mid_price
            # –î–ï–ë–ê–ì: –ü—Ä–æ–≤–µ—Ä–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ current_price –ø—Ä—è–º–æ –ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            if cycle_number <= 5:
              logger.info(
                f"  üîç [{symbol}] current_price –î–û –ø—Ä–æ–≤–µ—Ä–∫–∏: {current_price}, "
                f"type={type(current_price)}, is_None={current_price is None}"
              )

            if current_price is None:


              if cycle_number <= 5:
                logger.info(
                  f"  ‚è≠Ô∏è  [{symbol}] –ù–µ—Ç —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã: "
                  f"bids={len(orderbook_snapshot.bids)}, "
                  f"asks={len(orderbook_snapshot.asks)}, "
                  f"best_bid={orderbook_snapshot.best_bid}, "
                  f"best_ask={orderbook_snapshot.best_ask}"
                )
                continue

            # –î–ï–ë–ê–ì: –£—Å–ø–µ—à–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            if cycle_number <= 5:
              logger.info(
                f"  ‚úÖ [{symbol}] –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã: "
                f"price={current_price:.2f}, candles={len(candles)}"
              )
            # 1.3 OrderBook Metrics
            # orderbook_metrics = self.market_analyzer.analyze_symbol(symbol, ob_manager)
            #
            # # 1.4 Market Metrics
            # market_metrics = self.market_analyzer.analyze_symbol(
            #   symbol=symbol,
            #   candles=candles,
            #   orderbook=orderbook_snapshot
            # )

            orderbook_metrics = self.orderbook_analyzer.analyze(ob_manager)

            # 1.4 Market Metrics
            market_metrics = self.market_analyzer.analyze_symbol(
              symbol,
              ob_manager
            )

            market_volatility = None
            if hasattr(self, 'indicator_features') and self.indicator_features:
              # –í–∞—Ä–∏–∞–Ω—Ç 1: –ò–∑ ATR –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
              market_volatility = self.indicator_features.get('atr_normalized', None)
            elif hasattr(self, 'orderbook_features') and self.orderbook_features:
              # –í–∞—Ä–∏–∞–Ω—Ç 2: –ò–∑ OrderBook Feature Extractor
              market_volatility = self.orderbook_features.orderbook_volatility

            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ volatility
            volatility_str = f"{market_volatility:.4f}" if market_volatility is not None else "N/A"

            logger.debug(
              f"[{symbol}] Market Data: "
              f"price={current_price:.2f}, "
              f"candles={len(candles)}, "
              f"spread={orderbook_metrics.spread:.2f}bps, "
              f"imbalance={orderbook_metrics.imbalance:.3f}, "
              f"volatility={volatility_str}"
            )
            # ============================================================
            # –®–ê–ì 2: –ü–û–õ–£–ß–ï–ù–ò–ï –ü–†–ï–î–´–î–£–©–ò–• –°–û–°–¢–û–Ø–ù–ò–ô
            # ============================================================

            # ‚úÖ –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π snapshot (–µ—Å–ª–∏ –µ—Å—Ç—å)
            prev_orderbook = self.prev_orderbook_snapshots.get(symbol)

            # ‚úÖ –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å–≤–µ—á—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
            prev_candle = self.prev_candles.get(symbol)

            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            if prev_orderbook:
              logger.debug(
                f"[{symbol}] –ü—Ä–µ–¥—ã–¥—É—â–∏–π snapshot –¥–æ—Å—Ç—É–ø–µ–Ω: "
                f"age={(orderbook_snapshot.timestamp - prev_orderbook.timestamp) / 1000:.1f}s"
              )
            else:
              logger.debug(f"[{symbol}] –ü—Ä–µ–¥—ã–¥—É—â–∏–π snapshot –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–ø–µ—Ä–≤–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è)")

            if prev_candle:
              logger.debug(
                f"[{symbol}] –ü—Ä–µ–¥—ã–¥—É—â–∞—è —Å–≤–µ—á–∞ –¥–æ—Å—Ç—É–ø–Ω–∞: "
                f"close={prev_candle.close:.2f}"
              )
            else:
              logger.debug(f"[{symbol}] –ü—Ä–µ–¥—ã–¥—É—â–∞—è —Å–≤–µ—á–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")


            # ==================== BROADCAST ORDERBOOK (–ö–†–ò–¢–ò–ß–ù–û –î–õ–Ø –§–†–û–ù–¢–ï–ù–î–ê) ====================
            # try:
            #   from api.websocket import broadcast_orderbook_update
            #   await broadcast_orderbook_update(symbol, orderbook_snapshot.to_dict())
            # except Exception as e:
            #   logger.error(f"{symbol} | –û—à–∏–±–∫–∞ broadcast orderbook: {e}")

            # ============================================================
            # –®–ê–ì 2: –î–ï–¢–ï–ö–¶–ò–Ø –ú–ê–ù–ò–ü–£–õ–Ø–¶–ò–ô (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # ============================================================

            manipulation_detected = False
            manipulation_types = []

            # 2.1 Spoofing Detection
            if has_spoofing_detector:
              try:
                self.spoofing_detector.update(orderbook_snapshot)
                has_spoofing = self.spoofing_detector.is_spoofing_active(
                  symbol,
                  time_window_seconds=60
                )

                if has_spoofing:
                  manipulation_detected = True
                  manipulation_types.append("spoofing")

              except Exception as e:
                logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ Spoofing Detector: {e}")

            # 2.2 Layering Detection
            if has_layering_detector:
              try:
                self.layering_detector.update(orderbook_snapshot)
                has_layering = self.layering_detector.is_layering_active(
                  symbol,
                  time_window_seconds=60
                )

                if has_layering:
                  manipulation_detected = True
                  manipulation_types.append("layering")

              except Exception as e:
                logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ Layering Detector: {e}")

            # 2.3 Quote Stuffing Detection
            if hasattr(self, 'quote_stuffing_detector') and self.quote_stuffing_detector:
              try:
                self.quote_stuffing_detector.update(orderbook_snapshot)
                has_quote_stuffing = self.quote_stuffing_detector.is_stuffing_active(
                  symbol,
                  time_window_seconds=30
                )

                if has_quote_stuffing:
                  manipulation_detected = True
                  manipulation_types.append("quote_stuffing")

              except Exception as e:
                logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ Quote Stuffing Detector: {e}")

            # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏ –ø—Ä–∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è—Ö
            if manipulation_detected:
              logger.warning(
                f"‚ö†Ô∏è [{symbol}] –ú–ê–ù–ò–ü–£–õ–Ø–¶–ò–ò –û–ë–ù–ê–†–£–ñ–ï–ù–´: "
                f"{', '.join(manipulation_types).upper()} - "
                f"–¢–û–†–ì–û–í–õ–Ø –ó–ê–ë–õ–û–ö–ò–†–û–í–ê–ù–ê"
              )
              self.stats['manipulations_detected'] += 1

              # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è data collection,
              # –Ω–æ –ù–ï –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã
              # (skip –±—É–¥–µ—Ç –ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)

            # ============================================================
            # –®–ê–ì 3: S/R LEVELS DETECTION & UPDATE (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # ============================================================

            # –î–µ—Ç–µ–∫—Ü–∏—è —É—Ä–æ–≤–Ω–µ–π
            sr_levels: List[SRLevel] = self.sr_detector.detect_levels(symbol)

            if sr_levels:
              # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Ç–∏–ø—É
              supports = [lvl for lvl in sr_levels if lvl.level_type == "support"]
              resistances = [lvl for lvl in sr_levels if lvl.level_type == "resistance"]

              logger.debug(
                f"[{symbol}] S/R Levels: "
                f"{len(supports)} supports, {len(resistances)} resistances"
              )

              # –ü–æ–ª—É—á–µ–Ω–∏–µ –±–ª–∏–∂–∞–π—à–∏—Ö —É—Ä–æ–≤–Ω–µ–π (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict!)
              nearest = self.sr_detector.get_nearest_levels(symbol, current_price)

              # ‚úÖ –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .get(), —Ç.–∫. nearest - —ç—Ç–æ dict
              if nearest.get("support"):
                logger.info(f"Nearest support: {nearest['support'].price}")

              if nearest.get("resistance"):
                logger.info(f"Nearest resistance: {nearest['resistance'].price}")

            # ==================== 4. –¢–†–ê–î–ò–¶–ò–û–ù–ù–´–ô –ê–ù–ê–õ–ò–ó ====================
            # –ü–†–ê–í–ò–õ–¨–ù–û: –ø–µ—Ä–µ–¥–∞—ë–º OrderBookManager, –ù–ï OrderBookSnapshot
            # metrics = self.market_analyzer.analyze_symbol(symbol, ob_manager)

            # ==================== BROADCAST METRICS (–ö–†–ò–¢–ò–ß–ù–û –î–õ–Ø –§–†–û–ù–¢–ï–ù–î–ê) ====================
            # try:
            #   from api.websocket import broadcast_metrics_update
            #   await broadcast_metrics_update(symbol, metrics.to_dict())
            # except Exception as e:
            #   logger.error(f"{symbol} | –û—à–∏–±–∫–∞ broadcast metrics: {e}")

            # ============================================================
            # –®–ê–ì 4: ML FEATURE EXTRACTION
            # ============================================================

            feature_vector = None
            ml_prediction = None

            if has_ml_feature_pipeline:
              try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                feature_vector = await self.ml_feature_pipeline.extract_features_enhanced(
                  symbol=symbol,
                  orderbook_snapshot=orderbook_snapshot,
                  candles=candles,
                  orderbook_metrics=orderbook_metrics,
                  sr_levels=sr_levels if sr_levels else None,
                  prev_orderbook=prev_orderbook,  # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π snapshot
                  prev_candle=prev_candle  # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å–≤–µ—á—É
                )

                if feature_vector:
                  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                  data_quality = feature_vector.metadata.get('data_quality', {})

                  logger.debug(
                    f"[{symbol}] Feature extraction —É—Å–ø–µ—à–Ω–æ: "
                    f"{feature_vector.feature_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, "
                    f"prev_snapshot={data_quality.get('has_prev_orderbook', False)}, "
                    f"prev_candle={data_quality.get('has_prev_candle', False)}"
                  )

                  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ enrichment
                  if 'orderbook_metrics' in feature_vector.metadata:
                    ob_meta = feature_vector.metadata['orderbook_metrics']
                    logger.debug(
                      f"[{symbol}] OrderBook enrichment: "
                      f"imbalance={ob_meta['imbalance']:.3f}"
                    )

                  if 'sr_levels' in feature_vector.metadata:
                    sr_meta = feature_vector.metadata['sr_levels']
                    logger.debug(
                      f"[{symbol}] S/R enrichment: "
                      f"{sr_meta['num_supports']} supports, "
                      f"{sr_meta['num_resistances']} resistances"
                    )


                else:
                  logger.warning(f"[{symbol}] Feature extraction –≤–µ—Ä–Ω—É–ª None")

              except Exception as e:
                logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ ML Feature Extraction: {e}")
                logger.debug(traceback.format_exc())

            # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏ –µ—Å–ª–∏ –±—ã–ª–∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏
            # (–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–ª—è data collection)
            if manipulation_detected:
              # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ ML Data Collection (–®–ê–ì 11)
              # –ù–ï –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª
              logger.debug(f"[{symbol}] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º analysis –∏–∑-–∑–∞ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π")
              # Jump to ML Data Collection...
              # (–∫–æ–¥ –Ω–∏–∂–µ –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω —á–µ—Ä–µ–∑ continue –≤ –∫–æ–Ω—Ü–µ —ç—Ç–æ–≥–æ –±–ª–æ–∫–∞)

            # ============================================================
            # –®–ê–ì 5: üéØ INTEGRATED ANALYSIS (–Ø–î–†–û –°–ò–°–¢–ï–ú–´)
            # ============================================================
            # –†–µ–∂–∏–º ONLY_TRAINING: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ —Å–∏–≥–Ω–∞–ª–æ–≤, —Ç–æ–ª—å–∫–æ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
            integrated_signal = None

            if not settings.ONLY_TRAINING and not manipulation_detected:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è –∏ –Ω–µ—Ç –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π
              try:
                # –î–ï–ë–ê–ì: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º IntegratedEngine
                if cycle_number <= 5:
                  logger.info(f"  üéØ [{symbol}] –ó–∞–ø—É—Å–∫ IntegratedEngine.analyze()...")

                # –í—ã–∑—ã–≤–∞–µ–º IntegratedEngine –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                integrated_signal = await self.integrated_engine.analyze(
                  symbol=symbol,
                  candles=candles,
                  current_price=current_price,
                  orderbook=orderbook_snapshot,
                  metrics=orderbook_metrics
                )

                # –î–ï–ë–ê–ì: –†–µ–∑—É–ª—å—Ç–∞—Ç IntegratedEngine
                if cycle_number <= 5:
                  if integrated_signal:
                    logger.info(f"  ‚úÖ [{symbol}] IntegratedSignal –ø–æ–ª—É—á–µ–Ω!")
                  else:
                    logger.info(f"  ‚ùå [{symbol}] IntegratedSignal = None (–Ω–µ—Ç —Å–∏–≥–Ω–∞–ª–∞)")

                if integrated_signal:
                  # ========================================================
                  # –û–ë–†–ê–ë–û–¢–ö–ê INTEGRATED SIGNAL
                  # ========================================================

                  logger.info(
                    f"üéØ [{symbol}] IntegratedSignal –ø–æ–ª—É—á–µ–Ω: "
                    f"type={integrated_signal.final_signal.signal_type.value}, "
                    f"mode={integrated_signal.source_analysis_mode.value}, "
                    f"quality={integrated_signal.combined_quality_score:.3f}, "
                    f"confidence={integrated_signal.combined_confidence:.3f}"
                  )

                  # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
                  if settings.VERBOSE_SIGNAL_LOGGING:
                    self._log_integrated_signal(symbol, integrated_signal)

                  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª
                  final_signal = integrated_signal.final_signal

                  # ========================================================
                  # –®–ê–ì 6: ENRICHMENT SIGNAL METADATA
                  # ========================================================
                  spread_bps = None
                  if orderbook_metrics.spread and orderbook_metrics.mid_price and orderbook_metrics.mid_price > 0:
                    spread_bps = (orderbook_metrics.spread / orderbook_metrics.mid_price) * 10000

                  # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å market_metrics –∏–∑ –¥—Ä—É–≥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞)


                  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è metadata –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                  if not final_signal.metadata:
                    final_signal.metadata = {}

                  # –î–æ–±–∞–≤–ª—è–µ–º integrated analysis –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                  final_signal.metadata.update({
                    # Integrated Analysis Info
                    'integrated_analysis': True,
                    'analysis_mode': integrated_signal.source_analysis_mode.value,
                    'combined_quality': integrated_signal.combined_quality_score,
                    'combined_confidence': integrated_signal.combined_confidence,

                    # Source tracking
                    'single_tf_used': integrated_signal.used_single_tf,
                    'mtf_used': integrated_signal.used_mtf,

                    # Risk parameters
                    'position_multiplier': integrated_signal.recommended_position_multiplier,
                    'risk_level': integrated_signal.risk_level,

                    # Timestamps
                    'signal_timestamp': int(time.time() * 1000),
                    'analysis_timestamp': integrated_signal.analysis_timestamp,
                    'analysis_duration_ms': integrated_signal.analysis_duration_ms,
                    'cycle_number': cycle_number,

                    # Market context
                    'current_price': current_price,
                    'orderbook_imbalance': orderbook_metrics.imbalance,
                    'spread_bps': spread_bps,
                    'market_volatility': market_volatility
                  })

                  # Single-TF Consensus Info
                  if integrated_signal.single_tf_consensus:
                    consensus = integrated_signal.single_tf_consensus

                    consensus_mode = consensus.final_signal.metadata.get('consensus_mode', 'unknown')

                    final_signal.metadata['single_tf_consensus'] = {
                      'mode': consensus_mode,  # ‚úÖ –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç
                      'confidence': consensus.consensus_confidence,
                      'agreement_count': consensus.agreement_count,
                      'disagreement_count': consensus.disagreement_count,

                      # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª–µ–∑–Ω—ã–µ –ø–æ–ª—è
                      'contributing_strategies': consensus.contributing_strategies,
                      'candle_strategies': consensus.candle_strategies_count,
                      'orderbook_strategies': consensus.orderbook_strategies_count,
                      'hybrid_strategies': consensus.hybrid_strategies_count,

                      # –î–µ—Ç–∞–ª–∏ –∏–∑ metadata
                      'buy_score': consensus.final_signal.metadata.get('buy_score'),
                      'sell_score': consensus.final_signal.metadata.get('sell_score'),
                    }

                    # Contributing strategies –¥–ª—è Performance Tracker
                    contributing_strategies = consensus.contributing_strategies
                    final_signal.metadata['contributing_strategies'] = contributing_strategies

                  # MTF Signal Info
                  if integrated_signal.mtf_signal:
                    mtf = integrated_signal.mtf_signal

                    # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ MultiTimeframeSignal
                    mtf_data = {
                      # –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
                      'quality': mtf.signal_quality,
                      'risk_level': mtf.risk_level,
                      'alignment_score': mtf.alignment_score,
                      'alignment_type': mtf.alignment_type.value if hasattr(mtf.alignment_type, 'value') else str(
                        mtf.alignment_type),
                      'recommended_position_multiplier': mtf.recommended_position_size_multiplier,

                      # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                      'synthesis_mode': mtf.synthesis_mode.value if hasattr(mtf.synthesis_mode, 'value') else str(
                        mtf.synthesis_mode),
                      'timeframes_analyzed': mtf.timeframes_analyzed,
                      'timeframes_agreeing': mtf.timeframes_agreeing,
                      'reliability_score': mtf.reliability_score,

                      # Risk management
                      'recommended_stop_loss': mtf.recommended_stop_loss_price,
                      'recommended_take_profit': mtf.recommended_take_profit_price,
                      'stop_loss_timeframe': mtf.stop_loss_timeframe.value if mtf.stop_loss_timeframe and hasattr(
                        mtf.stop_loss_timeframe, 'value') else None,

                      # Warnings
                      'warnings': mtf.warnings if mtf.warnings else []
                    }

                    # ============================================================
                    # CONFLUENCE –ò DIVERGENCE - –ü–†–ê–í–ò–õ–¨–ù–û–ï –ò–ó–í–õ–ï–ß–ï–ù–ò–ï
                    # ============================================================

                    # –í–∞—Ä–∏–∞–Ω—Ç A: –ï—Å–ª–∏ confluence/divergence –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ MultiTimeframeSignal (–ø–æ—Å–ª–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∫–ª–∞—Å—Å–∞)
                    if hasattr(mtf, 'has_confluence'):
                      mtf_data['confluence_detected'] = mtf.has_confluence
                      mtf_data['confluence_zones_count'] = mtf.confluence_zones_count

                    if hasattr(mtf, 'divergence_type'):
                      mtf_data['divergence_detected'] = mtf.divergence_detected
                      mtf_data['divergence_type'] = mtf.divergence_type.value if mtf.divergence_type and hasattr(
                        mtf.divergence_type, 'value') else 'no_divergence'
                      mtf_data['divergence_severity'] = mtf.divergence_severity

                    # –í–∞—Ä–∏–∞–Ω—Ç B: –ï—Å–ª–∏ alignment –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ IntegratedSignal
                    elif hasattr(integrated_signal, 'mtf_alignment') and integrated_signal.mtf_alignment:
                      alignment = integrated_signal.mtf_alignment

                      mtf_data['confluence_detected'] = alignment.has_strong_confluence
                      mtf_data['confluence_zones_count'] = len(alignment.confluence_zones)

                      mtf_data['divergence_detected'] = (alignment.divergence_type != DivergenceType.NO_DIVERGENCE)
                      mtf_data['divergence_type'] = alignment.divergence_type.value if hasattr(
                        alignment.divergence_type, 'value') else str(alignment.divergence_type)
                      mtf_data['divergence_severity'] = alignment.divergence_severity

                      logger.debug(
                        f"[{symbol}] MTF Alignment extracted: "
                        f"confluence={alignment.has_strong_confluence}, "
                        f"divergence={alignment.divergence_type.value}"
                      )

                    # –í–∞—Ä–∏–∞–Ω—Ç C: –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω MultiTimeframeManager
                    elif hasattr(self, 'mtf_manager') and self.mtf_manager:
                      try:
                        alignment = self.mtf_manager.get_last_alignment(symbol)

                        if alignment:
                          mtf_data['confluence_detected'] = alignment.has_strong_confluence
                          mtf_data['confluence_zones_count'] = len(alignment.confluence_zones)

                          mtf_data['divergence_detected'] = (alignment.divergence_type != DivergenceType.NO_DIVERGENCE)
                          mtf_data['divergence_type'] = alignment.divergence_type.value if hasattr(
                            alignment.divergence_type, 'value') else str(alignment.divergence_type)
                          mtf_data['divergence_severity'] = alignment.divergence_severity

                          logger.debug(f"[{symbol}] Alignment retrieved from MTF Manager")
                        else:
                          logger.warning(f"[{symbol}] No alignment found in MTF Manager")
                          # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                          mtf_data['confluence_detected'] = False
                          mtf_data['divergence_type'] = 'unknown'

                      except Exception as e:
                        logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ alignment: {e}")
                        mtf_data['confluence_detected'] = False
                        mtf_data['divergence_type'] = 'error'

                    # –í–∞—Ä–∏–∞–Ω—Ç D: –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ - –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    else:
                      logger.warning(
                        f"[{symbol}] MTF alignment data not accessible, "
                        "using default values"
                      )
                      mtf_data['confluence_detected'] = False
                      mtf_data['confluence_zones_count'] = 0
                      mtf_data['divergence_detected'] = False
                      mtf_data['divergence_type'] = 'not_available'
                      mtf_data['divergence_severity'] = 0.0

                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ metadata
                    final_signal.metadata['mtf_signal'] = mtf_data

                    logger.info(
                      f"[{symbol}] MTF Signal metadata added: "
                      f"quality={mtf.signal_quality:.2f}, "
                      f"confluence={mtf_data.get('confluence_detected', False)}, "
                      f"divergence={mtf_data.get('divergence_type', 'unknown')}"
                    )

                    if mtf.warnings:
                      final_signal.metadata['mtf_warnings'] = mtf.warnings

                  # Adaptive weights (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                  if integrated_signal.adaptive_weights:
                    final_signal.metadata['adaptive_weights'] = integrated_signal.adaptive_weights

                  # Market regime (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                  if integrated_signal.market_regime:
                    final_signal.metadata['market_regime'] = integrated_signal.market_regime

                  # ML Prediction (–µ—Å–ª–∏ –±—ã–ª–æ)
                  if ml_prediction:
                    final_signal.metadata['ml_prediction'] = {
                      'direction': ml_prediction.get('prediction'),
                      'confidence': ml_prediction.get('confidence')
                    }

                  # Warnings –æ—Ç engine
                  if integrated_signal.warnings:
                    final_signal.metadata['engine_warnings'] = integrated_signal.warnings

                  # ========================================================
                  # –®–ê–ì 7: ML VALIDATION –§–ò–ù–ê–õ–¨–ù–û–ì–û –°–ò–ì–ù–ê–õ–ê
                  # ========================================================

                  ml_should_trade = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–∑—Ä–µ—à–∞–µ–º
                  ml_validation_confidence = None

                  if has_ml_validator and feature_vector:
                    try:
                      logger.debug(f"[{symbol}] –ó–∞–ø—É—Å–∫ ML Validation...")

                      # ML Validator –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª
                      validation_result = await self.ml_validator.validate(

                        signal=final_signal,
                        feature_vector=feature_vector
                      )

                      ml_should_trade = validation_result.validated

                      ml_validation_confidence = validation_result.ml_confidence

                      # –î–æ–±–∞–≤–ª—è–µ–º ML validation –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                      final_signal.metadata.update({
                        'ml_validated': True,
                        'ml_should_trade': ml_should_trade,
                        'ml_validation_confidence': ml_validation_confidence,
                        'ml_validation_reason': validation_result.reason if not ml_should_trade else None
                      })

                      # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                      if ml_should_trade:
                        logger.info(
                          f"‚úÖ [{symbol}] ML Validation: APPROVED "
                          f"(confidence={ml_validation_confidence:.3f})"
                        )
                      else:
                        logger.warning(
                          f"‚ùå [{symbol}] ML Validation: REJECTED "
                          f"(reason={validation_result.reason})"
                        )

                      self.stats['ml_validations'] += 1

                      # –û—Ç–∫–ª–æ–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª –µ—Å–ª–∏ ML –Ω–µ –æ–¥–æ–±—Ä–∏–ª
                      if not ml_should_trade:
                        logger.info(f"‚õî [{symbol}] –°–∏–≥–Ω–∞–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω ML Validator")
                        integrated_signal = None  # –û—Ç–º–µ–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª
                        continue  # –°–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª

                    except Exception as e:
                      logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ ML Validation: {e}")
                      logger.debug(traceback.format_exc())
                      # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ ML validation

                  # ========================================================
                  # –®–ê–ì 8: QUALITY & RISK CHECKS
                  # ========================================================

                  # 8.1 –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                  if integrated_signal.combined_quality_score < settings.MIN_COMBINED_QUALITY:
                    logger.info(
                      f"‚ö†Ô∏è [{symbol}] –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–∞: "
                      f"{integrated_signal.combined_quality_score:.3f} < "
                      f"{settings.MIN_COMBINED_QUALITY}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º"
                    )
                    self.stats['warnings'] += 1
                    continue  # –°–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª

                  # 8.2 –ü—Ä–æ–≤–µ—Ä–∫–∞ confidence
                  if integrated_signal.combined_confidence < settings.MIN_SIGNAL_CONFIDENCE:
                    logger.info(
                      f"‚ö†Ô∏è [{symbol}] –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞: "
                      f"{integrated_signal.combined_confidence:.3f} < "
                      f"{settings.MIN_SIGNAL_CONFIDENCE}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º"
                    )
                    self.stats['warnings'] += 1
                    continue  # –°–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª

                  # 8.3 –ü—Ä–æ–≤–µ—Ä–∫–∞ EXTREME —Ä–∏—Å–∫–∞
                  if integrated_signal.risk_level == "EXTREME":
                    logger.warning(
                      f"üö® [{symbol}] EXTREME RISK –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º"
                    )
                    self.stats['warnings'] += 1
                    continue  # –°–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª

                  # ========================================================
                  # –®–ê–ì 9: S/R CONTEXT ENRICHMENT (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                  # ========================================================

                  if has_sr_detector and sr_levels:
                    try:
                      # –ü–æ–ª—É—á–∞–µ–º –±–ª–∏–∂–∞–π—à–∏–µ S/R —É—Ä–æ–≤–Ω–∏
                      nearest_levels = self.sr_detector.get_nearest_levels(
                        symbol=symbol,
                        current_price=current_price,
                        max_distance_pct=0.02  # 2% –æ—Ç —Ü–µ–Ω—ã
                      )

                      sr_context = []

                      # Support
                      if nearest_levels.get("support"):
                        support = nearest_levels["support"]
                        sr_context.append(
                          f"Support: ${support.price:.2f} "
                          f"(strength={support.strength:.2f}, "
                          f"distance={abs(current_price - support.price) / current_price * 100:.2f}%)"
                        )

                      # Resistance
                      if nearest_levels.get("resistance"):
                        resistance = nearest_levels["resistance"]
                        sr_context.append(
                          f"Resistance: ${resistance.price:.2f} "
                          f"(strength={resistance.strength:.2f}, "
                          f"distance={abs(resistance.price - current_price) / current_price * 100:.2f}%)"
                        )

                      if sr_context:
                        final_signal.metadata['sr_context'] = sr_context
                        logger.debug(
                          f"[{symbol}] S/R Context: {' | '.join(sr_context)}"
                        )

                    except Exception as e:
                      logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ S/R Context: {e}")

                  # ========================================================
                  # –®–ê–ì 10: EXECUTION SUBMISSION
                  # ========================================================

                  try:
                    logger.info(
                      f"üì§ [{symbol}] –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ: "
                      f"{final_signal.signal_type.value} @ {final_signal.price:.2f}"
                    )

                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –≤ ExecutionManager
                    submission_result = await self.execution_manager.submit_signal(
                      signal=final_signal
                    )

                    if submission_result is not None and submission_result.success:
                      logger.info(
                        f"‚úÖ [{symbol}] –°–∏–≥–Ω–∞–ª –ø—Ä–∏–Ω—è—Ç ExecutionManager: "
                        f"order_id={submission_result.order_id or 'pending'}"
                      )
                      self.stats['signals_executed'] += 1
                    elif submission_result is not None:
                      logger.warning(
                        f"‚ö†Ô∏è [{symbol}] –°–∏–≥–Ω–∞–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω ExecutionManager: "
                        f"{submission_result.reason}"
                      )
                      self.stats['warnings'] += 1
                    else:
                      logger.warning(
                        f"‚ö†Ô∏è [{symbol}] ExecutionManager –≤–µ—Ä–Ω—É–ª None (–æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ)"
                      )
                      self.stats['warnings'] += 1

                  except Exception as e:
                    logger.error(f"‚ùå [{symbol}] –û—à–∏–±–∫–∞ submission: {e}")
                    logger.debug(traceback.format_exc())

                  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                  self.stats['signals_generated'] += 1

                  if integrated_signal.used_mtf:
                    self.stats['mtf_signals'] += 1

                else:
                  # –°–∏–≥–Ω–∞–ª –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω
                  logger.debug(
                    f"[{symbol}] IntegratedEngine –Ω–µ –≤–µ—Ä–Ω—É–ª —Å–∏–≥–Ω–∞–ª "
                    f"(–∫–æ–Ω—Å–µ–Ω—Å—É—Å –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∏–ª–∏ –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)"
                  )

              except Exception as e:
                logger.error(
                  f"‚ùå [{symbol}] –û—à–∏–±–∫–∞ IntegratedEngine.analyze(): {e}"
                )
                logger.error(traceback.format_exc())
                error_count[symbol] += 1
                continue  # –°–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª

            # ============================================================
            # –®–ê–ì 11: DRIFT MONITORING (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # ============================================================

            # –ò–∑–≤–ª–µ–∫–∞–µ–º final_signal –∏–∑ integrated_signal –¥–ª—è drift monitoring
            drift_signal = integrated_signal.final_signal if integrated_signal else None

            if has_drift_detector and feature_vector and drift_signal:
              try:
                # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ drift_signal - —ç—Ç–æ TradingSignal (–¥–æ–±–∞–≤–ª—è–µ–º type hint)
                from backend.models.signal import TradingSignal, SignalType

                # Type guard –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∏–ø–∞
                if not isinstance(drift_signal, TradingSignal):
                  logger.warning(f"{symbol} | drift_signal –Ω–µ —è–≤–ª—è–µ—Ç—Å—è TradingSignal, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º drift monitoring")
                else:
                  # ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–´–ô –î–û–°–¢–£–ü –∫ signal_type
                  signal_type_value = None

                  # –í–∞—Ä–∏–∞–Ω—Ç 1: –ß–µ—Ä–µ–∑ hasattr
                  if hasattr(drift_signal, 'signal_type'):
                    signal_type_value = safe_enum_value(drift_signal.signal_type)

                  # –í–∞—Ä–∏–∞–Ω—Ç 2: –ß–µ—Ä–µ–∑ getattr —Å fallback
                  # signal_type_enum = getattr(signal, 'signal_type', None)
                  # if signal_type_enum:
                  #     signal_type_value = safe_enum_value(signal_type_enum)

                  if not signal_type_value:
                    logger.warning(f"{symbol} | –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å signal_type, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º drift monitoring")
                  else:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º SignalType –≤ int –¥–ª—è drift detector
                    signal_type_map = {
                      "BUY": 1,
                      "SELL": 2,
                      "HOLD": 0
                    }

                    prediction_int = signal_type_map.get(signal_type_value, 0)

                    logger.debug(
                      f"{symbol} | Drift monitoring: signal_type={signal_type_value}, "
                      f"prediction_int={prediction_int}"
                    )

                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –≤ drift detector
                    self.drift_detector.add_observation(
                      features=feature_vector.to_array(),
                      prediction=prediction_int,
                      label=None  # Label –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–∑–∂–µ
                    )

                    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ drift
                    if self.drift_detector.should_check_drift():
                      drift_metrics = self.drift_detector.check_drift()

                      if drift_metrics and drift_metrics.drift_detected:
                        logger.warning(
                          f"‚ö†Ô∏è  MODEL DRIFT –û–ë–ù–ê–†–£–ñ–ï–ù [{symbol}]:\n"
                          f"   Severity: {drift_metrics.severity}\n"
                          f"   Feature drift: {drift_metrics.feature_drift_score:.4f}\n"
                          f"   Prediction drift: {drift_metrics.prediction_drift_score:.4f}\n"
                          f"   Recommendation: {drift_metrics.recommendation}"
                        )

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º drift history
                        try:
                          self.drift_detector.save_drift_history(
                            f"logs/drift_history_{symbol}.json"
                          )
                        except Exception as e:
                          logger.error(f"{symbol} | –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è drift history: {e}")
                      else:
                        logger.debug(f"{symbol} | Drift check passed, no drift detected")

              except AttributeError as e:
                logger.error(
                  f"{symbol} | AttributeError –≤ drift monitoring: {e}. "
                  "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ signal –∏–º–µ–µ—Ç –∞—Ç—Ä–∏–±—É—Ç signal_type",
                  exc_info=True
                )
              except Exception as e:
                logger.error(f"{symbol} | –û—à–∏–±–∫–∞ drift monitoring: {e}", exc_info=True)
# +++++–≤–∫–ª—é—á–∏—Ç—å –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
            # ============================================================
            # –®–ê–ì 12: ML DATA COLLECTION (–¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
            # ============================================================

            if has_ml_data_collector and feature_vector and should_collect_ml_data_this_cycle:
              try:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ sample
                sample_data = {
                  'symbol': symbol,
                  'timestamp': int(time.time() * 1000),
                  'features': feature_vector,
                  'price': current_price,
                  'orderbook_snapshot': {
                    'best_bid': orderbook_snapshot.best_bid,
                    'best_ask': orderbook_snapshot.best_ask,
                    'mid_price': orderbook_snapshot.mid_price,
                    'spread': orderbook_snapshot.spread,
                    'imbalance': orderbook_metrics.imbalance
                  },
                  'market_metrics': {
                    'volatility': market_volatility if market_metrics else None,
                    'volume': (candles[-1].volume if candles and len(candles) > 0 else None) ,
                    'momentum': (
                        ((candles[-1].close - candles[-2].close) / candles[-2].close) * 100
                        if candles and len(candles) > 1 and candles[-2].close > 0
                        else None
                    )
                  }
                }

                # –ï—Å–ª–∏ –±—ã–ª —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å–∏–≥–Ω–∞–ª - –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
                if integrated_signal:
                  sample_data['signal'] = {
                    'type': integrated_signal.final_signal.signal_type.value,
                    'confidence': integrated_signal.combined_confidence,
                    'quality': integrated_signal.combined_quality_score,
                    'entry_price': integrated_signal.final_signal.price,
                    'stop_loss': (
                          integrated_signal.recommended_stop_loss
                          if hasattr(integrated_signal, 'recommended_stop_loss')
                          else integrated_signal.final_signal.metadata.get('stop_loss', None)
                      ),
                    'take_profit': (
                          integrated_signal.recommended_take_profit
                          if hasattr(integrated_signal, 'recommended_take_profit')
                          else integrated_signal.final_signal.metadata.get('take_profit', None)
                      ),
                    'source_mode': integrated_signal.source_analysis_mode.value
                  }

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ sample
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–µ—Ä–µ–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏–≥–Ω–∞–ª–µ –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω
                signal_info = None
                if integrated_signal:
                  signal_info = {
                    'type': integrated_signal.final_signal.signal_type.value,
                    'confidence': integrated_signal.combined_confidence,
                    'strength': integrated_signal.final_signal.strength.value if hasattr(integrated_signal.final_signal.strength, 'value') else str(integrated_signal.final_signal.strength)
                  }

                await self.ml_data_collector.collect_sample(
                  symbol=symbol,
                  feature_vector=feature_vector,
                  orderbook_snapshot=orderbook_snapshot,
                  market_metrics=market_metrics,
                  executed_signal=signal_info
                )

                self.stats['ml_data_collected'] += 1
                logger.debug(f"[{symbol}] ML Data sample —Å–æ–±—Ä–∞–Ω")

              except Exception as e:
                logger.error(f"[{symbol}] –û—à–∏–±–∫–∞ ML Data Collection: {e}")

            # ============================================================
            # –®–ê–ì 13: REAL-TIME BROADCASTING (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # ============================================================

            try:
              # Broadcast OrderBook Update
              from backend.api.websocket import broadcast_orderbook_update
              await broadcast_orderbook_update(
                symbol=symbol,
                orderbook=orderbook_snapshot.to_dict()
              )

              # Broadcast Metrics Update
              from backend.api.websocket import broadcast_metrics_update
              await broadcast_metrics_update(
                symbol=symbol,
                metrics=market_metrics.to_dict()
              )
# +++++–≤–∫–ª—é—á–∏—Ç—å –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
              # Broadcast Signal (–µ—Å–ª–∏ –±—ã–ª)
              if integrated_signal:
                from backend.api.websocket import broadcast_signal

                try:
                  await broadcast_signal(
                    signal=integrated_signal.final_signal.to_dict()
                  )

                  logger.debug(
                    f"[{symbol}] –°–∏–≥–Ω–∞–ª —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —á–µ—Ä–µ–∑ WebSocket: "
                    f"{integrated_signal.final_signal.signal_type.value}"
                  )

                except Exception as e:
                  logger.debug(f"[{symbol}] –û—à–∏–±–∫–∞ broadcasting —Å–∏–≥–Ω–∞–ª–∞: {e}")
# +++++–≤–∫–ª—é—á–∏—Ç—å –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
            except Exception as e:
              # Broadcasting errors –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã
              logger.debug(f"[{symbol}] –û—à–∏–±–∫–∞ broadcasting: {e}")

            # ============================================================
            # –£–°–ü–ï–®–ù–û–ï –ó–ê–í–ï–†–®–ï–ù–ò–ï –ê–ù–ê–õ–ò–ó–ê –°–ò–ú–í–û–õ–ê
            # ============================================================

            # –°–±—Ä–æ—Å error counter –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
            error_count[symbol] = 0

            # –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è —Å–∏–º–≤–æ–ª–∞
            symbol_elapsed = time.time() - symbol_start

            if symbol_elapsed > settings.ANALYSIS_WARNING_THRESHOLD:
              logger.warning(
                f"‚è±Ô∏è [{symbol}] –ê–Ω–∞–ª–∏–∑ –∑–∞–Ω—è–ª {symbol_elapsed:.2f}—Å "
                f"(> {settings.ANALYSIS_WARNING_THRESHOLD}—Å)"
              )
            else:
              logger.debug(
                f"[{symbol}] –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {symbol_elapsed:.2f}—Å"
              )

          except Exception as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            # error_count[symbol] += 1

            logger.error(
              f"‚ùå [{symbol}] –û—à–∏–±–∫–∞ –≤ analysis loop "
              f"(#{error_count[symbol]}/{max_consecutive_errors}): {e}"
            )
            logger.debug(traceback.format_exc())

            # self.stats['errors'] += 1
            #
            # # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ –æ—à–∏–±–æ–∫
            # if error_count[symbol] >= max_consecutive_errors:
            #   logger.critical(
            #     f"üö® [{symbol}] –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫ "
            #     f"({max_consecutive_errors}), —Å–∏–º–≤–æ–ª –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω –¥–æ —Ä–µ—Å—Ç–∞—Ä—Ç–∞"
            #   )
            #
            #   # –û—Ç–ø—Ä–∞–≤–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–µ—Ä—Ç–∞
            #   if settings.ENABLE_CRITICAL_ALERTS:
            #     await self._send_critical_alert(
            #       f"[{symbol}] –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ analysis loop",
            #       f"–°–∏–º–≤–æ–ª –ø—Ä–æ–ø—É—â–µ–Ω –ø–æ—Å–ª–µ {max_consecutive_errors} –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥"
            #     )

        # await asyncio.sleep(1)

            continue  # –°–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª

        self.stats['analysis_cycles'] += 1

        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–∫–∞–∂–¥—ã–µ 100 —Ü–∏–∫–ª–æ–≤)
        # if cycle_number % 100 == 0:
        #   self._log_analysis_statistics()

          # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ü–∏–∫–ª–∞
        cycle_elapsed = time.time() - cycle_start

        try:
          analysis_interval = float(settings.ANALYSIS_INTERVAL)
        except (ValueError, TypeError):
          analysis_interval = 0.5  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
          logger.warning(
            f"ANALYSIS_INTERVAL –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–º, –∏—Å–ø–æ–ª—å–∑—É—é {analysis_interval}"
          )

        # Warning –µ—Å–ª–∏ —Ü–∏–∫–ª –∑–∞–Ω—è–ª —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        if cycle_elapsed > analysis_interval:
          logger.warning(
            f"‚è±Ô∏è –¶–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ #{cycle_number} –∑–∞–Ω—è–ª {cycle_elapsed:.2f}—Å "
            f"(> –∏–Ω—Ç–µ—Ä–≤–∞–ª {analysis_interval}—Å)"
          )

        # –û–∂–∏–¥–∞–Ω–∏–µ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞
        try:
          sleep_duration = max(0.1, analysis_interval - cycle_elapsed)
        except (TypeError, ValueError):
          sleep_duration = 0.5

        await asyncio.sleep(sleep_duration)

      except asyncio.CancelledError:
        # Graceful shutdown
        logger.info("üõë Analysis Loop –ø–æ–ª—É—á–∏–ª CancelledError, –∑–∞–≤–µ—Ä—à–∞–µ–º...")
        break

      except Exception as e:
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        logger.error(f"‚ùå –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
        logger.error(f"‚ùå –°—Ç–µ–∫ –≤—ã–∑–æ–≤–æ–≤:\n{traceback.format_exc()}")
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≤ –≥–ª–∞–≤–Ω–æ–º analysis loop: {e}")
        logger.error(traceback.format_exc())

        self.stats['errors'] += 1

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–µ—Ä—Ç–∞
        if settings.ENABLE_CRITICAL_ALERTS:
          await self._send_critical_alert(
            "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ",
            f"Error: {str(e)}"
          )

        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
        await asyncio.sleep(5)

    # ========================================================================
    # –ó–ê–í–ï–†–®–ï–ù–ò–ï LOOP
    # ========================================================================

    logger.warning("‚ö†Ô∏è Analysis Loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    logger.info("=" * 80)
    logger.info("üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ë–û–¢–´")
    logger.info("=" * 80)
    logger.info(f"   ‚îú‚îÄ –¶–∏–∫–ª–æ–≤ –∞–Ω–∞–ª–∏–∑–∞: {self.stats.get('analysis_cycles', 0)}")
    logger.info(f"   ‚îú‚îÄ –°–∏–≥–Ω–∞–ª–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {self.stats.get('signals_generated', 0)}")
    logger.info(f"   ‚îú‚îÄ –°–∏–≥–Ω–∞–ª–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {self.stats.get('signals_executed', 0)}")
    logger.info(f"   ‚îú‚îÄ –û—Ä–¥–µ—Ä–æ–≤ —Ä–∞–∑–º–µ—â–µ–Ω–æ: {self.stats.get('orders_placed', 0)}")
    logger.info(f"   ‚îú‚îÄ –ü–æ–∑–∏—Ü–∏–π –æ—Ç–∫—Ä—ã—Ç–æ: {self.stats.get('positions_opened', 0)}")
    logger.info(f"   ‚îú‚îÄ –ü–æ–∑–∏—Ü–∏–π –∑–∞–∫—Ä—ã—Ç–æ: {self.stats.get('positions_closed', 0)}")
    logger.info(f"   ‚îú‚îÄ –û–±—â–∏–π PnL: {self.stats.get('total_pnl', 0.0):.2f} USDT")
    logger.info(f"   ‚îú‚îÄ MTF —Å–∏–≥–Ω–∞–ª–æ–≤: {self.stats.get('mtf_signals', 0)}")
    logger.info(f"   ‚îú‚îÄ ML –≤–∞–ª–∏–¥–∞—Ü–∏–π: {self.stats.get('ml_validations', 0)}")
    logger.info(f"   ‚îú‚îÄ –ú–∞–Ω–∏–ø—É–ª—è—Ü–∏–π –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {self.stats.get('manipulations_detected', 0)}")
    logger.info(f"   ‚îú‚îÄ Drift –¥–µ—Ç–µ–∫—Ü–∏–π: {self.stats.get('drift_detections', 0)}")
    logger.info(f"   ‚îú‚îÄ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {self.stats.get('warnings', 0)}")
    logger.info(f"   ‚îî‚îÄ –û—à–∏–±–æ–∫: {self.stats.get('errors', 0)}")
    logger.info("=" * 80)

  async def _analysis_loop_watchdog(self):
    """
    Watchdog –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–∞–±–æ—Ç—ã analysis loop.
    –ï—Å–ª–∏ loop –∑–∞–≤–∏—Å–∞–µ—Ç - –ª–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ.
    """
    logger.info("üêï –ó–∞–ø—É—â–µ–Ω Analysis Loop Watchdog")

    last_iteration_time = asyncio.get_event_loop().time()
    watchdog_interval = 30  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
    max_stall_time = 60  # –ú–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥ –±–µ–∑ –∏—Ç–µ—Ä–∞—Ü–∏–π

    while self.status == BotStatus.RUNNING:
      await asyncio.sleep(watchdog_interval)

      current_time = asyncio.get_event_loop().time()
      elapsed = current_time - last_iteration_time

      if elapsed > max_stall_time:
        logger.error(
          f"üö® ANALYSIS LOOP STALLED! "
          f"–ü—Ä–æ—à–ª–æ {elapsed:.1f}s –±–µ–∑ –∏—Ç–µ—Ä–∞—Ü–∏–π"
        )
        logger.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        logger.error("  1. WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è")
        logger.error("  2. –ù–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö orderbook/candles")
        logger.error("  3. –ó–∞–≤–∏—Å—à–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ loop")


  async def stop(self):
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞."""
    if self.status == BotStatus.STOPPED:
      logger.warning("–ë–æ—Ç —É–∂–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
      return

    try:
      self.status = BotStatus.STOPPING
      self.running = False
      logger.info("=" * 80)
      logger.info("–û–°–¢–ê–ù–û–í–ö–ê –¢–û–†–ì–û–í–û–ì–û –ë–û–¢–ê")
      logger.info("=" * 80)

      # ===== –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ML –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π =====
      if hasattr(self, 'layering_data_collector') and self.layering_data_collector:
        try:
          logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ML training data...")
          self.layering_data_collector.save_to_disk()
          stats = self.layering_data_collector.get_statistics()
          logger.info(
            f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {stats['buffer_size']} samples, "
            f"Total collected: {stats['total_collected']}"
          )
        except Exception as e:
          logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ML data: {e}")

      # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–¥–∞—á–∏
      tasks_to_cancel = []

      # ===== SCREENER MANAGER (–ù–û–í–û–ï) =====
      if self.screener_broadcast_task:
        self.screener_broadcast_task.cancel()

      if self.screener_manager:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ Screener Manager...")
        await self.screener_manager.stop()
        logger.info("‚úì Screener Manager –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

      if self.analysis_task:
        tasks_to_cancel.append(self.analysis_task)

      if self.candle_update_task:  # –ù–û–í–û–ï
        tasks_to_cancel.append(self.candle_update_task)

      if self.websocket_task:
        tasks_to_cancel.append(self.websocket_task)

      if self.ml_stats_task:
        tasks_to_cancel.append(self.ml_stats_task)

      if hasattr(self, 'layering_save_task') and self.layering_save_task:
        tasks_to_cancel.append(self.layering_save_task)

      for task in tasks_to_cancel:
        task.cancel()
        try:
          await task
        except asyncio.CancelledError:
          pass

      # ===== –ù–û–í–û–ï: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è ML Data Collector =====
      if self.ml_data_collector:
        await self.ml_data_collector.finalize()
        logger.info("‚úì ML Data Collector —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

      # ===== MEMORY FIX: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ =====
      logger.info("üßπ –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ...")

      # 1. –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ ML –±—É—Ñ–µ—Ä—ã —è–≤–Ω–æ
      if self.ml_data_collector:
        try:
          for symbol in list(self.ml_data_collector.feature_buffers.keys()):
            self.ml_data_collector.feature_buffers[symbol].clear()
            self.ml_data_collector.label_buffers[symbol].clear()
            self.ml_data_collector.metadata_buffers[symbol].clear()
          logger.info("  ‚úì ML –±—É—Ñ–µ—Ä—ã –æ—á–∏—â–µ–Ω—ã")
        except Exception as e:
          logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ ML –±—É—Ñ–µ—Ä–æ–≤: {e}")

      # 2. –û—á–∏—Å—Ç–∏—Ç—å feature pipelines
      if self.ml_feature_pipeline:
        try:
          for symbol in list(self.ml_feature_pipeline.pipelines.keys()):
            pipeline = self.ml_feature_pipeline.pipelines[symbol]
            # –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à–∏
            if hasattr(pipeline, '_cache'):
              pipeline._cache.clear()
            # –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –≤ extractors
            if hasattr(pipeline, 'orderbook_extractor'):
              pipeline.orderbook_extractor.snapshot_history.clear()
              pipeline.orderbook_extractor.level_ttl_history.clear()
            if hasattr(pipeline, 'indicator_extractor'):
              pipeline.indicator_extractor.candle_history.clear()
          logger.info("  ‚úì Feature pipeline –∫—ç—à–∏ –æ—á–∏—â–µ–Ω—ã")
        except Exception as e:
          logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ feature pipelines: {e}")

      # 3. –£–¥–∞–ª–∏—Ç—å –∫—Ä—É–ø–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
      try:
        if self.ml_data_collector:
          del self.ml_data_collector
          self.ml_data_collector = None
        if self.ml_feature_pipeline:
          del self.ml_feature_pipeline
          self.ml_feature_pipeline = None
        logger.info("  ‚úì –ö—Ä—É–ø–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã —É–¥–∞–ª–µ–Ω—ã")
      except Exception as e:
        logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤: {e}")

      # 4. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞ (3 –ø—Ä–æ—Ö–æ–¥–∞)
      import gc
      collected_total = 0
      for i in range(3):
        collected = gc.collect()
        collected_total += collected
        logger.info(f"  ‚úì GC –ø—Ä–æ—Ö–æ–¥ {i+1}/3: —Å–æ–±—Ä–∞–Ω–æ {collected} –æ–±—ä–µ–∫—Ç–æ–≤")

      logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ: {collected_total} –æ–±—ä–µ–∫—Ç–æ–≤")

      # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
      try:
        final_memory = get_memory_usage()
        logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {final_memory:.1f} MB")
      except:
        pass

      # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
      if self.websocket_manager:
        await self.websocket_manager.stop()
        logger.info("‚úì WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

      if self.execution_manager:
        await self.execution_manager.stop()
        logger.info("‚úì –ú–µ–Ω–µ–¥–∂–µ—Ä –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

      # ========== –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Daily Loss Killer ==========
      await daily_loss_killer.stop()
      logger.info("‚úì Daily Loss Killer –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

      if self.balance_tracker:
        await self.balance_tracker.stop()
        logger.info("‚úì –¢—Ä–µ–∫–µ—Ä –±–∞–ª–∞–Ω—Å–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

      # ========== –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π ==========
      if self.correlation_update_task:
        self.correlation_update_task.cancel()
        try:
          await self.correlation_update_task
        except asyncio.CancelledError:
          pass

      if self.symbols_refresh_task:
        self.symbols_refresh_task.cancel()
        try:
          await self.symbols_refresh_task
        except asyncio.CancelledError:
          pass
        logger.info("‚úì Symbols refresh task –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

      # ============================================
      # ML SIGNAL VALIDATOR - –û—Å—Ç–∞–Ω–æ–≤–∫–∞
      # ============================================
      # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º cleanup() –≤–º–µ—Å—Ç–æ stop()
      if hasattr(self, 'ml_validator') and self.ml_validator:
        try:
          logger.info("ü§ñ –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ML Signal Validator...")
          await self.ml_validator.cleanup()  # ‚Üê –ò–°–ü–†–ê–í–õ–ï–ù–û: cleanup() –≤–º–µ—Å—Ç–æ stop()
          logger.info("‚úÖ ML Signal Validator –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
          logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ ML validator: {e}")

      # ==========================================
      # –û–°–¢–ê–ù–û–í–ö–ê TRAILING STOP MANAGER
      # ==========================================
      logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ Trailing Stop Manager...")
      await trailing_stop_manager.stop()

      # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ Position Monitor
      if self.position_monitor:
        await self.position_monitor.stop()
        logger.info("‚úì Position Monitor –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


      self.status = BotStatus.STOPPED
      logger.info("=" * 80)
      logger.info("–ë–û–¢ –£–°–ü–ï–®–ù–û –û–°–¢–ê–ù–û–í–õ–ï–ù")
      logger.info("=" * 80)

      # –£–≤–µ–¥–æ–º–ª—è–µ–º —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥
      from backend.api.websocket import broadcast_bot_status
      await broadcast_bot_status("stopped", {
        "message": "–ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
      })

    except Exception as e:
      self.status = BotStatus.ERROR
      logger.error(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–æ—Ç–∞: {e}")
      log_exception(logger, e, "–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞")
      raise

  async def _correlation_update_loop(self):
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.

    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Ä–∞–∑ –≤ –¥–µ–Ω—å –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø
    –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä.
    """
    logger.info("–ó–∞–ø—É—â–µ–Ω —Ü–∏–∫–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–∫–∞–∂–¥—ã–µ 24 —á–∞—Å–∞)")

    while self.running:
      try:
        # –ñ–¥–µ–º 24 —á–∞—Å–∞
        await asyncio.sleep(24 * 3600)

        if not self.running:
          break

        logger.info("–í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π...")

        # –ï—Å–ª–∏ —Å–∏–º–≤–æ–ª—ã –∏–∑–º–µ–Ω–∏–ª–∏—Å—å - –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        current_symbols = set(self.symbols)
        registered_symbols = set(correlation_manager.group_manager.symbol_to_group.keys())

        if current_symbols != registered_symbols:
          logger.warning(
            f"‚ö†Ô∏è –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑–º–µ–Ω–∏–ª—Å—è! "
            f"–°—Ç–∞—Ä—ã–µ: {len(registered_symbols)}, –ù–æ–≤—ã–µ: {len(current_symbols)}"
          )

          # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –¥–ª—è –Ω–æ–≤—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
          await correlation_manager.update_correlations(list(current_symbols))

          logger.info("‚úì –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤")
        else:
          # –ü—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
          await correlation_manager.update_correlations(self.symbols)
          logger.info("‚úì –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

      except asyncio.CancelledError:
        logger.info("–ó–∞–¥–∞—á–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –æ—Ç–º–µ–Ω–µ–Ω–∞")
        break
      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π: {e}", exc_info=True)
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        await asyncio.sleep(3600)  # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ 1 —á–∞—Å

  async def _handle_reversal_signal(
        self,
        symbol: str,
        reversal: ReversalSignal,
        position: Dict
    ):
      """
      –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ —Ä–∞–∑–≤–æ—Ä–æ—Ç–∞.

      Args:
          symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
          reversal: –°–∏–≥–Ω–∞–ª —Ä–∞–∑–≤–æ—Ä–æ—Ç–∞
          position: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ RiskManager
      """
      try:
        if reversal.suggested_action == "close_position":
          logger.warning(
            f"{symbol} | üö® CRITICAL REVERSAL DETECTED | "
            f"Strength: {reversal.strength.value} | "
            f"Confidence: {reversal.confidence:.2%} | "
            f"Reason: {reversal.reason}"
          )

          if reversal_detector.auto_action:
            logger.warning(
              f"{symbol} | AUTO-CLOSING position due to critical reversal"
            )

            # –ù–∞—Ö–æ–¥–∏–º position_id –≤ –ë–î
            position_in_db = await position_repository.find_open_by_symbol(symbol)

            if position_in_db:
              current_price = position.get('entry_price', 0) * 1.01  # Fallback

              # –ò–ª–∏ –ø–æ–ª—É—á–∞–µ–º –∏–∑ OrderBook Manager
              orderbook_manager = self.orderbook_managers.get(symbol)
              if orderbook_manager:
                snapshot = orderbook_manager.get_snapshot()
                if snapshot and snapshot.mid_price:
                  current_price = snapshot.mid_price

              # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é —á–µ—Ä–µ–∑ ExecutionManager
              await self.execution_manager.close_position(
                position_id=str(position_in_db.id),
                exit_price=current_price,
                exit_reason=f"Critical reversal: {reversal.reason}",
                exit_signal={
                  "type": "reversal",
                  "strength": reversal.strength.value,
                  "indicators": reversal.indicators_confirming,
                  "confidence": reversal.confidence
                }
              )

              logger.info(
                f"{symbol} | ‚úì Position closed due to critical reversal"
              )
            else:
              logger.error(
                f"{symbol} | Position found in RiskManager but not in DB!"
              )
          else:
            logger.warning(
              f"{symbol} | ‚ö†Ô∏è MANUAL INTERVENTION REQUIRED | "
              f"Auto-action disabled - please close position manually"
            )

        elif reversal.suggested_action == "reduce_size":
          logger.warning(
            f"{symbol} | üî∂ STRONG REVERSAL | "
            f"Strength: {reversal.strength.value} | "
            f"Suggestion: Reduce position size by 50%"
          )

          # –ß–∞—Å—Ç–∏—á–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ 50%
          position_in_db = await position_repository.find_open_by_symbol(symbol)

          if position_in_db:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É
            current_price = position.get('entry_price', 0) * 1.01  # Fallback

            orderbook_manager = self.orderbook_managers.get(symbol)
            if orderbook_manager:
              snapshot = orderbook_manager.get_snapshot()
              if snapshot and snapshot.mid_price:
                current_price = snapshot.mid_price

            # –í—ã–ø–æ–ª–Ω—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —á–µ—Ä–µ–∑ ExecutionManager
            try:
              result = await self.execution_manager.partial_close_position(
                position_id=str(position_in_db.id),
                close_percentage=0.5,  # –ó–∞–∫—Ä—ã–≤–∞–µ–º 50%
                exit_price=current_price,
                exit_reason=f"Strong reversal: {reversal.reason}"
              )

              if result and result.get('status') == 'success':
                logger.info(
                  f"{symbol} | ‚úì Partial close —É—Å–ø–µ—à–Ω–æ | "
                  f"Closed: {result['closed_quantity']}, "
                  f"Remaining: {result['remaining_quantity']}, "
                  f"Partial PnL: ${result['partial_pnl']:.2f}"
                )
              else:
                logger.error(
                  f"{symbol} | ‚úó Partial close failed - "
                  f"consider manual reduction"
                )
            except Exception as e:
              logger.error(
                f"{symbol} | Error during partial close: {e}",
                exc_info=True
              )
          else:
            logger.error(
              f"{symbol} | Position found in RiskManager but not in DB!"
            )

        elif reversal.suggested_action == "tighten_sl":
          logger.warning(
            f"{symbol} | üî∏ MODERATE REVERSAL | "
            f"Strength: {reversal.strength.value} | "
            f"Suggestion: Tighten stop loss"
          )

          # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ Stop Loss
          position_in_db = await position_repository.find_open_by_symbol(symbol)

          if position_in_db:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–∫—É—â–∏–π SL
            current_sl = position_in_db.stop_loss

            if not current_sl:
              logger.debug(f"{symbol} | No current SL set, skipping tighten")
            else:
              # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É
              current_price = position.get('entry_price', 0) * 1.01  # Fallback

              orderbook_manager = self.orderbook_managers.get(symbol)
              if orderbook_manager:
                snapshot = orderbook_manager.get_snapshot()
                if snapshot and snapshot.mid_price:
                  current_price = snapshot.mid_price

              # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–π –ø–æ–¥—Ç—è–Ω—É—Ç—ã–π SL
              entry_price = position_in_db.entry_price
              side = position_in_db.side.value

              if side == "BUY":
                # LONG: –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º SL –≤–≤–µ—Ä—Ö (–∫ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω–µ)
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ breakeven + 0.3% –¥–ª—è –∑–∞—â–∏—Ç—ã –ø—Ä–∏–±—ã–ª–∏
                new_sl = entry_price * 1.003

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–æ–≤—ã–π SL –ª—É—á—à–µ —Å—Ç–∞—Ä–æ–≥–æ –∏ –Ω–∏–∂–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã
                if not (new_sl > current_sl and new_sl < current_price):
                  # –§–æ–ª–ª–±—ç–∫: —Å–µ—Ä–µ–¥–∏–Ω–∞ –º–µ–∂–¥—É entry –∏ current
                  new_sl = (entry_price + current_price) / 2

              else:  # SELL
                # SHORT: –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º SL –≤–Ω–∏–∑ (–∫ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω–µ)
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ breakeven - 0.3% –¥–ª—è –∑–∞—â–∏—Ç—ã –ø—Ä–∏–±—ã–ª–∏
                new_sl = entry_price * 0.997

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–æ–≤—ã–π SL –ª—É—á—à–µ —Å—Ç–∞—Ä–æ–≥–æ –∏ –≤—ã—à–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã
                if not (new_sl < current_sl and new_sl > current_price):
                  # –§–æ–ª–ª–±—ç–∫: —Å–µ—Ä–µ–¥–∏–Ω–∞ –º–µ–∂–¥—É entry –∏ current
                  new_sl = (entry_price + current_price) / 2

              # –û–±–Ω–æ–≤–ª—è–µ–º SL —á–µ—Ä–µ–∑ ExecutionManager
              try:
                result = await self.execution_manager.update_stop_loss(
                  position_id=str(position_in_db.id),
                  new_stop_loss=new_sl,
                  reason=f"Moderate reversal: {reversal.reason}"
                )

                if result and result.get('status') == 'success':
                  logger.info(
                    f"{symbol} | ‚úì Stop Loss updated | "
                    f"Old SL: ${result['old_stop_loss']:.2f} ‚Üí "
                    f"New SL: ${result['new_stop_loss']:.2f}"
                  )
                else:
                  logger.error(
                    f"{symbol} | ‚úó SL update failed - "
                    f"consider manual adjustment"
                  )
              except Exception as e:
                logger.error(
                  f"{symbol} | Error during SL update: {e}",
                  exc_info=True
                )
          else:
            logger.error(
              f"{symbol} | Position found in RiskManager but not in DB!"
            )

        else:
          logger.debug(
            f"{symbol} | Weak reversal detected, no action required"
          )

      except Exception as e:
        logger.error(
          f"{symbol} | Error handling reversal signal: {e}",
          exc_info=True
        )

  async def _handle_websocket_message(self, message: Dict[str, Any]):
    """
    Unified –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ WebSocket —Å–æ–æ–±—â–µ–Ω–∏–π.
    –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞.

    Args:
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç WebSocket
    """
    try:
      # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–∏–ø–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (–¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –≤ WebSocketManager)
      message_type = message.get('_message_type')

      if message_type == 'trade':
        # –≠—Ç–æ market trade —Å–æ–æ–±—â–µ–Ω–∏–µ
        await self._handle_trade_message(message)
      else:
        # –≠—Ç–æ orderbook —Å–æ–æ–±—â–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        await self._handle_orderbook_message(message)

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –≤ unified websocket handler: {e}", exc_info=True)

  async def _handle_trade_message(self, message: Dict[str, Any]):
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π WebSocket –¥–ª—è market trades.
    –ü–∞—Ä—Å–∏—Ç –ø—É–±–ª–∏—á–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç –∏—Ö –≤ TradeManager.

    Args:
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç WebSocket

    –§–æ—Ä–º–∞—Ç Bybit publicTrade message:
    {
      "topic": "publicTrade.BTCUSDT",
      "type": "snapshot",
      "ts": 1672304486868,
      "data": [
        {
          "T": 1672304486868,  # timestamp
          "s": "BTCUSDT",      # symbol
          "S": "Buy",          # side
          "v": "0.001",        # volume (quantity)
          "p": "16578.50",     # price
          "L": "PlusTick",     # tick direction
          "i": "trade_id",     # trade ID
          "BT": false          # block trade indicator
        }
      ]
    }
    """
    try:
      topic = message.get("topic", "")
      data_list = message.get("data", [])

      if not data_list:
        return

      # –ò–∑–≤–ª–µ–∫–∞–µ–º symbol –∏–∑ topic: "publicTrade.BTCUSDT" -> "BTCUSDT"
      symbol = None
      if topic.startswith("publicTrade."):
        symbol = topic.split(".", 1)[1]

      if not symbol or symbol not in self.trade_managers:
        logger.warning(
          f"‚ö†Ô∏è Trade manager –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Å–∏–º–≤–æ–ª–∞ {symbol}, topic={topic}"
        )
        return

      trade_manager = self.trade_managers[symbol]

      # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é —Å–¥–µ–ª–∫—É –∏–∑ data –º–∞—Å—Å–∏–≤–∞
      for trade_data in data_list:
        try:
          # –°–æ–∑–¥–∞–µ–º MarketTrade –æ–±—ä–µ–∫—Ç
          market_trade = MarketTrade(
            trade_id=trade_data.get("i", ""),
            symbol=trade_data.get("s", symbol),
            side=trade_data.get("S", "Buy"),  # "Buy" –∏–ª–∏ "Sell"
            price=float(trade_data.get("p", 0)),
            quantity=float(trade_data.get("v", 0)),
            timestamp=int(trade_data.get("T", 0)),  # milliseconds
            is_block_trade=trade_data.get("BT", False)
          )

          # –î–æ–±–∞–≤–ª—è–µ–º –≤ TradeManager
          trade_manager.add_trade(market_trade)

        except (ValueError, KeyError) as e:
          logger.warning(
            f"{symbol} | –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ trade: {e}, data={trade_data}"
          )

    except Exception as e:
      logger.error(
        f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ trade message: {e}",
        exc_info=True
      )

  async def _handle_orderbook_message(self, message: Dict[str, Any]):
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π WebSocket –¥–ª—è —Å—Ç–∞–∫–∞–Ω–∞.
    –û–±–Ω–æ–≤–ª—è–µ—Ç OrderBookManager –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π snapshot.

    Args:
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç WebSocket
    """
    try:
        # symbol = message.get("s")
        topic = message.get("topic", "")
        symbol = message.get("s")  # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ø–æ–ª—è 's'

        # –ï—Å–ª–∏ 's' –Ω–µ—Ç, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ topic
        if not symbol and topic:
          # topic —Ñ–æ—Ä–º–∞—Ç: "orderbook.200.APRUSDT"
          parts = topic.split(".")
          if len(parts) >= 3:
            symbol = parts[2]
        msg_type = message.get("type")
        # topic = message.get("topic", "unknown")
        data = message.get("data", {})

        # –î–ï–ë–ê–ì: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        # logger.info(f"üì® _handle_orderbook_message: symbol={symbol}, type={msg_type}, topic={topic}")

        # –ï—Å–ª–∏ symbol –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –µ–≥–æ –∏–∑ topic (–¥–ª—è Bybit)
        if symbol is None and topic.startswith("orderbook."):
            parts = topic.split(".")
            if len(parts) == 3:
                symbol = parts[2]
                logger.info(f"üîç [{symbol}] –°–∏–º–≤–æ–ª –∏–∑–≤–ª–µ—á–µ–Ω –∏–∑ topic")
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–∏–º–≤–æ–ª –∏–∑ topic: {topic}")
                return

        if not symbol or symbol not in self.orderbook_managers:
            logger.warning(f"‚ö†Ô∏è –°–∏–º–≤–æ–ª {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ orderbook_managers –∏–ª–∏ –ø—É—Å—Ç–æ–π")
            logger.info(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã: {list(self.orderbook_managers.keys())}")
            return

        manager = self.orderbook_managers[symbol]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π snapshot –∫–∞–∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–µ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ
        if manager.snapshot_received:
            current_snapshot = manager.get_snapshot()
            if current_snapshot:
                # MEMORY OPTIMIZATION: LRU cache with size limit
                # Evict oldest snapshots when cache is full
                if len(self.prev_orderbook_snapshots) >= self.MAX_PREV_SNAPSHOTS:
                    # Remove oldest entry (FIFO)
                    oldest_symbol, _ = self.prev_orderbook_snapshots.popitem(last=False)
                    logger.debug(f"[LRU Cache] Evicted prev_snapshot for {oldest_symbol}")

                # Add/update snapshot (moves to end if exists)
                self.prev_orderbook_snapshots[symbol] = current_snapshot
                self.prev_orderbook_snapshots.move_to_end(symbol)  # Mark as recently used

                self.last_snapshot_update[symbol] = current_snapshot.timestamp
                logger.debug(
                    f"[{symbol}] –°–æ—Ö—Ä–∞–Ω–µ–Ω –ø—Ä–µ–¥—ã–¥—É—â–∏–π snapshot: "
                    f"mid_price={current_snapshot.mid_price:.2f}, "
                    f"cache_size={len(self.prev_orderbook_snapshots)}/{self.MAX_PREV_SNAPSHOTS}"
                )

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        if msg_type == "snapshot":
            logger.info(f"‚úÖ [{symbol}] –ü—Ä–∏–º–µ–Ω—è–µ–º snapshot...")
            manager.apply_snapshot(data)
            logger.info(
                f"[{symbol}] Snapshot –ø—Ä–∏–º–µ–Ω–µ–Ω: "
                f"{len(manager.bids)} bids, {len(manager.asks)} asks"
            )

        elif msg_type == "delta":
            if not manager.snapshot_received:
                logger.debug(f"[{symbol}] Delta –ø–æ–ª—É—á–µ–Ω–∞ –¥–æ snapshot, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return
            manager.apply_delta(data)
            logger.debug(f"[{symbol}] Delta –ø—Ä–∏–º–µ–Ω–µ–Ω–∞")

        else:
            logger.warning(f"‚ö†Ô∏è [{symbol}] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è: {msg_type}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ orderbook message: {e}", exc_info=True)
        if not isinstance(e, (OrderBookSyncError, OrderBookError)):
            log_exception(logger, e, "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞–∫–∞–Ω–∞")  # –ï—Å–ª–∏ log_exception —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

  def get_status(self) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –±–æ—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π ML –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π."""

    # ========================================
    # –°–£–©–ï–°–¢–í–£–Æ–©–ê–Ø –õ–û–ì–ò–ö–ê (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô)
    # ========================================

    ws_status: Dict[Any, Any] = {}
    if self.websocket_manager:
      ws_status = self.websocket_manager.get_connection_statuses()

    # ===== –°–£–©–ï–°–¢–í–£–Æ–©–ê–Ø ML —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ =====
    ml_status: Dict[str, Any] = {
      "features_extracted": len(self.latest_features),
      "data_collected_samples": (
        self.ml_data_collector.get_statistics()
        if self.ml_data_collector else {}
      )
    }

    # ========================================
    # –†–ê–°–®–ò–†–ï–ù–ò–ï ml_status –ù–û–í–´–ú–ò –ú–ï–¢–†–ò–ö–ê–ú–ò
    # ========================================

    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
    try:
      ml_status["ml_integration_enabled"] = getattr(
        settings, 'ML_RISK_INTEGRATION_ENABLED', False
      )
    except Exception:
      ml_status["ml_integration_enabled"] = False

    # ML Validator —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if hasattr(self, 'ml_validator') and self.ml_validator:
      try:
        validator_stats = self.ml_validator.get_statistics()
        ml_status["validator"] = {
          "total_validations": validator_stats.get("total_validations", 0),
          "ml_success_count": validator_stats.get("ml_success_count", 0),
          "fallback_count": validator_stats.get("fallback_count", 0),
          "agreement_count": validator_stats.get("agreement_count", 0),
          "ml_server_available": validator_stats.get("ml_server_available", False),
          "success_rate": validator_stats.get("success_rate", 0.0),
          "agreement_rate": validator_stats.get("agreement_rate", 0.0),
          "fallback_rate": validator_stats.get("fallback_rate", 0.0),
          # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
          "avg_mae": validator_stats.get("avg_mae"),
          "avg_manipulation_risk": validator_stats.get("avg_manipulation_risk", 0.0)
        }
      except Exception as e:
        logger.debug(f"Cannot get ML validator stats: {e}")
        ml_status["validator"] = {"status": "unavailable"}
    else:
      ml_status["validator"] = {"status": "not_initialized"}

    # ML-Enhanced Risk Manager —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if (
        hasattr(self, 'risk_manager') and
        hasattr(self.risk_manager, 'get_ml_stats')
    ):
      try:
        ml_risk_stats = self.risk_manager.get_ml_stats()
        ml_status["risk_manager"] = {
          "ml_enabled": ml_risk_stats.get("ml_enabled", False),
          "total_validations": ml_risk_stats.get("total_validations", 0),
          "ml_used": ml_risk_stats.get("ml_used", 0),
          "ml_rejected": ml_risk_stats.get("ml_rejected", 0),
          "fallback_used": ml_risk_stats.get("fallback_used", 0),
          "ml_usage_rate": ml_risk_stats.get("ml_usage_rate", 0.0),
          "ml_rejection_rate": ml_risk_stats.get("ml_rejection_rate", 0.0)
        }
      except Exception as e:
        logger.debug(f"Cannot get ML risk manager stats: {e}")
        ml_status["risk_manager"] = {"status": "unavailable"}
    else:
      ml_status["risk_manager"] = {"status": "standard_mode"}

    # Feature Pipeline —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if hasattr(self, 'ml_feature_pipeline') and self.ml_feature_pipeline:
      try:
        symbols_with_features = list(self.latest_features.keys()) if hasattr(self, 'latest_features') else []
        ml_status["feature_pipeline"] = {
          "active": True,
          "symbols_count": len(symbols_with_features),
          "recent_symbols": symbols_with_features[:10]
        }
      except Exception as e:
        logger.debug(f"Cannot get feature pipeline stats: {e}")
        ml_status["feature_pipeline"] = {"active": False}
    else:
      ml_status["feature_pipeline"] = {"active": False}

    # ========================================
    # –ë–ê–ó–û–í–´–ô RETURN (–°–£–©–ï–°–¢–í–£–Æ–©–ê–Ø –°–¢–†–£–ö–¢–£–†–ê)
    # ========================================

    status_dict: Dict[str, Any] = {
      "status": self.status.value,
      "symbols": self.symbols,
      "ml_enabled": True,  # –°–£–©–ï–°–¢–í–£–Æ–©–ï–ï
      "ml_status": ml_status,  # –†–ê–°–®–ò–†–ï–ù–ù–û–ï
      "websocket_connections": ws_status,
      "orderbook_managers": {
        symbol: manager.get_stats()
        for symbol, manager in self.orderbook_managers.items()
      },
      "execution_stats": (
        self.execution_manager.get_statistics()
        if self.execution_manager else {}
      ),
    }

    # ========================================
    # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò (–ù–û–í–´–ï –ö–õ–Æ–ß–ò)
    # ========================================

    # Risk Manager metrics
    if hasattr(self, 'risk_manager') and self.risk_manager:
      try:
        status_dict["risk_metrics"] = self.risk_manager.metrics.to_dict()
        status_dict["active_positions"] = len(self.risk_manager.open_positions)
        status_dict["open_positions_list"] = list(
          self.risk_manager.open_positions.keys()
        )
      except Exception as e:
        logger.debug(f"Cannot get risk metrics: {e}")

    # Balance Tracker
    try:
      from backend.utils.balance_tracker import balance_tracker
      balance_stats = balance_tracker.get_stats()
      status_dict["balance"] = {
        "current": balance_stats.get("current_balance", 0.0),
        "initial": balance_stats.get("initial_balance", 0.0),
        "total_pnl": balance_stats.get("total_pnl", 0.0),
        "total_pnl_percentage": balance_stats.get("total_pnl_percentage", 0.0)
      }
    except Exception as e:
      logger.debug(f"Cannot get balance stats: {e}")

    # Daily Loss Killer
    try:
      from backend.strategy.daily_loss_killer import daily_loss_killer
      dlk_stats = daily_loss_killer.get_statistics()
      status_dict["daily_loss_killer"] = {
        "trading_allowed": dlk_stats.get("is_allowed", True),
        "daily_pnl": dlk_stats.get("daily_pnl", 0.0),
        "daily_loss_percent": dlk_stats.get("daily_loss_percent", 0.0),
        "max_loss_percent": dlk_stats.get("max_daily_loss_percent", 0.0)
      }
    except Exception as e:
      logger.debug(f"Cannot get daily loss killer stats: {e}")

    # Correlation Manager
    try:
      from backend.strategy.correlation_manager import correlation_manager
      corr_stats = correlation_manager.get_statistics()
      status_dict["correlation_stats"] = {
        "total_groups": corr_stats.get("total_groups", 0),
        "total_symbols": corr_stats.get("total_symbols", 0),
        "active_positions": corr_stats.get("active_positions", 0)
      }
    except Exception as e:
      logger.debug(f"Cannot get correlation stats: {e}")

    # Position Monitor (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if hasattr(self, 'position_monitor') and self.position_monitor:
      try:
        status_dict["position_monitor"] = self.position_monitor.get_statistics()
      except Exception as e:
        logger.debug(f"Cannot get position monitor stats: {e}")

    # Timestamp
    status_dict["timestamp"] = datetime.now().isoformat()

    return status_dict

  async def _ml_stats_loop(self):
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–±–æ—Ä–∞ ML –¥–∞–Ω–Ω—ã—Ö.

    –í—ã–≤–æ–¥–∏—Ç:
    - –û–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–≤—Å–µ–≥–æ —Å–µ–º–ø–ª–æ–≤, —Ñ–∞–π–ª–æ–≤)
    - –î–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–∂–¥–æ–º—É —Å–∏–º–≤–æ–ª—É
    """
    logger.info("–ó–∞–ø—É—â–µ–Ω —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ ML —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")

    while True:
      try:
        await asyncio.sleep(300)  # –ö–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç

        # MEMORY FIX: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ —Å –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–º –ø–æ—Ä–æ–≥–æ–º
        memory_mb = get_memory_usage()

        if memory_mb > 4000:  # MEMORY FIX: 8000 ‚Üí 4000 (trigger cleanup earlier)
          logger.warning(f"‚ö†Ô∏è HIGH MEMORY USAGE: {memory_mb:.1f} MB - –∑–∞–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏")
          await self._cleanup_memory()
          # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
          memory_after = get_memory_usage()
          logger.info(
            f"üìä Memory: {memory_mb:.1f} MB ‚Üí {memory_after:.1f} MB (–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {memory_mb - memory_after:.1f} MB)")

        if self.ml_data_collector:
          stats = self.ml_data_collector.get_statistics()

          # ===== –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—ã–≤–æ–¥–∏–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É =====
          logger.info(
            f"ML Stats | –û–ë–©–ê–Ø: "
            f"–≤—Å–µ–≥–æ_—Å–µ–º–ø–ª–æ–≤={stats['total_samples_collected']:,}, "
            f"—Ñ–∞–π–ª–æ–≤={stats['files_written']}, "
            f"–∏—Ç–µ—Ä–∞—Ü–∏–π={stats['iteration_counter']}, "
            f"–∏–Ω—Ç–µ—Ä–≤–∞–ª={stats['collection_interval']}"
            f"–∏–Ω—Ç–µ—Ä–≤–∞–ª={stats['collection_interval']}, "
            f"–ø–∞–º—è—Ç—å={memory_mb:.1f}MB"  # –ù–û–í–û–ï: –í—ã–≤–æ–¥ –ø–∞–º—è—Ç–∏
          )

          # ===== –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ stats["symbols"], –∞ –Ω–µ stats =====
          symbol_stats = stats.get("symbols", {})

          if not symbol_stats:
            logger.info("ML Stats | –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–∏–º–≤–æ–ª–∞–º")
          else:
            for symbol, stat in symbol_stats.items():
              # ===== –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–ª—é—á–∏ =====
              logger.info(
                f"ML Stats | {symbol}: "
                f"samples={stat['total_samples']:,}, "
                f"batch={stat['current_batch']}, "  # ‚Üê –ù–ï 'batches_saved'
                f"buffer={stat['buffer_size']}/{self.ml_data_collector.max_samples_per_file}"
              )

      except asyncio.CancelledError:
        logger.info("ML stats loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (CancelledError)")
        break
      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ ML stats loop: {e}")
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π traceback –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        import traceback
        logger.error(f"Traceback:\n{traceback.format_exc()}")

  async def _cleanup_memory(self):
    """
    –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–µ–∫.

    IMPORTANT: Python Memory Management Reality
    ==========================================
    Python's memory allocator (pymalloc) and malloc() do NOT always return freed
    memory back to the OS immediately. This is BY DESIGN for performance:

    1. Memory Fragmentation:
       - Python keeps freed memory in internal arenas for reuse
       - Small objects (< 512 bytes) use pymalloc which rarely returns memory to OS
       - Large objects use malloc() which MAY return memory via malloc_trim(0)

    2. Expected Behavior:
       - RSS (Resident Set Size) may NOT decrease after cleanup
       - Memory is freed INTERNALLY but kept in process for reuse
       - This is NORMAL and not a bug

    3. What We Can Do:
       - Prevent accumulation by limiting cache sizes
       - Use LRU eviction to cap memory growth
       - Call malloc_trim(0) to encourage OS return (not guaranteed)
       - Monitor object counts (not just RSS) to detect real leaks

    4. Real Leaks vs. Apparent Leaks:
       - Real leak: object count grows indefinitely
       - Apparent leak: RSS stays high but objects are freed (reusable memory)

    This cleanup focuses on preventing REAL leaks (growing object counts),
    not forcing RSS reduction (which is often impossible in Python).

    –û—á–∏—â–∞–µ—Ç:
    - ML –±—É—Ñ–µ—Ä—ã (—á–µ—Ä–µ–∑ MLDataCollector._emergency_save_all_buffers())
    - OrderBook –∫—ç—à–∏ (—á–µ—Ä–µ–∑ OrderBookManager.clear_old_data())
    - Python garbage collector
    """
    try:
      logger.info("üßπ –ù–∞—á–∞–ª–æ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏...")

      # MEMORY PROFILING: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
      if settings.ENABLE_MEMORY_PROFILING:
        import tracemalloc
        if not tracemalloc.is_tracing():
          tracemalloc.start()
          logger.info("  üî¨ Memory profiling started")

        snapshot_before = tracemalloc.take_snapshot()

      # 1. üö® –≠–ö–°–¢–†–ï–ù–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï ML –±—É—Ñ–µ—Ä–æ–≤ (–≤–º–µ—Å—Ç–æ —É—Ä–µ–∑–∞–Ω–∏—è!)
      if self.ml_data_collector:
        await self.ml_data_collector._emergency_save_all_buffers()
        logger.info("  ‚úì ML –±—É—Ñ–µ—Ä—ã —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

      # 2. –û—á–∏—Å—Ç–∫–∞ OrderBook –∫—ç—à–µ–π
      cleaned_count = 0
      cached_snapshots_cleared = 0
      for manager in self.orderbook_managers.values():
        if hasattr(manager, 'clear_old_data'):
          manager.clear_old_data()
          cleaned_count += 1

        # MEMORY OPTIMIZATION: –Ø–≤–Ω–æ –æ—á–∏—â–∞–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ snapshots
        if hasattr(manager, '_cached_snapshot') and manager._cached_snapshot is not None:
          manager._cached_snapshot = None
          manager._snapshot_dirty = True  # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Å—Ç—Å—è –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º get_snapshot()
          cached_snapshots_cleared += 1

      if cleaned_count > 0:
        logger.info(
          f"  ‚úì OrderBook –∫—ç—à–∏ –æ—á–∏—â–µ–Ω—ã ({cleaned_count} —Å–∏–º–≤–æ–ª–æ–≤, "
          f"{cached_snapshots_cleared} cached snapshots)"
        )

      # 2b. –û—á–∏—Å—Ç–∫–∞ prev_orderbook_snapshots (LRU cache)
      prev_snapshots_count = len(self.prev_orderbook_snapshots)
      if prev_snapshots_count > 10:
        # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ —É—Ä–µ–∑–∞—Ç—å –¥–æ 10 (–º–∞–∫—Å 20)
        while len(self.prev_orderbook_snapshots) > 10:
          self.prev_orderbook_snapshots.popitem(last=False)
        logger.info(f"  ‚úì prev_orderbook_snapshots —É—Ä–µ–∑–∞–Ω: {prev_snapshots_count} ‚Üí 10")

      # 3. CRITICAL: –û—á–∏—Å—Ç–∫–∞ Feature Pipeline –∫—ç—à–µ–π –∏ –∏—Å—Ç–æ—Ä–∏–π
      if self.ml_feature_pipeline and hasattr(self.ml_feature_pipeline, 'pipelines'):
        cache_cleared = 0
        history_cleared = 0
        for symbol, pipeline in self.ml_feature_pipeline.pipelines.items():
          # –û—á–∏—Å—Ç–∏—Ç—å _cache (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç—ã—Å—è—á–∏ FeatureVector!)
          if hasattr(pipeline, '_cache') and pipeline._cache:
            cache_size = len(pipeline._cache)
            pipeline._cache.clear()
            cache_cleared += cache_size

          # –û—á–∏—Å—Ç–∏—Ç—å FeatureScalerManager.feature_history (–¥–æ 5000 —Å–µ–º–ø–ª–æ–≤ √ó 112 —Ñ–∏—á!)
          if hasattr(pipeline, 'scaler_manager') and pipeline.scaler_manager:
            if hasattr(pipeline.scaler_manager, 'feature_history'):
              history_size = len(pipeline.scaler_manager.feature_history)
              pipeline.scaler_manager.feature_history.clear()
              history_cleared += history_size

          # BALANCED: Partial cleanup to preserve analysis quality
          # Keep minimum data for feature extraction (volatility, frequency, etc.)
          if hasattr(pipeline, 'orderbook_extractor'):
            ob_ext = pipeline.orderbook_extractor
            if hasattr(ob_ext, 'snapshot_history'):
              # Keep last 5 snapshots (instead of clearing all 20)
              # Needed for: volatility calculation, update frequency, net volume change
              while len(ob_ext.snapshot_history) > 5:
                ob_ext.snapshot_history.popleft()
            if hasattr(ob_ext, 'level_ttl_history'):
              # Keep last 10 TTL records (instead of clearing all 50)
              while len(ob_ext.level_ttl_history) > 10:
                ob_ext.level_ttl_history.popleft()

          if hasattr(pipeline, 'indicator_extractor'):
            ind_ext = pipeline.indicator_extractor
            if hasattr(ind_ext, 'candle_history') and len(ind_ext.candle_history) > 50:
              ind_ext.candle_history = ind_ext.candle_history[-50:]  # –û—Å—Ç–∞–≤–∏—Ç—å 50 –∏–∑ 100

        if cache_cleared > 0 or history_cleared > 0:
          logger.info(f"  ‚úì Feature Pipeline –æ—á–∏—â–µ–Ω: cache={cache_cleared}, history={history_cleared}")

      # 4. AGGRESSIVE: –û—á–∏—Å—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
      if hasattr(self, 'layering_detector') and self.layering_detector:
        # CRITICAL: Clear order_history to prevent unbounded growth
        if hasattr(self.layering_detector, 'trackers'):
          for symbol, sides in self.layering_detector.trackers.items():
            for side, tracker in sides.items():
              if hasattr(tracker, 'order_history'):
                # Cleanup old data (keeps last 5 minutes)
                cutoff = get_timestamp_ms() - (5 * 60 * 1000)
                tracker.cleanup_old_history(cutoff)

        # Clear price history
        if hasattr(self.layering_detector, 'price_history'):
          for symbol_history in self.layering_detector.price_history.values():
            # Deque with maxlen will auto-manage, but clear aggressively during cleanup
            if len(symbol_history) > 250:
              # Keep only last 250 (was 500)
              while len(symbol_history) > 250:
                symbol_history.popleft()

        # Clear old detected patterns (keep last 50)
        if hasattr(self.layering_detector, 'detected_patterns'):
          for symbol, patterns in self.layering_detector.detected_patterns.items():
            # deque with maxlen=100, but clear aggressively to 50
            while len(patterns) > 50:
              patterns.popleft()

        logger.info("  ‚úì Layering detector –æ—á–∏—â–µ–Ω (order_history, price_history, patterns)")

      # 4b. BALANCED: QuoteStuffing detector partial cleanup
      if hasattr(self, 'quote_stuffing_detector') and self.quote_stuffing_detector:
        if hasattr(self.quote_stuffing_detector, 'update_trackers'):
          total_snapshots_trimmed = 0
          for symbol, tracker in self.quote_stuffing_detector.update_trackers.items():
            # BALANCED: Keep last 3 snapshots (instead of clearing all)
            # Needed to detect update frequency patterns
            if hasattr(tracker, 'update_snapshots') and len(tracker.update_snapshots) > 3:
              snapshots_before = len(tracker.update_snapshots)
              while len(tracker.update_snapshots) > 3:
                tracker.update_snapshots.popleft()
              total_snapshots_trimmed += (snapshots_before - 3)

            # –£—Ä–µ–∑–∞—Ç—å timestamps —Å 1000 –¥–æ 200
            if hasattr(tracker, 'update_timestamps') and len(tracker.update_timestamps) > 200:
              while len(tracker.update_timestamps) > 200:
                tracker.update_timestamps.popleft()

          if total_snapshots_trimmed > 0:
            logger.info(f"  ‚úì QuoteStuffing detector –æ—á–∏—â–µ–Ω: —É—Ä–µ–∑–∞–Ω–æ {total_snapshots_trimmed} snapshots (–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –ø–æ 3)")

      # 4c. CRITICAL: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞ LayeringDataCollector –±—É—Ñ–µ—Ä–∞
      if hasattr(self, 'layering_data_collector') and self.layering_data_collector:
        buffer_size = len(self.layering_data_collector.data_buffer)
        if buffer_size > 0:
          logger.info(f"  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Layering ML buffer: {buffer_size} samples")
          self.layering_data_collector.save_to_disk()
          logger.info(f"  ‚úì Layering ML buffer —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∏ –æ—á–∏—â–µ–Ω")

      # 4d. BALANCED: Spoofing detector cleanup with extended window
      if hasattr(self, 'spoofing_detector') and self.spoofing_detector:
        total_level_history_cleared = 0
        total_events_cleared = 0

        # BALANCED: Keep 90 seconds of history (reduced from 120s due to OrderEvent growth)
        # Spoofing patterns typically appear in 10-60 second windows
        cutoff_time = get_timestamp_ms() - (90 * 1000)  # –°—Ç–∞—Ä—à–µ 90 —Å–µ–∫ (was 120)

        for symbol in list(self.spoofing_detector.level_history.keys()):
          for side in ["bid", "ask"]:
            history_side = self.spoofing_detector.level_history[symbol][side]

            # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã–µ —É—Ä–æ–≤–Ω–∏
            old_prices = [
              price for price, level in history_side.items()
              if level.last_seen and level.last_seen < cutoff_time
            ]

            for price in old_prices:
              level = history_side[price]
              total_events_cleared += len(level.events)
              del history_side[price]
              total_level_history_cleared += 1

        if total_level_history_cleared > 0:
          logger.info(
            f"  ‚úì Spoofing detector –æ—á–∏—â–µ–Ω: {total_level_history_cleared} old levels (>90 sec), "
            f"{total_events_cleared} OrderEvent released"
          )

      # 5. –Ø–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –ø–µ—Ä–µ–¥ GC
      if self.ml_feature_pipeline and hasattr(self.ml_feature_pipeline, 'pipelines'):
        for symbol, pipeline in self.ml_feature_pipeline.pipelines.items():
          # Clear last feature vector reference
          pipeline._last_feature_vector = None

          # Clear scaler manager internal state
          if hasattr(pipeline, 'scaler_manager') and pipeline.scaler_manager:
            # Clear feature names (list of strings)
            if hasattr(pipeline.scaler_manager, 'feature_names'):
              pipeline.scaler_manager.feature_names.clear()

      # 6. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞ (4 –ø—Ä–æ—Ö–æ–¥–∞ –¥–ª—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫)
      # –†–∞–∑–±–ª–æ–∫–∏—Ä—É–µ–º –≤—Å–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è –ø–µ—Ä–µ–¥ —Å–±–æ—Ä–∫–æ–π
      gc.collect(0)  # Collect generation 0
      gc.collect(1)  # Collect generation 1
      gc.collect(2)  # Collect generation 2 (full)

      # SAFE: Numpy memory cleanup (without dangerous reload)
      # The key is preventing accumulation, not forcing release
      numpy_memory_freed = False
      try:
        import numpy as np

        # Method 1: Clear numpy internal temp array cache (safe)
        # This clears _global_ufunc_cache and similar structures
        try:
          # Trigger cleanup by calling gc on numpy arrays
          # This is safe and documented
          collected_before_np = gc.collect()

          # Small allocation-deallocation cycle to hint numpy to release pools
          # Using small arrays (not 100MB!) to avoid performance hit
          for dtype in [np.float64, np.float32]:
            try:
              # 1MB is enough to hint the allocator
              temp = np.empty(125000, dtype=dtype)  # 1MB
              del temp
            except:
              pass

          collected_after_np = gc.collect()

          numpy_memory_freed = True
          logger.debug(f"  ‚úì Numpy cleanup: collected {collected_after_np} objects")

        except Exception as e:
          logger.debug(f"  ‚ö†Ô∏è Numpy cleanup failed: {e}")
          pass

      except Exception as e:
        logger.debug(f"  ‚ö†Ô∏è Numpy memory cleanup skipped: {e}")
        pass

      # BALANCED: Partial cleanup of cyclic references
      # NOTE: SpoofingDetector level_history already cleaned above (>2 min old)
      # Here we only clean structures not already handled
      refs_cleared = 0

      # LayeringDetector: already cleaned by cleanup_old_history in block 4a
      # No need for additional clearing here - data already bounded by deque maxlen

      # SR level detector: keep recent levels, clear only very old
      if hasattr(self, 'sr_level_detector') and self.sr_level_detector:
        if hasattr(self.sr_level_detector, 'candle_history'):
          for symbol in list(self.sr_level_detector.candle_history.keys()):
            # Keep last 100 candles (instead of clearing all)
            candle_list = self.sr_level_detector.candle_history[symbol]
            if len(candle_list) > 100:
              removed = len(candle_list) - 100
              self.sr_level_detector.candle_history[symbol] = candle_list[-100:]
              refs_cleared += removed

      if refs_cleared > 0:
        logger.info(f"  ‚úì –ß–∞—Å—Ç–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {refs_cleared} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π —É–¥–∞–ª–µ–Ω–æ")

      # AGGRESSIVE: –ü–æ–ª–Ω–∞—è —Å–±–æ—Ä–∫–∞ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ö–æ–¥–∞–º–∏ –¥–ª—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫
      total_collected = 0
      for _ in range(5):  # 5 –ø—Ä–æ—Ö–æ–¥–æ–≤ –¥–ª—è —É–ø—Ä—è–º—ã—Ö —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫
        total_collected += gc.collect()

      logger.info(f"  ‚úì Garbage collector: —Å–æ–±—Ä–∞–Ω–æ {total_collected} –æ–±—ä–µ–∫—Ç–æ–≤ (8 –ø—Ä–æ—Ö–æ–¥–æ–≤ –≤—Å–µ–≥–æ)")

      # DIAGNOSTIC: Log object counts to identify memory leaks
      try:
        all_objects = gc.get_objects()
        total_objects = len(all_objects)

        # Count objects by type
        type_counts = {}
        for obj in all_objects:
          obj_type = type(obj).__name__
          type_counts[obj_type] = type_counts.get(obj_type, 0) + 1

        # Get top 20 most common object types for detailed diagnostics
        top_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:20]

        logger.info(f"  üìä Total objects in memory: {total_objects:,}")
        logger.info("  üìä Top 20 object types:")
        for obj_type, count in top_types:
          logger.info(f"     {obj_type}: {count:,}")

        # Check for specific potential leaks
        feature_vectors = type_counts.get('FeatureVector', 0)
        snapshots = type_counts.get('OrderBookSnapshot', 0)
        ndarrays = type_counts.get('ndarray', 0)

        # UPDATED THRESHOLDS based on actual steady-state measurements:
        # For 15 symbols with optimized settings:
        # - prev_snapshots: 20
        # - orderbook_extractor: 15 √ó 20 = 300
        # - quote_stuffing: 15 √ó 10 = 150
        # - active processing: ~14
        # Expected total: ~484 snapshots (steady state)

        if feature_vectors > 500:
          logger.warning(f"  ‚ö†Ô∏è HIGH FeatureVector count: {feature_vectors} (expected < 500)")

        if snapshots > 550:
          # Warn if significantly above expected steady-state
          logger.warning(f"  ‚ö†Ô∏è HIGH OrderBookSnapshot count: {snapshots} (expected < 550)")
        elif snapshots > 500:
          # Info if slightly elevated but not alarming
          logger.info(f"  ‚ÑπÔ∏è Elevated OrderBookSnapshot count: {snapshots} (normal range: 450-500)")
        else:
          # Healthy range
          logger.debug(f"  ‚úì Healthy OrderBookSnapshot count: {snapshots} (steady state)")

        if ndarrays > 5000:
          logger.warning(f"  ‚ö†Ô∏è HIGH ndarray count: {ndarrays} (expected < 5000)")

        # Additional leak diagnostics
        dicts = type_counts.get('dict', 0)
        lists = type_counts.get('list', 0)
        deques = type_counts.get('deque', 0)
        tuples = type_counts.get('tuple', 0)
        orderbook_levels = type_counts.get('OrderBookLevel', 0)

        logger.info(f"  üìä Data structures: dict={dicts:,}, list={lists:,}, deque={deques:,}, tuple={tuples:,}")
        logger.info(f"  üìä Trading objects: OrderBookLevel={orderbook_levels:,}, FeatureVector={feature_vectors:,}")

      except Exception as e:
        logger.debug(f"  ‚ö†Ô∏è Object diagnostic failed: {e}")

      # CRITICAL: Return memory to OS (CPython-specific)
      # This is essential for preventing the 13GB memory growth issue
      try:
        import ctypes
        if os.name == 'posix':  # Linux/Unix
          try:
            # Try libc.so.6 first (most common)
            libc = ctypes.CDLL('libc.so.6')
            if hasattr(libc, 'malloc_trim'):
              result = libc.malloc_trim(0)  # Return all freed memory to OS
              logger.info(f"  ‚úì malloc_trim(0) executed on Linux (result={result})")
          except Exception as e:
            logger.debug(f"  ‚ö†Ô∏è malloc_trim failed: {e}")
            # Try alternative: force madvise via /proc
            try:
              import mmap
              # This helps Linux kernel reclaim memory pages
              with open('/proc/self/smaps', 'r') as f:
                # Reading smaps can trigger kernel memory reclaim
                _ = f.read()
              logger.debug("  ‚úì Triggered kernel memory reclaim via /proc/self/smaps")
            except:
              pass
        elif os.name == 'nt':  # Windows
          try:
            # Windows uses different memory management
            libc = ctypes.CDLL('msvcrt.dll')
            # _heapmin() compacts the heap and returns memory to OS
            if hasattr(libc, '_heapmin'):
              result = libc._heapmin()
              logger.info(f"  ‚úì _heapmin() executed on Windows (result={result})")
          except Exception as e:
            logger.debug(f"  ‚ö†Ô∏è _heapmin failed: {e}")

        # ADDITIONAL: Set Python memory allocator arena threshold lower
        # This encourages Python to release memory arenas back to OS sooner
        try:
          import sys
          if hasattr(sys, 'get_int_max_str_digits'):
            # Python 3.10+ - we can manipulate allocator behavior
            # Force arena release by triggering gc with low threshold
            gc.set_threshold(500, 5, 5)  # More aggressive GC
            logger.debug("  ‚úì Set aggressive GC thresholds (500, 5, 5)")
        except:
          pass

      except Exception as e:
        logger.warning(f"  ‚ö†Ô∏è Failed to return memory to OS: {e}")
        pass

      # Show GC stats
      gc_stats = gc.get_stats()
      logger.debug(f"  GC stats: {gc_stats}")

      # MEMORY PROFILING: –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π –ø–∞–º—è—Ç–∏
      if settings.ENABLE_MEMORY_PROFILING:
        snapshot_after = tracemalloc.take_snapshot()
        top_stats = snapshot_after.compare_to(snapshot_before, 'lineno')

        logger.info("  üî¨ Top 10 memory changes:")
        for stat in top_stats[:10]:
          logger.info(f"    {stat}")

      logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏: {e}")

  async def _layering_ml_save_loop(self):
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Layering ML training data.

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±—É—Ñ–µ—Ä –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö.
    """
    logger.info("üíæ –ó–∞–ø—É—â–µ–Ω —Ü–∏–∫–ª –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Layering ML data")

    while self.running:
      try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç
        await asyncio.sleep(1800)

        if self.layering_data_collector:
          buffer_size = len(self.layering_data_collector.data_buffer)

          if buffer_size > 0:
            logger.info(
              f"üíæ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Layering ML data: "
              f"{buffer_size} samples –≤ –±—É—Ñ–µ—Ä–µ"
            )

            self.layering_data_collector.save_to_disk()

            stats = self.layering_data_collector.get_statistics()
            logger.info(
              f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: collected={stats['total_collected']}, "
              f"labeled={stats['total_labeled']} ({stats['labeling_rate']*100:.1f}%), "
              f"files={stats['files_on_disk']}"
            )
          else:
            logger.debug("üíæ Layering ML buffer –ø—É—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ")

      except asyncio.CancelledError:
        logger.info("Layering ML save loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (CancelledError)")
        break
      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ Layering ML save loop: {e}")

  async def _screener_broadcast_loop(self):
    """
    –¶–∏–∫–ª —Ä–∞—Å—Å—ã–ª–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å–∫—Ä–∏–Ω–µ—Ä–∞ —á–µ—Ä–µ–∑ WebSocket.
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥.
    """
    from backend.api.websocket import broadcast_screener_update

    interval = settings.SCREENER_BROADCAST_INTERVAL
    logger.info(f"–ó–∞–ø—É—â–µ–Ω screener broadcast loop (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {interval}s)")

    while self.status == BotStatus.RUNNING:
      try:
        if self.screener_manager:
          pairs = self.screener_manager.get_all_pairs()
          await broadcast_screener_update(pairs)

        await asyncio.sleep(interval)

      except asyncio.CancelledError:
        break
      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ screener broadcast loop: {e}")
        await asyncio.sleep(interval)

  # ============================================================================
  # BACKGROUND TASK: Weight Optimization Loop
  # ============================================================================

  async def _weight_optimization_loop(self):
    """
    –§–æ–Ω–æ–≤—ã–π —Ü–∏–∫–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (Adaptive Consensus).

    –ß–∞—Å—Ç–æ—Ç–∞: –ö–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    """
    logger.info("üîÑ Weight Optimization Loop started")

    if not self.adaptive_consensus:
      logger.warning("‚ö†Ô∏è Adaptive Consensus –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
      return

    error_count = 0
    max_errors = 5

    while self.status == BotStatus.RUNNING:
      try:
        for symbol in self.symbols:
          try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ weight_optimizer
            if not hasattr(self.adaptive_consensus, 'weight_optimizer') or not self.adaptive_consensus.weight_optimizer:
              logger.warning(f"[{symbol}] Weight optimizer –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
              continue

            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            strategy_names = list(self.strategy_manager.all_strategies.keys())

            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –≤–µ—Å–∞
            current_weights = {
              **self.strategy_manager.config.candle_strategy_weights,
              **self.strategy_manager.config.orderbook_strategy_weights,
              **self.strategy_manager.config.hybrid_strategy_weights
            }

            # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –í—ã–∑—ã–≤–∞–µ–º get_optimal_weights
            optimal_weights = self.adaptive_consensus.weight_optimizer.get_optimal_weights(
              symbol=symbol,
              strategy_names=strategy_names,
              current_weights=current_weights
            )

            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            strategies_updated = sum(
              1 for strategy in strategy_names
              if abs(optimal_weights.get(strategy, 0) - current_weights.get(strategy, 0)) > 0.01
            )

            if strategies_updated > 0:
              # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ –≤ strategy_manager
              self.adaptive_consensus._update_strategy_weights(optimal_weights)

              logger.info(
                f"‚öñÔ∏è [{symbol}] –í–µ—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: "
                f"–∏–∑–º–µ–Ω–µ–Ω–æ {strategies_updated} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"
              )
              self.stats['adaptive_weight_updates'] += 1
            else:
              logger.debug(f"[{symbol}] –í–µ—Å–∞ –Ω–µ —Ç—Ä–µ–±—É—é—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")

          except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ –¥–ª—è {symbol}: {e}")

        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
        await asyncio.sleep(21600)

      except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤: {e}")

        if error_count >= max_errors:
          logger.critical(f"üö® Weight Optimization Loop: –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –æ—à–∏–±–æ–∫")
          break

        await asyncio.sleep(3600)  # 1 hour

    logger.warning("‚ö†Ô∏è Weight Optimization Loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

  # ============================================================================
  # BACKGROUND TASK: MTF Update Loop
  # ============================================================================

  async def _mtf_update_loop(self):
    """
    –¶–∏–∫–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Multi-Timeframe –¥–∞–Ω–Ω—ã—Ö.

    –§—É–Ω–∫—Ü–∏–∏:
    - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö
    - Staggered updates (–Ω–µ –≤—Å–µ TF –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    """
    logger.info("üîÑ MTF Update Loop started")

    # ‚úÖ –ü–†–û–í–ï–†–ö–ê: –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
    if not self.mtf_manager:
      logger.warning("‚ö†Ô∏è MTF Manager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
      return

    # ‚úÖ –î–û–ë–ê–í–ò–¢–¨: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    logger.info(f"üîç MTF Manager ID: {id(self.mtf_manager)}")
    logger.info(f"üîç Coordinator ID: {id(self.mtf_manager.coordinator)}")
    logger.info(f"üîç Initialized symbols –≤ MTF Manager: {self.mtf_manager._initialized_symbols}")

    error_count = 0
    max_errors = 10

    while self.status == BotStatus.RUNNING:
      try:
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
        for symbol in self.symbols:
          try:
            # ‚úÖ –î–û–ë–ê–í–ò–¢–¨: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º
            if symbol not in self.mtf_manager._initialized_symbols:
              logger.warning(
                f"‚ö†Ô∏è [{symbol}] –ù–µ –Ω–∞–π–¥–µ–Ω –≤ _initialized_symbols, "
                f"–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ"
              )
              continue

            # ‚úÖ –í—ã–∑—ã–≤–∞–µ–º update —á–µ—Ä–µ–∑ MTF Manager
            success = await self.mtf_manager.update_timeframes(symbol)

            if success:
              logger.debug(f"[{symbol}] MTF –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
            else:
              logger.warning(f"[{symbol}] –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å MTF –¥–∞–Ω–Ω—ã–µ")

          except Exception as e:
            logger.error(f"‚ùå [{symbol}] –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è MTF –¥–∞–Ω–Ω—ã—Ö: {e}")

        # Reset error counter
        error_count = 0

        # Staggered interval
        await asyncio.sleep(settings.MTF_STAGGERED_UPDATE_INTERVAL)

      except Exception as e:
        error_count += 1
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ MTF Update Loop: {e}")

        if error_count >= max_errors:
          logger.critical(f"üö® MTF Update Loop: –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –æ—à–∏–±–æ–∫")
          break

        await asyncio.sleep(60)

    logger.warning("‚ö†Ô∏è MTF Update Loop –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

  # async def _initialize_risk_manager(self):
  #   """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Risk Manager."""
  #   # –°–æ–∑–¥–∞—ë–º –±–µ–∑ –±–∞–ª–∞–Ω—Å–∞
  #   self.risk_manager = RiskManager(default_leverage=settings.DEFAULT_LEVERAGE)
  #
  #   # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
  #   try:
  #     balance_data = await rest_client.get_wallet_balance()
  #     real_balance = balance_tracker._calculate_total_balance(balance_data)
  #
  #     # –ò–°–ü–û–õ–¨–ó–£–ï–ú update_available_balance
  #     self.risk_manager.update_available_balance(real_balance)
  #
  #     logger.info(f"‚úì Risk Manager –æ–±–Ω–æ–≤–ª—ë–Ω –±–∞–ª–∞–Ω—Å–æ–º: {real_balance:.2f} USDT")
  #   except Exception as e:
  #     logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞: {e}")


  async def _initialize_risk_manager(self):
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Risk Manager —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –±–∞–ª–∞–Ω—Å–æ–º.

    –õ–û–ì–ò–ö–ê:
    - –ï—Å–ª–∏ ML_RISK_INTEGRATION_ENABLED=True ‚Üí RiskManagerMLEnhanced
    - –ï—Å–ª–∏ ML_RISK_INTEGRATION_ENABLED=False ‚Üí –æ–±—ã—á–Ω—ã–π RiskManager
    - –ü—Ä–∏ ml_validator=None ‚Üí RiskManagerMLEnhanced —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ fallback —Ä–µ–∂–∏–º–µ
    """
    logger.info("=" * 80)
    logger.info("–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø RISK MANAGER")
    logger.info("=" * 80)

    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
        balance_data = await rest_client.get_wallet_balance()
        real_balance = balance_tracker._calculate_total_balance(balance_data)

        logger.info(f"‚úì –ü–æ–ª—É—á–µ–Ω –±–∞–ª–∞–Ω—Å —Å –±–∏—Ä–∂–∏: {real_balance:.2f} USDT")

        # ========================================
        # –£–°–õ–û–í–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø RISK MANAGER
        # ========================================

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω–∞ –ª–∏ ML –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
        ml_enabled = settings.ML_RISK_INTEGRATION_ENABLED

        if ml_enabled:
            # ========================================
            # ML-ENHANCED RISK MANAGER
            # ========================================
            logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ ML-Enhanced Risk Manager...")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ml_validator
            ml_validator_available = (
                hasattr(self, 'ml_validator') and
                self.ml_validator is not None
            )

            if ml_validator_available:
                logger.info(
                    f"‚úì ML Validator –¥–æ—Å—Ç—É–ø–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏"
                )
            else:
                logger.warning(
                    f"‚ö†Ô∏è ML Validator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, Risk Manager –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å "
                    f"–≤ fallback —Ä–µ–∂–∏–º–µ (–∫–∞–∫ –æ–±—ã—á–Ω—ã–π RiskManager)"
                )

            # –°–æ–∑–¥–∞–µ–º ML-Enhanced Risk Manager
            # –í–ê–ñ–ù–û: –î–∞–∂–µ –µ—Å–ª–∏ ml_validator=None, –æ–Ω –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ fallback
            self.risk_manager = RiskManagerMLEnhanced(
                ml_validator=self.ml_validator if ml_validator_available else None,
                default_leverage=settings.DEFAULT_LEVERAGE,
                initial_balance=real_balance
            )

            logger.info(
                f"‚úÖ ML-Enhanced Risk Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: "
                f"leverage={settings.DEFAULT_LEVERAGE}x, "
                f"balance=${real_balance:.2f}, "
                f"ml_validator={'enabled' if ml_validator_available else 'disabled (fallback)'}"
            )

        else:
            # ========================================
            # –û–ë–´–ß–ù–´–ô RISK MANAGER (–ë–ï–ó ML)
            # ========================================
            logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ã—á–Ω–æ–≥–æ Risk Manager (ML –æ—Ç–∫–ª—é—á–µ–Ω)...")

            self.risk_manager = RiskManager(
                default_leverage=settings.DEFAULT_LEVERAGE,
                initial_balance=real_balance
            )

            logger.info(
                f"‚úÖ Risk Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: "
                f"leverage={settings.DEFAULT_LEVERAGE}x, "
                f"balance=${real_balance:.2f}, "
                f"mode=standard (–±–µ–∑ ML)"
            )

        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Risk Manager: {e}", exc_info=True)
        raise

  async def _cleanup_on_error(self):
    """Cleanup —á–∞—Å—Ç–∏—á–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –æ—à–∏–±–∫–µ."""
    logger.warning("‚ö†Ô∏è –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è cleanup –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏...")

    try:
      # –ó–∞–∫—Ä—ã–≤–∞–µ–º WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
      if self.websocket_manager:
        try:
          await self.websocket_manager.stop()
        except Exception as e:
          logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ cleanup WebSocket: {e}")

      # –ó–∞–∫—Ä—ã–≤–∞–µ–º ML Validator
      if hasattr(self, 'ml_validator') and self.ml_validator:
        try:
          await self.ml_validator.cleanup()
        except Exception as e:
          logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ cleanup ML Validator: {e}")

      logger.info("‚úì Cleanup –∑–∞–≤–µ—Ä—à–µ–Ω")

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ cleanup: {e}")

  def _log_integrated_signal(self, symbol: str, integrated_signal):
      """
      –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞.

      Args:
          symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
          integrated_signal: IntegratedSignal –æ–±—ä–µ–∫—Ç
      """
      signal = integrated_signal.final_signal

      logger.info("=" * 80)
      logger.info(f"üéØ INTEGRATED SIGNAL: {symbol}")
      logger.info("=" * 80)

      # ===== –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø =====
      logger.info(f"üìä –¢–∏–ø —Å–∏–≥–Ω–∞–ª–∞: {signal.signal_type.value}")
      logger.info(f"üíØ Combined Confidence: {integrated_signal.combined_confidence:.3f}")
      logger.info(f"‚≠ê Combined Quality: {integrated_signal.combined_quality_score:.3f}")
      logger.info(f"üìà Entry Price: ${signal.price:.2f}")
      if integrated_signal.recommended_stop_loss is not None:
        stop_loss_pct = ((integrated_signal.recommended_stop_loss - signal.price) / signal.price) * 100
        logger.info(f"üõ°Ô∏è Stop Loss: ${integrated_signal.recommended_stop_loss:.2f} ({stop_loss_pct:+.2f}%)")
      else:
        logger.info(f"üõ°Ô∏è Stop Loss: Not set")

        # Take Profit (—Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π)
      if integrated_signal.recommended_take_profit is not None:
        take_profit_pct = ((integrated_signal.recommended_take_profit - signal.price) / signal.price) * 100
        logger.info(f"üéØ Take Profit: ${integrated_signal.recommended_take_profit:.2f} ({take_profit_pct:+.2f}%)")
      else:
        logger.info(f"üéØ Take Profit: Not set")
      logger.info(f"üí∞ Position Multiplier: {integrated_signal.recommended_position_multiplier:.2f}x")
      logger.info(f"‚ö†Ô∏è Risk Level: {integrated_signal.risk_level}")

      # ===== –ò–°–¢–û–ß–ù–ò–ö –ê–ù–ê–õ–ò–ó–ê =====
      logger.info("-" * 80)
      logger.info("üîß ANALYSIS SOURCE:")
      logger.info(f"   ‚îú‚îÄ Analysis Mode: {integrated_signal.source_analysis_mode.value}")
      logger.info(f"   ‚îú‚îÄ Single-TF: {'‚úÖ USED' if integrated_signal.used_single_tf else '‚ùå NOT USED'}")
      logger.info(f"   ‚îî‚îÄ MTF: {'‚úÖ USED' if integrated_signal.used_mtf else '‚ùå NOT USED'}")

      # ===== SINGLE-TF CONSENSUS =====
      if integrated_signal.single_tf_consensus:
        consensus = integrated_signal.single_tf_consensus
        logger.info("-" * 80)
        logger.info("üî∏ SINGLE-TF CONSENSUS:")
        consensus_mode = consensus.final_signal.metadata.get('consensus_mode', 'unknown')
        logger.info(f"   ‚îú‚îÄ Consensus Mode: {consensus_mode}")
        logger.info(f"   ‚îú‚îÄ Consensus Confidence: {consensus.consensus_confidence:.3f}")
        logger.info(f"   ‚îú‚îÄ Agreement: {consensus.agreement_count} strategies")
        logger.info(f"   ‚îú‚îÄ Disagreement: {consensus.disagreement_count} strategies")
        logger.info(f"   ‚îî‚îÄ Contributing Strategies:")
        for strategy in consensus.contributing_strategies:
          logger.info(f"       ‚îî‚îÄ {strategy}")

      # ===== MTF SIGNAL =====
      if integrated_signal.mtf_signal:
        mtf = integrated_signal.mtf_signal
        logger.info("-" * 80)
        logger.info("üîπ MTF SIGNAL:")
        logger.info(f"   ‚îú‚îÄ Signal Quality: {mtf.signal_quality:.3f}")
        logger.info(f"   ‚îú‚îÄ Risk Level: {mtf.risk_level}")
        logger.info(f"   ‚îú‚îÄ Alignment Score: {mtf.alignment_score:.3f}")
        logger.info(f"   ‚îú‚îÄ Confluence Detected: {'‚úÖ YES' if mtf.has_confluence else '‚ùå NO'}")
        logger.info(f"   ‚îú‚îÄ Recommended Position Multiplier: {mtf.recommended_position_size_multiplier:.2f}x")

        if mtf.divergence_type:
          logger.info(f"   ‚îú‚îÄ Divergence Type: {mtf.divergence_type}")

        if mtf.warnings:
          logger.info("   ‚îî‚îÄ MTF Warnings:")
          for warning in mtf.warnings:
            logger.info(f"       ‚ö†Ô∏è {warning}")

      # ===== ADAPTIVE WEIGHTS =====
      if integrated_signal.adaptive_weights:
        logger.info("-" * 80)
        logger.info("‚öñÔ∏è ADAPTIVE WEIGHTS:")
        for strategy, weight in integrated_signal.adaptive_weights.items():
          logger.info(f"   ‚îú‚îÄ {strategy}: {weight:.3f}")

      # ===== MARKET REGIME =====
      if integrated_signal.market_regime:
        logger.info("-" * 80)
        logger.info(f"üìä Market Regime: {integrated_signal.market_regime}")

      # ===== WARNINGS =====
      if integrated_signal.warnings:
        logger.info("-" * 80)
        logger.info("‚ö†Ô∏è WARNINGS:")
        for warning in integrated_signal.warnings:
          logger.info(f"   ‚îî‚îÄ {warning}")

      # ===== ANALYSIS PERFORMANCE =====
      logger.info("-" * 80)
      logger.info("‚è±Ô∏è PERFORMANCE:")
      logger.info(f"   ‚îú‚îÄ Analysis Duration: {integrated_signal.analysis_duration_ms:.2f}ms")
      logger.info(f"   ‚îî‚îÄ Analysis Timestamp: {integrated_signal.analysis_timestamp}")

      logger.info("=" * 80)

  def _log_analysis_statistics(self):
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã analysis loop.
    """
    logger.info("=" * 80)
    logger.info("üìä ANALYSIS LOOP STATISTICS")
    logger.info("=" * 80)

    # ===== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò =====
    logger.info("üîÑ CYCLES & SIGNALS:")
    logger.info(f"   ‚îú‚îÄ Analysis Cycles: {self.stats['analysis_cycles']}")
    logger.info(f"   ‚îú‚îÄ Signals Generated: {self.stats['signals_generated']}")
    logger.info(f"   ‚îú‚îÄ Signals Executed: {self.stats['signals_executed']}")
    logger.info(
      f"   ‚îî‚îÄ Execution Rate: {self.stats['signals_executed'] / max(self.stats['signals_generated'], 1) * 100:.1f}%")

    # ===== TRADING ACTIVITY =====
    logger.info("üí∞ TRADING ACTIVITY:")
    logger.info(f"   ‚îú‚îÄ Orders Placed: {self.stats['orders_placed']}")
    logger.info(f"   ‚îú‚îÄ Positions Opened: {self.stats['positions_opened']}")
    logger.info(f"   ‚îú‚îÄ Positions Closed: {self.stats['positions_closed']}")
    logger.info(f"   ‚îî‚îÄ Total PnL: {self.stats['total_pnl']:.2f} USDT")

    # ===== ADAPTIVE CONSENSUS =====
    if self.adaptive_consensus:
      logger.info("üîÑ ADAPTIVE CONSENSUS:")
      logger.info(f"   ‚îú‚îÄ Consensus Achieved: {self.stats['consensus_achieved']}")
      logger.info(f"   ‚îú‚îÄ Consensus Failed: {self.stats['consensus_failed']}")
      logger.info(f"   ‚îú‚îÄ Weight Updates: {self.stats['adaptive_weight_updates']}")

      consensus_rate = self.stats['consensus_achieved'] / max(
        self.stats['consensus_achieved'] + self.stats['consensus_failed'], 1
      ) * 100
      logger.info(f"   ‚îî‚îÄ Consensus Rate: {consensus_rate:.1f}%")

    # ===== MTF ANALYSIS =====
    if self.mtf_manager:
      logger.info("‚è±Ô∏è MULTI-TIMEFRAME:")
      logger.info(f"   ‚îú‚îÄ MTF Signals: {self.stats['mtf_signals']}")
      mtf_rate = self.stats['mtf_signals'] / max(self.stats['signals_generated'], 1) * 100
      logger.info(f"   ‚îî‚îÄ MTF Signal Rate: {mtf_rate:.1f}%")

    # ===== ML COMPONENTS =====
    if self.ml_validator:
      logger.info("ü§ñ ML COMPONENTS:")
      logger.info(f"   ‚îú‚îÄ ML Validations: {self.stats['ml_validations']}")
      logger.info(f"   ‚îú‚îÄ ML Data Collected: {self.stats['ml_data_collected']}")
      logger.info(f"   ‚îú‚îÄ Drift Detections: {self.stats['drift_detections']}")
      logger.info(f"   ‚îî‚îÄ Manipulations Detected: {self.stats['manipulations_detected']}")

    # ===== ERRORS & WARNINGS =====
    logger.info("‚ö†Ô∏è ISSUES:")
    logger.info(f"   ‚îú‚îÄ Warnings: {self.stats['warnings']}")
    logger.info(f"   ‚îî‚îÄ Errors: {self.stats['errors']}")

    # ===== COMPONENT STATISTICS =====
    if self.integrated_engine:
      logger.info("-" * 80)
      logger.info("üéØ INTEGRATED ENGINE STATS:")
      engine_stats = self.integrated_engine.get_statistics()
      for key, value in engine_stats.items():
        logger.info(f"   ‚îú‚îÄ {key}: {value}")

    if self.adaptive_consensus:
      logger.info("-" * 80)
      logger.info("üîÑ ADAPTIVE CONSENSUS STATS:")
      adaptive_stats = self.adaptive_consensus.get_statistics()
      for key, value in adaptive_stats.items():
        logger.info(f"   ‚îú‚îÄ {key}: {value}")

    if self.mtf_manager:
      logger.info("-" * 80)
      logger.info("‚è±Ô∏è MTF MANAGER STATS:")
      mtf_stats = self.mtf_manager.get_statistics()
      for key, value in mtf_stats.items():
        logger.info(f"   ‚îú‚îÄ {key}: {value}")

    logger.info("=" * 80)

  async def _send_critical_alert(self, title: str, message: str):
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–µ—Ä—Ç–∞.

    Args:
        title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∞–ª–µ—Ä—Ç–∞
        message: –°–æ–æ–±—â–µ–Ω–∏–µ
    """
    try:
      logger.critical(f"üö® CRITICAL ALERT: {title}")
      logger.critical(f"   Message: {message}")

      # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –≤ Telegram, Discord, Email –∏ —Ç.–¥.
      # –ù–∞–ø—Ä–∏–º–µ—Ä:
      # if self.telegram_notifier:
      #     await self.telegram_notifier.send_critical_alert(title, message)

      # –ò–ª–∏ –∑–∞–ø–∏—Å—å –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π
      # if self.alert_repository:
      #     await self.alert_repository.create_critical_alert(
      #         title=title,
      #         message=message,
      #         timestamp=datetime.now()
      #     )

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–µ—Ä—Ç–∞: {e}")

  async def _send_drift_alert(self, symbol: str):
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª–µ—Ä—Ç–∞ –æ model drift.

    Args:
        symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
    """
    try:
      logger.warning(f"üîî DRIFT ALERT: {symbol}")
      logger.warning("   Model drift –æ–±–Ω–∞—Ä—É–∂–µ–Ω, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ")

      # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –∞–ª–µ—Ä—Ç–∞
      # if self.telegram_notifier:
      #     await self.telegram_notifier.send_drift_alert(symbol)

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ drift –∞–ª–µ—Ä—Ç–∞: {e}")

  def _handle_symbol_error(self, symbol: str, error: Exception, error_count: dict):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.

    Args:
        symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        error: Exception
        error_count: –°–ª–æ–≤–∞—Ä—å —Å—á–µ—Ç—á–∏–∫–æ–≤ –æ—à–∏–±–æ–∫
    """
    error_count[symbol] = error_count.get(symbol, 0) + 1

    logger.error(
      f"‚ùå [{symbol}] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ "
      f"(#{error_count[symbol]}/{settings.MAX_CONSECUTIVE_ERRORS}): {error}"
    )
    logger.debug(traceback.format_exc())

    self.stats['errors'] += 1

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞
    if error_count[symbol] >= settings.MAX_CONSECUTIVE_ERRORS:
      logger.critical(
        f"üö® [{symbol}] –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫ "
        f"({settings.MAX_CONSECUTIVE_ERRORS}), —Å–∏–º–≤–æ–ª –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω"
      )

  def attach_ml_to_timeframe_analyzer(self):
      """
      –ü—Ä–∏–≤—è–∑–∞—Ç—å ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫ TimeframeAnalyzer.
      –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ ML –º–æ–¥–µ–ª–µ–π.
      """
      if not hasattr(self, 'mtf_manager') or self.mtf_manager is None:
        logger.warning("MTF Manager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

      if not hasattr(self, 'ml_validator') or self.ml_validator is None:
        logger.warning("ML Validator –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

      try:
        # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∫ analyzer
        self.mtf_manager.analyzer.ml_validator = self.ml_validator

        if hasattr(self, 'feature_pipeline') and self.feature_pipeline:
          self.mtf_manager.analyzer.ml_feature_pipeline  = self.feature_pipeline

        logger.info("‚úÖ ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ TimeframeAnalyzer")
        return True

      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–≤—è–∑–∫–∏ ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
        return False

  def detach_ml_from_timeframe_analyzer(self):
    """
    –û—Ç–≤—è–∑–∞—Ç—å ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ—Ç TimeframeAnalyzer.
    –ü–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –≤ —Ä–µ–∂–∏–º –±–µ–∑ ML –∏–ª–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö ML –º–æ–¥–µ–ª–µ–π.
    """
    if hasattr(self, 'mtf_manager') and self.mtf_manager:
      self.mtf_manager.analyzer.ml_validator = None
      self.mtf_manager.analyzer.ml_feature_pipeline  = None
      logger.info("ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ—Ç–≤—è–∑–∞–Ω—ã –æ—Ç TimeframeAnalyzer")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –±–æ—Ç–∞
bot_controller: Optional[BotController] = None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å MLflow UI
mlflow_ui_process: Optional[subprocess.Popen] = None


def start_mlflow_ui() -> Optional[subprocess.Popen]:
  """
  –ó–∞–ø—É—Å–∫–∞–µ—Ç MLflow UI server –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ.

  Returns:
      subprocess.Popen: –ü—Ä–æ—Ü–µ—Å—Å MLflow UI –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
  """
  try:
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è artifacts –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    artifact_path = Path(settings.MLFLOW_ARTIFACT_LOCATION)
    artifact_path.mkdir(parents=True, exist_ok=True)

    # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ MLflow UI
    cmd = [
      "mlflow", "ui",
      "--backend-store-uri", settings.MLFLOW_TRACKING_URI,
      "--default-artifact-root", settings.MLFLOW_ARTIFACT_LOCATION,
      "--host", "0.0.0.0",
      "--port", "5000"
    ]

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ (–±–µ–∑ –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å)
    process = subprocess.Popen(
      cmd,
      stdout=subprocess.DEVNULL,
      stderr=subprocess.DEVNULL,
      start_new_session=True  # –û—Ç–¥–µ–ª—è–µ–º –æ—Ç —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
    )

    logger.info(f"üöÄ MLflow UI –∑–∞–ø—É—â–µ–Ω (PID: {process.pid}) –Ω–∞ http://localhost:5000")
    return process

  except FileNotFoundError:
    logger.warning("‚ö† MLflow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install mlflow")
    return None
  except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ MLflow UI: {e}")
    return None


def stop_mlflow_ui(process: Optional[subprocess.Popen]) -> None:
  """
  –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç MLflow UI server.

  Args:
      process: –ü—Ä–æ—Ü–µ—Å—Å MLflow UI –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
  """
  if process and process.poll() is None:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –µ—â–µ –∂–∏–≤
    try:
      process.terminate()  # Graceful shutdown
      try:
        process.wait(timeout=5)  # –ñ–¥–µ–º –¥–æ 5 —Å–µ–∫—É–Ω–¥
        logger.info("‚úì MLflow UI –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
      except subprocess.TimeoutExpired:
        process.kill()  # Force kill –µ—Å–ª–∏ –Ω–µ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è
        logger.warning("‚ö† MLflow UI –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ MLflow UI: {e}")


@asynccontextmanager
async def lifespan(app):
  """
  –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

  Args:
      app: FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
  """
  global bot_controller, mlflow_ui_process

  # Startup
  logger.info("–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
  try:

    with trace_operation("app_startup"):
      # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
      logger.info("‚Üí –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
      await db_manager.initialize()
      logger.info("‚úì –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")

      # 2. –ó–∞–ø—É—Å–∫ MLflow UI Server
      logger.info("‚Üí –ó–∞–ø—É—Å–∫ MLflow UI Server...")
      mlflow_ui_process = start_mlflow_ui()

      # 3. Recovery & Reconciliation (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
      if settings.ENABLE_AUTO_RECOVERY:
        logger.info("–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è...")

        recovery_result = await recovery_service.recover_from_crash()

        if recovery_result["recovered"]:
          logger.info("‚úì –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")

          # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏
          if recovery_result["hanging_orders"]:
            logger.warning(
              f"‚ö† –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(recovery_result['hanging_orders'])} "
              f"–∑–∞–≤–∏—Å—à–∏—Ö –æ—Ä–¥–µ—Ä–æ–≤ - —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤–Ω–∏–º–∞–Ω–∏–µ!"
            )

          logger.info(
            f"FSM –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: "
            f"{recovery_result['fsm_restored']['orders']} –æ—Ä–¥–µ—Ä–æ–≤, "
            f"{recovery_result['fsm_restored']['positions']} –ø–æ–∑–∏—Ü–∏–π"
          )
        else:
          logger.error("‚úó –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è")
          if "error" in recovery_result:
            logger.error(f"–î–µ—Ç–∞–ª–∏: {recovery_result['error']}")
      else:
        logger.info("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

      # –°–æ–∑–¥–∞–µ–º –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä
      bot_controller = BotController()
      await bot_controller.initialize()

      await cleanup_tasks.start()

    logger.info("=" * 80)
    logger.info("‚úì –ü–†–ò–õ–û–ñ–ï–ù–ò–ï –ì–û–¢–û–í–û –ö –†–ê–ë–û–¢–ï")
    logger.info("=" * 80)

    yield

  except Exception as e:
    logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {e}")
    log_exception(logger, e, "–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
    raise

  finally:
    # Shutdown
    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")

    # if bot_controller:
    #   if bot_controller.status == BotStatus.RUNNING:
    #     await bot_controller.stop()
    #
    #   # –ó–∞–∫—Ä—ã–≤–∞–µ–º REST –∫–ª–∏–µ–Ω—Ç
    #   await rest_client.close()
    with trace_operation("app_shutdown"):
      if bot_controller:
        await bot_controller.stop()

      # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º MLflow UI
      logger.info("‚Üí –û—Å—Ç–∞–Ω–æ–≤–∫–∞ MLflow UI Server...")
      stop_mlflow_ui(mlflow_ui_process)

      await rest_client.close()
      await db_manager.close()

      await cleanup_tasks.stop()

    logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

async def fsm_cleanup_task():
  """
  Background task –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã—Ö FSM.
  –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –ø–∞–º—è—Ç—å –æ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö FSM.
  """
  logger.info("FSM Cleanup Task –∑–∞–ø—É—â–µ–Ω")

  while True:
    try:
      # –ñ–¥–µ–º 30 –º–∏–Ω—É—Ç
      await asyncio.sleep(1800)

      logger.info("–ó–∞–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã—Ö FSM...")

      # –û—á–∏—â–∞–µ–º —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã–µ FSM
      cleared = fsm_registry.clear_terminal_fsms()

      logger.info(
        f"–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: "
        f"–æ—Ä–¥–µ—Ä–æ–≤ - {cleared['orders_cleared']}, "
        f"–ø–æ–∑–∏—Ü–∏–π - {cleared['positions_cleared']}"
      )

      # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
      stats = fsm_registry.get_stats()
      logger.info(
        f"FSM Registry —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: "
        f"–æ—Ä–¥–µ—Ä–æ–≤ - {stats['total_order_fsms']}, "
        f"–ø–æ–∑–∏—Ü–∏–π - {stats['total_position_fsms']}"
      )

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –≤ FSM cleanup task: {e}", exc_info=True)
      # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
      await asyncio.sleep(60)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º lifespan
from backend.api.app import app

app.router.lifespan_context = lifespan

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ä–æ—É—Ç–µ—Ä—ã
from backend.api.routes import (
  auth_router, bot_router, data_router, trading_router,
  monitoring_router, screener_router, adaptive_router,
  ml_router, detection_router, strategies_router,
  ml_management_router, layering_ml_router
)
from backend.api.backtesting_api import router as backtesting_router

app.include_router(auth_router)
app.include_router(bot_router)
app.include_router(data_router)
app.include_router(trading_router)
app.include_router(monitoring_router)
app.include_router(screener_router)
app.include_router(adaptive_router)
app.include_router(ml_router)
app.include_router(detection_router)
app.include_router(strategies_router)
app.include_router(ml_management_router)
app.include_router(layering_ml_router)
app.include_router(backtesting_router)
# WebSocket —ç–Ω–¥–ø–æ–∏–Ω—Ç
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
  """
  WebSocket —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞.

  Args:
      websocket: WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
  """
  await ws_manager.connect(websocket)

  try:
    await handle_websocket_messages(websocket)
  except WebSocketDisconnect:
    logger.info("WebSocket –∫–ª–∏–µ–Ω—Ç –æ—Ç–∫–ª—é—á–µ–Ω")
  except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ WebSocket: {e}")
  finally:
    ws_manager.disconnect(websocket)


def handle_shutdown_signal(signum, frame):
  """
  –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.

  Args:
      signum: –ù–æ–º–µ—Ä —Å–∏–≥–Ω–∞–ª–∞
      frame: –§—Ä–µ–π–º
  """
  logger.info(f"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {signum}")
  # Uvicorn –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏


# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
signal.signal(signal.SIGINT, handle_shutdown_signal)
signal.signal(signal.SIGTERM, handle_shutdown_signal)

if __name__ == "__main__":
  """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –Ω–∞–ø—Ä—è–º—É—é."""

  logger.info("=" * 80)
  logger.info(f"–ó–∞–ø—É—Å–∫ {settings.APP_NAME} v{settings.APP_VERSION}")
  logger.info(f"–†–µ–∂–∏–º: {settings.BYBIT_MODE.upper()}")
  logger.info(f"–•–æ—Å—Ç: {settings.API_HOST}:{settings.API_PORT}")
  logger.info("=" * 80)

  # –ó–∞–ø—É—Å–∫–∞–µ–º Uvicorn —Å–µ—Ä–≤–µ—Ä
  uvicorn.run(
    "backend.main:app",
    host=settings.API_HOST,
    port=settings.API_PORT,
    reload=settings.DEBUG,
    log_level=settings.LOG_LEVEL.lower(),
  )