"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ Feature Store.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –ö–∞–∫–∏–µ parquet —Ñ–∞–π–ª—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç
- –ß—Ç–æ –≤ –Ω–∏—Ö –∑–∞–ø–∏—Å–∞–Ω–æ
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ NaN –∑–Ω–∞—á–µ–Ω–∏—è–º
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ labels
- –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫

Usage:
    python -m backend.ml_engine.scripts.diagnose_feature_store --storage-path data/feature_store
"""

import argparse
from pathlib import Path
import pandas as pd
import numpy as np
from collections import Counter
from backend.core.logger import get_logger
from backend.ml_engine.feature_store.feature_schema import DEFAULT_SCHEMA

logger = get_logger(__name__)


def diagnose_parquet_file(file_path: Path):
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ–¥–Ω–æ–≥–æ parquet —Ñ–∞–π–ª–∞."""
    logger.info(f"\n{'='*80}")
    logger.info(f"–§–∞–π–ª: {file_path.name}")
    logger.info(f"–†–∞–∑–º–µ—Ä: {file_path.stat().st_size / 1024:.2f} KB")
    logger.info(f"{'='*80}")

    try:
        df = pd.read_parquet(file_path)

        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        logger.info(f"\nüìä –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
        logger.info(f"  ‚Ä¢ –°—Ç—Ä–æ–∫: {len(df):,}")
        logger.info(f"  ‚Ä¢ –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
        logger.info(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")

        # –°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        logger.info(f"\nüìã –ö–æ–ª–æ–Ω–∫–∏ ({len(df.columns)}):")
        logger.info(f"  {list(df.columns[:10])}... (–ø–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 10)")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['symbol', 'timestamp', 'future_direction_60s']
        missing_cols = set(required_cols) - set(df.columns)
        if missing_cols:
            logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        else:
            logger.info(f"‚úì –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ feature –∫–æ–ª–æ–Ω–æ–∫
        feature_columns = DEFAULT_SCHEMA.get_all_feature_columns()
        logger.info(f"\nüîç Feature –∫–æ–ª–æ–Ω–∫–∏ (–æ–∂–∏–¥–∞–µ—Ç—Å—è {len(feature_columns)}):")

        present_features = [col for col in feature_columns if col in df.columns]
        missing_features = [col for col in feature_columns if col not in df.columns]

        logger.info(f"  ‚Ä¢ –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç: {len(present_features)}/{len(feature_columns)}")
        if missing_features:
            logger.warning(f"  ‚Ä¢ –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç ({len(missing_features)}): {missing_features[:5]}...")

        # –ê–Ω–∞–ª–∏–∑ NaN –∑–Ω–∞—á–µ–Ω–∏–π
        logger.info(f"\nüîé –ê–Ω–∞–ª–∏–∑ NaN –∑–Ω–∞—á–µ–Ω–∏–π:")

        total_values = df.shape[0] * df.shape[1]
        total_nan = df.isna().sum().sum()
        nan_pct = 100 * total_nan / total_values if total_values > 0 else 0

        logger.info(f"  ‚Ä¢ –í—Å–µ–≥–æ NaN: {total_nan:,} –∏–∑ {total_values:,} ({nan_pct:.2f}%)")

        # NaN –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
        nan_per_col = df.isna().sum()
        cols_with_nan = nan_per_col[nan_per_col > 0]

        if len(cols_with_nan) > 0:
            logger.warning(f"  ‚Ä¢ –ö–æ–ª–æ–Ω–æ–∫ —Å NaN: {len(cols_with_nan)}/{len(df.columns)}")
            logger.warning(f"  ‚Ä¢ –¢–æ–ø-5 –∫–æ–ª–æ–Ω–æ–∫ —Å NaN:")
            for col, count in cols_with_nan.nlargest(5).items():
                pct = 100 * count / len(df)
                logger.warning(f"    - {col}: {count:,} ({pct:.1f}%)")
        else:
            logger.info(f"  ‚úì –ù–µ—Ç NaN –∑–Ω–∞—á–µ–Ω–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö")

        # –ê–Ω–∞–ª–∏–∑ labels
        if 'future_direction_60s' in df.columns:
            logger.info(f"\nüéØ –ê–Ω–∞–ª–∏–∑ labels (future_direction_60s):")

            labels = df['future_direction_60s']
            unique_labels = labels.dropna().unique()

            logger.info(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {sorted(unique_labels)}")
            logger.info(f"  ‚Ä¢ NaN –≤ labels: {labels.isna().sum():,} ({100*labels.isna().sum()/len(labels):.1f}%)")

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            label_dist = Counter(labels.dropna())
            logger.info(f"  ‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
            for label, count in sorted(label_dist.items()):
                pct = 100 * count / len(labels.dropna())
                logger.info(f"    - {label}: {count:,} ({pct:.1f}%)")

        # –ê–Ω–∞–ª–∏–∑ feature values
        logger.info(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ features:")

        feature_cols_present = [col for col in feature_columns if col in df.columns]
        if feature_cols_present:
            feature_df = df[feature_cols_present]

            logger.info(f"  ‚Ä¢ Min: {feature_df.min().min():.6f}")
            logger.info(f"  ‚Ä¢ Max: {feature_df.max().max():.6f}")
            logger.info(f"  ‚Ä¢ Mean: {feature_df.mean().mean():.6f}")
            logger.info(f"  ‚Ä¢ Std: {feature_df.std().mean():.6f}")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ inf –∑–Ω–∞—á–µ–Ω–∏—è
            inf_count = np.isinf(feature_df.values).sum()
            if inf_count > 0:
                logger.warning(f"  ‚ö†Ô∏è Inf –∑–Ω–∞—á–µ–Ω–∏–π: {inf_count:,}")

        # –ü–æ–∫–∞–∑–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫
        logger.info(f"\nüìÑ –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏:")
        logger.info(f"\n{df.head(3).to_string()}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ timestamp –∏ symbol
        if 'timestamp' in df.columns:
            logger.info(f"\n‚è∞ Timestamps:")
            logger.info(f"  ‚Ä¢ –¢–∏–ø: {df['timestamp'].dtype}")
            logger.info(f"  ‚Ä¢ Min: {df['timestamp'].min()}")
            logger.info(f"  ‚Ä¢ Max: {df['timestamp'].max()}")
            logger.info(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {df['timestamp'].nunique():,}")

        if 'symbol' in df.columns:
            logger.info(f"\nüí± Symbols:")
            symbols = df['symbol'].value_counts()
            for sym, count in symbols.items():
                logger.info(f"  ‚Ä¢ {sym}: {count:,} –∑–∞–ø–∏—Å–µ–π")

        return df

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}", exc_info=True)
        return None


def main():
    parser = argparse.ArgumentParser(description="–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ Feature Store –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument(
        "--storage-path",
        type=str,
        default="data/feature_store",
        help="–ü—É—Ç—å –∫ Feature Store"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=5,
        help="–ú–∞–∫—Å–∏–º—É–º —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"
    )

    args = parser.parse_args()

    storage_path = Path(args.storage_path)

    logger.info(f"üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ Feature Store")
    logger.info(f"üìÇ –ü—É—Ç—å: {storage_path.absolute()}")
    logger.info(f"=" * 80)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è
    if not storage_path.exists():
        logger.error(f"‚ùå –ü—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {storage_path}")
        return

    # –ù–∞–π—Ç–∏ –≤—Å–µ parquet —Ñ–∞–π–ª—ã
    parquet_files = list(storage_path.rglob("*.parquet"))

    if not parquet_files:
        logger.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ parquet —Ñ–∞–π–ª–æ–≤ –≤ {storage_path}")
        return

    logger.info(f"‚úì –ù–∞–π–¥–µ–Ω–æ parquet —Ñ–∞–π–ª–æ–≤: {len(parquet_files)}")

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–µ)
    parquet_files = sorted(parquet_files, key=lambda f: f.stat().st_mtime, reverse=True)

    logger.info(f"\nüìã –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ (–ø–æ–∫–∞–∑–∞–Ω—ã {min(len(parquet_files), args.limit)} –∏–∑ {len(parquet_files)}):")
    for i, f in enumerate(parquet_files[:args.limit]):
        rel_path = f.relative_to(storage_path)
        logger.info(f"  {i+1}. {rel_path}")

    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–æ–≤
    logger.info(f"\n{'='*80}")
    logger.info(f"–î–ï–¢–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê")
    logger.info(f"{'='*80}")

    for i, file_path in enumerate(parquet_files[:args.limit]):
        df = diagnose_parquet_file(file_path)

        if i < len(parquet_files[:args.limit]) - 1:
            logger.info(f"\n{'='*80}\n")

    logger.info(f"\n‚úì –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


if __name__ == "__main__":
    main()
