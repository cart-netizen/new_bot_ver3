#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤ v2 - Industry Standard.

–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
1. Adaptive Threshold Labeling - –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ percentiles
2. Class Weights Calculator - –º–µ—Ç–æ–¥—ã balanced, sqrt, log, effective
3. Focal Loss integration - –≥–æ—Ç–æ–≤—ã–µ alpha –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
4. Oversampling/Undersampling - —Å —É—á—ë—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
5. SMOTE –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ - –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è

–ü—É—Ç—å: backend/ml_engine/training/class_balancing_v2.py
"""

import numpy as np
from typing import Dict, Optional, Tuple, List, Union
from dataclasses import dataclass, field
from collections import Counter
from enum import Enum
import warnings
from tqdm import tqdm

from backend.core.logger import get_logger

logger = get_logger(__name__)


def _log(msg: str):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ tqdm.write() –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å."""
    tqdm.write(f"[Balancing] {msg}")


# ============================================================================
# ENUMS –ò CONFIGURATION
# ============================================================================

class BalancingMethod(str, Enum):
    """–ú–µ—Ç–æ–¥—ã –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏."""
    NONE = "none"
    CLASS_WEIGHTS = "class_weights"
    OVERSAMPLING = "oversampling"
    UNDERSAMPLING = "undersampling"
    SMOTE = "smote"
    COMBINED = "combined"  # Oversampling + Class Weights


class WeightMethod(str, Enum):
    """–ú–µ—Ç–æ–¥—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤."""
    BALANCED = "balanced"  # sklearn style
    SQRT = "sqrt"  # Square root of balanced
    LOG = "log"  # Log of inverse frequency
    EFFECTIVE = "effective"  # Class-balanced loss paper


class ThresholdMethod(str, Enum):
    """–ú–µ—Ç–æ–¥—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è labeling."""
    FIXED = "fixed"
    PERCENTILE = "percentile"
    ADAPTIVE = "adaptive"
    VOLATILITY_ADJUSTED = "volatility_adjusted"


@dataclass
class ClassBalancingConfigV2:
    """
    –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤ v2.
    
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    """
    
    # === –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ ===
    method: BalancingMethod = BalancingMethod.COMBINED
    
    # === Class Weights ===
    use_class_weights: bool = True
    weight_method: WeightMethod = WeightMethod.BALANCED
    weight_smoothing: float = 0.0  # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤
    
    # === Focal Loss ===
    use_focal_loss: bool = True
    focal_gamma: float = 2.5
    
    # === Oversampling ===
    use_oversampling: bool = True
    oversample_ratio: float = 0.5  # Minority –¥–æ 50% –æ—Ç majority
    oversample_with_noise: bool = True  # –î–æ–±–∞–≤–ª—è—Ç—å —à—É–º –ø—Ä–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–∏
    noise_std: float = 0.01
    
    # === Undersampling ===
    use_undersampling: bool = False
    undersample_ratio: float = 0.8
    
    # === SMOTE ===
    use_smote: bool = False
    smote_k_neighbors: int = 5
    
    # === Threshold –¥–ª—è Labeling ===
    threshold_method: ThresholdMethod = ThresholdMethod.PERCENTILE
    
    # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    fixed_threshold_sell: float = -0.001  # -0.1%
    fixed_threshold_buy: float = 0.001   # +0.1%
    
    # Percentile –ø–æ—Ä–æ–≥–∏
    percentile_sell: float = 0.25  # Bottom 25% = Sell
    percentile_buy: float = 0.75   # Top 25% = Buy
    
    # Adaptive –ø–æ—Ä–æ–≥–∏
    min_class_ratio: float = 0.15  # –ú–∏–Ω–∏–º—É–º 15% –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    
    # === –¶–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ===
    target_distribution: Tuple[float, float, float] = (0.30, 0.40, 0.30)  # Sell, Hold, Buy


# ============================================================================
# THRESHOLD OPTIMIZER
# ============================================================================

class ThresholdOptimizer:
    """
    –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è labeling.
    
    –¶–µ–ª—å: –Ω–∞–π—Ç–∏ –ø–æ—Ä–æ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞—é—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤.
    """
    
    def __init__(self, config: ClassBalancingConfigV2):
        self.config = config
    
    def compute_thresholds(
        self,
        returns: np.ndarray,
        method: Optional[ThresholdMethod] = None
    ) -> Tuple[float, float]:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏.
        
        Args:
            returns: –ú–∞—Å—Å–∏–≤ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
            method: –ú–µ—Ç–æ–¥ (–µ—Å–ª–∏ None - –∏–∑ config)
        
        Returns:
            (sell_threshold, buy_threshold)
        """
        method = method or self.config.threshold_method
        
        if method == ThresholdMethod.FIXED:
            return self.config.fixed_threshold_sell, self.config.fixed_threshold_buy
        
        elif method == ThresholdMethod.PERCENTILE:
            return self._percentile_thresholds(returns)
        
        elif method == ThresholdMethod.ADAPTIVE:
            return self._adaptive_thresholds(returns)
        
        elif method == ThresholdMethod.VOLATILITY_ADJUSTED:
            return self._volatility_adjusted_thresholds(returns)
        
        else:
            return self.config.fixed_threshold_sell, self.config.fixed_threshold_buy
    
    def _percentile_thresholds(
        self,
        returns: np.ndarray
    ) -> Tuple[float, float]:
        """–ü–æ—Ä–æ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ percentiles."""
        sell_threshold = np.percentile(returns, self.config.percentile_sell * 100)
        buy_threshold = np.percentile(returns, self.config.percentile_buy * 100)
        
        _log(
            f"Percentile thresholds: sell={sell_threshold:.6f} "
            f"({self.config.percentile_sell*100}%), "
            f"buy={buy_threshold:.6f} ({self.config.percentile_buy*100}%)"
        )
        
        return sell_threshold, buy_threshold
    
    def _adaptive_thresholds(
        self,
        returns: np.ndarray
    ) -> Tuple[float, float]:
        """
        –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.
        
        –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ –ø–æ–¥–±–∏—Ä–∞–µ—Ç –ø–æ—Ä–æ–≥–∏ —á—Ç–æ–±—ã –¥–æ—Å—Ç–∏—á—å –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤.
        """
        target_sell, target_hold, target_buy = self.config.target_distribution
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –º–µ–¥–∏–∞–Ω—ã
        sorted_returns = np.sort(returns)
        n = len(sorted_returns)
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        sell_idx = int(n * target_sell)
        buy_idx = int(n * (target_sell + target_hold))
        
        sell_threshold = sorted_returns[sell_idx]
        buy_threshold = sorted_returns[buy_idx]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        labels = self._apply_thresholds(returns, sell_threshold, buy_threshold)
        dist = Counter(labels)
        
        _log(
            f"Adaptive thresholds: sell={sell_threshold:.6f}, buy={buy_threshold:.6f}"
        )
        _log(
            f"Resulting distribution: {dict(dist)} "
            f"(target: sell={target_sell:.0%}, hold={target_hold:.0%}, buy={target_buy:.0%})"
        )
        
        return sell_threshold, buy_threshold
    
    def _volatility_adjusted_thresholds(
        self,
        returns: np.ndarray,
        lookback: int = 100
    ) -> Tuple[float, float]:
        """
        –ü–æ—Ä–æ–≥–∏ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ–º rolling std –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ —Ç–µ–∫—É—â–µ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏.
        """
        # Rolling volatility
        if len(returns) > lookback:
            recent_std = np.std(returns[-lookback:])
        else:
            recent_std = np.std(returns)
        
        # –ü–æ—Ä–æ–≥–∏ = k * sigma
        k = 0.5  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
        sell_threshold = -k * recent_std
        buy_threshold = k * recent_std
        
        _log(
            f"Volatility-adjusted thresholds: sell={sell_threshold:.6f}, "
            f"buy={buy_threshold:.6f} (volatility={recent_std:.6f})"
        )
        
        return sell_threshold, buy_threshold
    
    def _apply_thresholds(
        self,
        returns: np.ndarray,
        sell_threshold: float,
        buy_threshold: float
    ) -> np.ndarray:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥–∏ –∫ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º."""
        labels = np.ones(len(returns), dtype=np.int64)  # Default: HOLD = 1

        # –°–¢–ê–ù–î–ê–†–¢–ù–´–ô –ú–ê–ü–ü–ò–ù–ì: SELL=0, HOLD=1, BUY=2
        labels[returns < sell_threshold] = 0  # SELL
        labels[returns > buy_threshold] = 2   # BUY
        labels[(returns >= sell_threshold) & (returns <= buy_threshold)] = 1  # HOLD

        return labels
    
    def relabel_data(
        self,
        returns: np.ndarray,
        method: Optional[ThresholdMethod] = None
    ) -> np.ndarray:
        """
        –ü–µ—Ä–µ–º–∞—Ä–∫–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏.
        
        Args:
            returns: –ú–∞—Å—Å–∏–≤ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
            method: –ú–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤
        
        Returns:
            labels: –ú–∞—Å—Å–∏–≤ –º–µ—Ç–æ–∫ (0=SELL, 1=HOLD, 2=BUY)
        """
        sell_threshold, buy_threshold = self.compute_thresholds(returns, method)
        labels = self._apply_thresholds(returns, sell_threshold, buy_threshold)
        
        dist = Counter(labels)
        _log(f"Relabeling result: {dict(dist)}")
        
        return labels


# ============================================================================
# CLASS WEIGHTS CALCULATOR
# ============================================================================

class ClassWeightsCalculator:
    """–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤."""
    
    @staticmethod
    def compute(
        labels: np.ndarray,
        method: WeightMethod = WeightMethod.BALANCED,
        smoothing: float = 0.0,
        num_classes: int = 3
    ) -> np.ndarray:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤.
        
        Args:
            labels: –ú–∞—Å—Å–∏–≤ –º–µ—Ç–æ–∫
            method: –ú–µ—Ç–æ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
            smoothing: –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (0 = off)
            num_classes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
        
        Returns:
            weights: Array –≤–µ—Å–æ–≤ [w0, w1, w2, ...]
        """
        class_counts = Counter(labels)
        total_samples = len(labels)
        
        # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –≤—Å–µ –∫–ª–∞—Å—Å—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã
        for i in range(num_classes):
            if i not in class_counts:
                class_counts[i] = 1  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        
        if method == WeightMethod.BALANCED:
            # sklearn style: n_samples / (n_classes * n_samples_per_class)
            weights = {
                cls: total_samples / (num_classes * count)
                for cls, count in class_counts.items()
            }
        
        elif method == WeightMethod.SQRT:
            # Square root of balanced (–±–æ–ª–µ–µ –º—è–≥–∫–∏–µ –≤–µ—Å–∞)
            weights = {
                cls: np.sqrt(total_samples / (num_classes * count))
                for cls, count in class_counts.items()
            }
        
        elif method == WeightMethod.LOG:
            # Log of inverse frequency
            weights = {
                cls: np.log(total_samples / count + 1)
                for cls, count in class_counts.items()
            }
        
        elif method == WeightMethod.EFFECTIVE:
            # Effective number of samples (Class-Balanced Loss paper)
            beta = 0.9999
            weights = {
                cls: (1 - beta) / (1 - beta ** count)
                for cls, count in class_counts.items()
            }
        
        else:
            # Default: uniform
            weights = {cls: 1.0 for cls in range(num_classes)}
        
        # Normalize so that sum = num_classes
        weight_sum = sum(weights.values())
        weights = {k: v * num_classes / weight_sum for k, v in weights.items()}
        
        # Apply smoothing: weight = weight * (1 - smoothing) + smoothing
        if smoothing > 0:
            weights = {
                k: v * (1 - smoothing) + smoothing
                for k, v in weights.items()
            }
        
        # Convert to array
        weight_array = np.array(
            [weights.get(i, 1.0) for i in range(num_classes)],
            dtype=np.float32
        )
        
        _log(f"Class weights ({method.value}): {weight_array}")
        
        return weight_array
    
    @staticmethod
    def compute_focal_alpha(
        labels: np.ndarray,
        num_classes: int = 3
    ) -> np.ndarray:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å alpha –¥–ª—è Focal Loss.
        
        Alpha –æ–±—ã—á–Ω–æ = inverse class frequency, normalized.
        """
        class_counts = Counter(labels)
        total = len(labels)
        
        alpha = np.zeros(num_classes, dtype=np.float32)
        
        for cls in range(num_classes):
            count = class_counts.get(cls, 1)
            alpha[cls] = 1.0 - (count / total)
        
        # Normalize
        alpha = alpha / alpha.sum() * num_classes
        
        _log(f"Focal alpha: {alpha}")
        
        return alpha


# ============================================================================
# RESAMPLING STRATEGIES
# ============================================================================

class ResamplingStrategy:
    """–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤."""
    
    def __init__(self, config: ClassBalancingConfigV2):
        self.config = config
    
    def oversample(
        self,
        X: np.ndarray,
        y: np.ndarray,
        target_ratio: Optional[float] = None
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Oversampling minority –∫–ª–∞—Å—Å–æ–≤.
        
        Args:
            X: Features (N, feature_dim) –∏–ª–∏ sequences (N, seq_len, feature_dim)
            y: Labels (N,)
            target_ratio: –¶–µ–ª–µ–≤–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ minority/majority
        
        Returns:
            X_resampled, y_resampled
        """
        target_ratio = target_ratio or self.config.oversample_ratio
        
        class_counts = Counter(y)
        majority_count = max(class_counts.values())
        target_count = int(majority_count * target_ratio)
        
        _log(f"Oversampling: majority={majority_count}, target_minority={target_count}")
        
        X_resampled = [X]
        y_resampled = [y]
        
        for cls, count in class_counts.items():
            if count < target_count:
                # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞
                indices = np.where(y == cls)[0]
                
                # –°–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å
                n_to_add = target_count - count
                
                # –°–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                sample_indices = np.random.choice(indices, size=n_to_add, replace=True)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —à—É–º–æ–º
                X_new = X[sample_indices].copy()
                
                if self.config.oversample_with_noise:
                    noise = np.random.randn(*X_new.shape) * self.config.noise_std
                    X_new = X_new + noise
                
                X_resampled.append(X_new)
                y_resampled.append(np.full(n_to_add, cls, dtype=y.dtype))
                
                _log(f"  Class {cls}: {count} ‚Üí {target_count} (+{n_to_add})")
        
        X_final = np.concatenate(X_resampled, axis=0)
        y_final = np.concatenate(y_resampled, axis=0)
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º
        shuffle_idx = np.random.permutation(len(X_final))
        
        return X_final[shuffle_idx], y_final[shuffle_idx]
    
    def undersample(
        self,
        X: np.ndarray,
        y: np.ndarray,
        target_ratio: Optional[float] = None
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Undersampling majority –∫–ª–∞—Å—Å–∞.
        
        Args:
            X: Features
            y: Labels
            target_ratio: –¶–µ–ª–µ–≤–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ majority/minority
        
        Returns:
            X_resampled, y_resampled
        """
        target_ratio = target_ratio or self.config.undersample_ratio
        
        class_counts = Counter(y)
        minority_count = min(class_counts.values())
        target_count = int(minority_count / target_ratio)
        
        _log(f"Undersampling: minority={minority_count}, target_majority={target_count}")
        
        indices_to_keep = []
        
        for cls, count in class_counts.items():
            cls_indices = np.where(y == cls)[0]
            
            if count > target_count:
                # –°–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ
                keep_indices = np.random.choice(
                    cls_indices,
                    size=target_count,
                    replace=False
                )
                indices_to_keep.extend(keep_indices)
                _log(f"  Class {cls}: {count} ‚Üí {target_count}")
            else:
                indices_to_keep.extend(cls_indices)
        
        indices_to_keep = np.array(indices_to_keep)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ (–≤–∞–∂–Ω–æ –¥–ª—è time series!)
        indices_to_keep = np.sort(indices_to_keep)
        
        return X[indices_to_keep], y[indices_to_keep]
    
    def smote_timeseries(
        self,
        X: np.ndarray,
        y: np.ndarray,
        k_neighbors: Optional[int] = None
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        SMOTE –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.
        
        –í–º–µ—Å—Ç–æ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ —Ç–æ—á–µ–∫, –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ—Ç —Ü–µ–ª—ã–µ sequences.
        
        Args:
            X: Sequences (N, seq_len, feature_dim)
            y: Labels (N,)
            k_neighbors: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π
        
        Returns:
            X_resampled, y_resampled
        """
        k_neighbors = k_neighbors or self.config.smote_k_neighbors
        
        class_counts = Counter(y)
        majority_count = max(class_counts.values())
        
        X_resampled = [X]
        y_resampled = [y]
        
        for cls, count in class_counts.items():
            if count < majority_count:
                cls_indices = np.where(y == cls)[0]
                X_cls = X[cls_indices]
                
                n_to_generate = majority_count - count
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ samples
                synthetic = self._generate_smote_samples(
                    X_cls,
                    n_to_generate,
                    k_neighbors
                )
                
                X_resampled.append(synthetic)
                y_resampled.append(np.full(n_to_generate, cls, dtype=y.dtype))
                
                _log(f"  SMOTE Class {cls}: +{n_to_generate} synthetic samples")
        
        X_final = np.concatenate(X_resampled, axis=0)
        y_final = np.concatenate(y_resampled, axis=0)
        
        shuffle_idx = np.random.permutation(len(X_final))
        
        return X_final[shuffle_idx], y_final[shuffle_idx]
    
    def _generate_smote_samples(
        self,
        X_class: np.ndarray,
        n_samples: int,
        k_neighbors: int
    ) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SMOTE samples –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞."""
        n_existing = len(X_class)
        
        if n_existing < k_neighbors:
            k_neighbors = max(1, n_existing - 1)
        
        # Flatten –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π
        if len(X_class.shape) == 3:
            X_flat = X_class.reshape(n_existing, -1)
        else:
            X_flat = X_class
        
        synthetic = []
        
        for _ in range(n_samples):
            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π sample
            idx = np.random.randint(0, n_existing)
            sample = X_flat[idx]
            
            # –ù–∞—Ö–æ–¥–∏–º k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π
            distances = np.linalg.norm(X_flat - sample, axis=1)
            neighbor_indices = np.argsort(distances)[1:k_neighbors + 1]
            
            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–æ—Å–µ–¥–∞
            neighbor_idx = np.random.choice(neighbor_indices)
            neighbor = X_flat[neighbor_idx]
            
            # –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è
            alpha = np.random.random()
            new_sample = sample + alpha * (neighbor - sample)
            
            synthetic.append(new_sample)
        
        synthetic = np.array(synthetic)
        
        # Reshape –æ–±—Ä–∞—Ç–Ω–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if len(X_class.shape) == 3:
            synthetic = synthetic.reshape(-1, X_class.shape[1], X_class.shape[2])
        
        return synthetic


# ============================================================================
# MAIN CLASS BALANCING STRATEGY
# ============================================================================

class ClassBalancingStrategyV2:
    """
    –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤ v2.
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –º–µ—Ç–æ–¥—ã –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –≤ –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.
    """
    
    def __init__(self, config: Optional[ClassBalancingConfigV2] = None):
        """
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        """
        self.config = config or ClassBalancingConfigV2()
        self.threshold_optimizer = ThresholdOptimizer(self.config)
        self.resampler = ResamplingStrategy(self.config)
        
        # Cached weights
        self._class_weights: Optional[np.ndarray] = None
        self._focal_alpha: Optional[np.ndarray] = None
        
        _log(
            f"‚úì ClassBalancingStrategyV2 initialized: "
            f"method={self.config.method.value}, "
            f"focal={self.config.use_focal_loss}, "
            f"oversample={self.config.use_oversampling}"
        )
    
    def balance_dataset(
        self,
        X: np.ndarray,
        y: np.ndarray,
        returns: Optional[np.ndarray] = None
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ü—Ä–∏–º–µ–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫ –¥–∞—Ç–∞—Å–µ—Ç—É.
        
        Args:
            X: Features –∏–ª–∏ sequences
            y: Labels
            returns: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ (–¥–ª—è –ø–µ—Ä–µ–º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏)
        
        Returns:
            X_balanced, y_balanced
        """
        tqdm.write("\n" + "=" * 60)
        tqdm.write("[Balancing] –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê –ö–õ–ê–°–°–û–í")
        tqdm.write("=" * 60)

        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        before_dist = Counter(y)
        _log(f"–î–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {dict(before_dist)}")

        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø–µ—Ä–µ–º–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
        if returns is not None and self.config.threshold_method != ThresholdMethod.FIXED:
            _log("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤...")
            y = self.threshold_optimizer.relabel_data(returns)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–µ—Ç–æ–¥ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        method = self.config.method
        
        if method == BalancingMethod.NONE:
            pass  # –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        
        elif method == BalancingMethod.OVERSAMPLING:
            if self.config.use_oversampling:
                X, y = self.resampler.oversample(X, y)
        
        elif method == BalancingMethod.UNDERSAMPLING:
            if self.config.use_undersampling:
                X, y = self.resampler.undersample(X, y)
        
        elif method == BalancingMethod.SMOTE:
            if self.config.use_smote:
                X, y = self.resampler.smote_timeseries(X, y)
        
        elif method == BalancingMethod.COMBINED:
            # Oversampling + –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å class weights –≤ loss
            if self.config.use_oversampling:
                X, y = self.resampler.oversample(X, y)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        after_dist = Counter(y)
        _log(f"–ü–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {dict(after_dist)}")
        tqdm.write("=" * 60 + "\n")
        
        return X, y
    
    def get_class_weights(
        self,
        y: np.ndarray,
        num_classes: int = 3
    ) -> np.ndarray:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤.
        
        Args:
            y: Labels
            num_classes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
        
        Returns:
            weights: Array –≤–µ—Å–æ–≤
        """
        if not self.config.use_class_weights:
            return np.ones(num_classes, dtype=np.float32)
        
        weights = ClassWeightsCalculator.compute(
            y,
            method=self.config.weight_method,
            smoothing=self.config.weight_smoothing,
            num_classes=num_classes
        )
        
        self._class_weights = weights
        return weights
    
    def get_focal_alpha(
        self,
        y: np.ndarray,
        num_classes: int = 3
    ) -> np.ndarray:
        """
        –ü–æ–ª—É—á–∏—Ç—å alpha –¥–ª—è Focal Loss.
        
        Args:
            y: Labels
            num_classes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
        
        Returns:
            alpha: Array –∑–Ω–∞—á–µ–Ω–∏–π alpha
        """
        if not self.config.use_focal_loss:
            return None
        
        alpha = ClassWeightsCalculator.compute_focal_alpha(y, num_classes)
        self._focal_alpha = alpha
        return alpha
    
    def get_loss_params(
        self,
        y: np.ndarray,
        num_classes: int = 3
    ) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è loss function.
        
        Args:
            y: Labels
            num_classes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
        
        Returns:
            Dict —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è loss
        """
        params = {
            'use_focal_loss': self.config.use_focal_loss,
            'focal_gamma': self.config.focal_gamma,
            'class_weights': None,
            'focal_alpha': None
        }
        
        if self.config.use_class_weights:
            params['class_weights'] = self.get_class_weights(y, num_classes)
        
        if self.config.use_focal_loss:
            params['focal_alpha'] = self.get_focal_alpha(y, num_classes)
        
        return params


# ============================================================================
# FACTORY FUNCTIONS
# ============================================================================

def create_balancing_strategy(
    preset: str = "production"
) -> ClassBalancingStrategyV2:
    """
    –°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∏–∑ –ø—Ä–µ—Å–µ—Ç–∞.
    
    –ü—Ä–µ—Å–µ—Ç—ã:
        - production: –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª—è production (Focal + Oversampling)
        - conservative: –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è (—Ç–æ–ª—å–∫–æ class weights)
        - aggressive: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è (SMOTE + –≤—ã—Å–æ–∫–∏–π gamma)
    
    Returns:
        ClassBalancingStrategyV2 instance
    """
    if preset == "production":
        config = ClassBalancingConfigV2(
            method=BalancingMethod.COMBINED,
            use_class_weights=True,
            use_focal_loss=True,
            focal_gamma=2.5,
            use_oversampling=True,
            oversample_ratio=0.5,
            threshold_method=ThresholdMethod.PERCENTILE,
            percentile_sell=0.25,
            percentile_buy=0.75
        )
    
    elif preset == "conservative":
        config = ClassBalancingConfigV2(
            method=BalancingMethod.CLASS_WEIGHTS,
            use_class_weights=True,
            use_focal_loss=True,
            focal_gamma=2.0,
            use_oversampling=False,
            threshold_method=ThresholdMethod.FIXED
        )
    
    elif preset == "aggressive":
        config = ClassBalancingConfigV2(
            method=BalancingMethod.COMBINED,
            use_class_weights=True,
            use_focal_loss=True,
            focal_gamma=3.0,
            use_oversampling=True,
            oversample_ratio=0.7,
            use_smote=True,
            smote_k_neighbors=5,
            threshold_method=ThresholdMethod.ADAPTIVE
        )
    
    else:
        config = ClassBalancingConfigV2()
    
    return ClassBalancingStrategyV2(config)


# ============================================================================
# EXAMPLE USAGE
# ============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("–¢–ï–°–¢ CLASS BALANCING V2")
    print("=" * 80)
    
    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å imbalance
    np.random.seed(42)
    
    n_samples = 1000
    n_features = 110
    
    # Imbalanced labels: 70% HOLD, 15% BUY, 15% SELL
    y = np.random.choice(
        [0, 1, 2],
        size=n_samples,
        p=[0.70, 0.15, 0.15]
    )
    X = np.random.randn(n_samples, n_features).astype(np.float32)
    
    print(f"\nüìä Original data:")
    print(f"  ‚Ä¢ X shape: {X.shape}")
    print(f"  ‚Ä¢ y distribution: {dict(Counter(y))}")
    
    # 1. Class Weights
    print("\n1Ô∏è‚É£ Class Weights Calculator:")
    for method in WeightMethod:
        weights = ClassWeightsCalculator.compute(y, method=method)
        print(f"  ‚Ä¢ {method.value}: {weights}")
    
    # 2. Threshold Optimizer
    print("\n2Ô∏è‚É£ Threshold Optimizer:")
    returns = np.random.randn(n_samples) * 0.01  # –°–∏–º—É–ª—è—Ü–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
    
    config = ClassBalancingConfigV2()
    optimizer = ThresholdOptimizer(config)
    
    for method in ThresholdMethod:
        if method != ThresholdMethod.VOLATILITY_ADJUSTED:
            sell_th, buy_th = optimizer.compute_thresholds(returns, method)
            print(f"  ‚Ä¢ {method.value}: sell={sell_th:.6f}, buy={buy_th:.6f}")
    
    # 3. Full Balancing Strategy
    print("\n3Ô∏è‚É£ Full Balancing Strategy:")
    strategy = create_balancing_strategy("production")
    
    X_balanced, y_balanced = strategy.balance_dataset(X, y)
    
    print(f"\nüìä Balanced data:")
    print(f"  ‚Ä¢ X shape: {X_balanced.shape}")
    print(f"  ‚Ä¢ y distribution: {dict(Counter(y_balanced))}")
    
    # 4. Loss Parameters
    print("\n4Ô∏è‚É£ Loss Parameters:")
    loss_params = strategy.get_loss_params(y_balanced)
    print(f"  ‚Ä¢ use_focal_loss: {loss_params['use_focal_loss']}")
    print(f"  ‚Ä¢ focal_gamma: {loss_params['focal_gamma']}")
    print(f"  ‚Ä¢ class_weights: {loss_params['class_weights']}")
    print(f"  ‚Ä¢ focal_alpha: {loss_params['focal_alpha']}")
    
    print("\n" + "=" * 80)
    print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
    print("=" * 80)
