#!/usr/bin/env python3
"""
Quick check of Layering ML data status (without pandas dependency)

Usage:
    python check_layering_data_status.py
"""

from pathlib import Path
import json

def main():
    print("=" * 80)
    print("üîç LAYERING ML DATA STATUS CHECK")
    print("=" * 80)
    print()

    # Check directory
    data_dir = Path("data/ml_training/layering")

    print("üìÅ DIRECTORY STATUS")
    print("-" * 80)

    if not data_dir.exists():
        print("‚ùå Directory does not exist yet")
        print(f"   Path: {data_dir.absolute()}")
        print()
        print("–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –µ—Å–ª–∏ –±–æ—Ç –µ—â–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª—Å—è.")
        print("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞—Å—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.")
        print()
        print("–î–ª—è –Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
        print("1. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤ config/.env —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ:")
        print("   TRADING_MODE=ONLY_TRAINING  (–∏–ª–∏ FULL)")
        print()
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞:")
        print("   python backend/main.py")
        print()
        return

    print(f"‚úÖ Directory exists: {data_dir.absolute()}")
    print()

    # Check parquet files
    parquet_files = list(data_dir.glob("layering_data_*.parquet"))

    print("üì¶ PARQUET FILES")
    print("-" * 80)
    print(f"Files found: {len(parquet_files)}")
    print()

    if len(parquet_files) == 0:
        print("‚ö†Ô∏è  No parquet files yet")
        print()
        print("–ü—Ä–∏—á–∏–Ω—ã:")
        print("- –ë–æ—Ç —Ç–æ–ª—å–∫–æ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è (–Ω—É–∂–Ω–æ –ø–æ–¥–æ–∂–¥–∞—Ç—å)")
        print("- Detector –µ—â–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª layering –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
        print("- Buffer –µ—â–µ –Ω–µ –Ω–∞–∫–æ–ø–∏–ª 100 samples –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        print()
        print("–ß—Ç–æ –¥–µ–ª–∞—Ç—å:")
        print("- –ü–æ–¥–æ–∂–¥–∏—Ç–µ –ø–æ–∫–∞ detector –æ–±–Ω–∞—Ä—É–∂–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
        print("- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏: tail -f logs/bot.log | grep -i layering")
        print()
        return

    # Show file info
    total_size = 0
    for i, filepath in enumerate(sorted(parquet_files)[:10], 1):
        size_kb = filepath.stat().st_size / 1024
        total_size += size_kb
        print(f"  {i:2d}. {filepath.name:40s}  {size_kb:8.1f} KB")

    if len(parquet_files) > 10:
        print(f"  ... and {len(parquet_files) - 10} more files")

    print()
    print(f"Total size: {total_size/1024:.2f} MB")
    print()

    # Check statistics file
    stats_file = data_dir / "statistics.json"

    print("üìä STATISTICS")
    print("-" * 80)

    if not stats_file.exists():
        print("‚ö†Ô∏è  No statistics file yet")
        print()
    else:
        with open(stats_file, 'r') as f:
            stats = json.load(f)

        print(f"Total collected:     {stats.get('total_collected', 0):,}")
        print(f"Total labeled:       {stats.get('total_labeled', 0):,}")
        print(f"Total saved:         {stats.get('total_saved', 0):,}")
        print(f"Last updated:        {stats.get('last_updated', 'Unknown')}")
        print()

        total_collected = stats.get('total_collected', 0)

        if total_collected == 0:
            print("‚ö†Ô∏è  No data collected yet")
        elif total_collected < 100:
            print(f"‚è≥ Collecting data... ({total_collected}/100 for first batch)")
        elif total_collected < 1000:
            print(f"üìä Good progress! ({total_collected:,} samples collected)")
        else:
            print(f"üéâ Excellent! ({total_collected:,} samples collected)")

    print()

    # Check model
    model_path = Path("data/models/layering_adaptive_v1.pkl")

    print("üß† ML MODEL STATUS")
    print("-" * 80)

    if not model_path.exists():
        print("‚ùå Model not trained yet")
        print()
        print("–î–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:")
        print("1. –°–æ–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 100 labeled samples")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python backend/scripts/train_layering_model.py")
    else:
        size_kb = model_path.stat().st_size / 1024
        print(f"‚úÖ Model exists: {model_path}")
        print(f"   Size: {size_kb:.1f} KB")

    print()
    print("=" * 80)
    print("üìö NEXT STEPS")
    print("=" * 80)
    print()

    if len(parquet_files) == 0:
        print("1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞ –∏ –ø–æ–¥–æ–∂–¥–∏—Ç–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")
        print("   python backend/main.py")
    elif stats_file.exists() and stats.get('total_collected', 0) < 100:
        print("1. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –ø–æ–∫–∞ —Å–æ–±–µ—Ä–µ—Ç—Å—è –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω–∏–º—É–º 100)")
        print(f"   –¢–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {stats.get('total_collected', 0)}/100")
    else:
        print("1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        print("   pip install pandas pyarrow scikit-learn")
        print("   python analyze_layering_ml_data.py")
        print()
        print("2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ labeling (automatic –∏–ª–∏ manual)")
        print()
        print("3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å:")
        print("   python backend/scripts/train_layering_model.py")

    print()
    print("üìñ –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:")
    print("   cat LAYERING_ML_GUIDE.md")
    print()
    print("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
