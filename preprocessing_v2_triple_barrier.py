#!/usr/bin/env python3
"""
Preprocessing V2 - Triple Barrier Labeling —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

–ò–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å V1:
1. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Triple Barrier Method (ATR-based) –≤–º–µ—Å—Ç–æ fixed threshold
2. –î–æ–±–∞–≤–ª–µ–Ω 5-–º–∏–Ω—É—Ç–Ω—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç (300s)
3. –ë–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è HOLD –∫–ª–∞—Å—Å–∞
4. –î–æ–±–∞–≤–ª–µ–Ω—ã lagged —Ñ–∏—á–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ–π —Å–∏–ª—ã
5. –î–æ–±–∞–≤–ª–µ–Ω—ã derived —Ñ–∏—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ top-–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π

–ó–∞–ø—É—Å–∫:
    python preprocessing_v2_triple_barrier.py --start-date 2025-11-01

–§–∞–π–ª: preprocessing_v2_triple_barrier.py
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
from dataclasses import dataclass

# –î–æ–±–∞–≤–ª—è–µ–º backend –≤ path
sys.path.insert(0, str(Path(__file__).parent))

PROJECT_ROOT = Path(__file__).resolve().parent

from backend.core.logger import get_logger
from backend.ml_engine.feature_store.feature_store import get_feature_store

logger = get_logger(__name__)


# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
# =============================================================================

@dataclass
class LabelingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Triple Barrier –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤."""

    # –ì–æ—Ä–∏–∑–æ–Ω—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
    horizons: List[int] = None

    # ATR –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –¥–ª—è —à–∏—Ä–∏–Ω—ã –±–∞—Ä—å–µ—Ä–æ–≤
    # –ß–µ–º –≤—ã—à–µ - —Ç–µ–º —à–∏—Ä–µ –±–∞—Ä—å–µ—Ä—ã, —Ç–µ–º –º–µ–Ω—å—à–µ HOLD
    tp_multiplier: float = 2.0   # Take Profit = entry + tp_mult * ATR
    sl_multiplier: float = 2.0   # Stop Loss = entry - sl_mult * ATR

    # Fallback threshold –µ—Å–ª–∏ ATR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–≤ % –æ—Ç —Ü–µ–Ω—ã)
    fixed_threshold_pct: float = 0.15  # 0.15% –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç

    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–≤–∏–∂–µ–Ω–∏—è –¥–ª—è non-HOLD (–≤ %)
    # –ï—Å–ª–∏ –¥–≤–∏–∂–µ–Ω–∏–µ < min_movement_pct -> HOLD
    min_movement_pct: float = 0.05  # 0.05%

    # === –†–µ–∂–∏–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ ===
    # –ï—Å–ª–∏ True - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç ATR –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç fixed_threshold_pct –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
    use_fixed_pct: bool = False

    # === –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç—É (‚àöT scaling) ===
    # –ï—Å–ª–∏ True - –ø–æ—Ä–æ–≥ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è —Å –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–º –ø–æ –ø—Ä–∞–≤–∏–ª—É ‚àö(horizon/base_horizon)
    # –≠—Ç–æ —É—á–∏—Ç—ã–≤–∞–µ—Ç, —á—Ç–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å—Ç—ë—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚àöT
    use_horizon_scaling: bool = True
    base_horizon: int = 60  # –ë–∞–∑–æ–≤—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç –¥–ª—è scaling (—Å–µ–∫—É–Ω–¥—ã)

    # === –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è "–ø–ª–æ—Å–∫–∏—Ö" —Å–∏–º–≤–æ–ª–æ–≤ ===
    # –°–∏–º–≤–æ–ª—ã, –≥–¥–µ HOLD > max_hold_pct –≤–æ –≤—Å–µ—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—Ö, –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è
    max_hold_pct: float = 85.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π % HOLD –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–∞

    def __post_init__(self):
        if self.horizons is None:
            # –ì–æ—Ä–∏–∑–æ–Ω—Ç—ã: 1 –º–∏–Ω, 3 –º–∏–Ω, 5 –º–∏–Ω
            self.horizons = [60, 180, 300]

    def get_scaled_threshold(self, horizon: int) -> float:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ä–æ–≥ —Å —É—á—ë—Ç–æ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç—É.

        –ü–æ —Ç–µ–æ—Ä–∏–∏ —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª—É–∂–¥–∞–Ω–∏–π: œÉ(T) = œÉ(1) √ó ‚àöT
        –ü–æ—ç—Ç–æ–º—É –ø–æ—Ä–æ–≥ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ.
        """
        if not self.use_horizon_scaling:
            return self.fixed_threshold_pct

        # ‚àöT scaling: threshold(T) = threshold(base) √ó ‚àö(T/base)
        scale_factor = np.sqrt(horizon / self.base_horizon)
        return self.fixed_threshold_pct * scale_factor


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è HOLD
DEFAULT_CONFIG = LabelingConfig(
    horizons=[60, 180, 300],  # 1, 3, 5 –º–∏–Ω—É—Ç
    tp_multiplier=2.0,
    sl_multiplier=2.0,
    fixed_threshold_pct=0.15,
    min_movement_pct=0.05
)


# =============================================================================
# LAGGED FEATURES - –õ–∞–≥–æ–≤—ã–µ —Ñ–∏—á–∏
# =============================================================================

# –§–∏—á–∏ —Å –Ω–∞–∏–≤—ã—Å—à–µ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π (–∏–∑ feature_quality_analyzer)
TOP_CORRELATED_FEATURES = [
    'imbalance_5',
    'depth_imbalance_ratio',
    'imbalance_10',
    'volume_delta_5',
    'gap_size',
    'momentum_10',
    'update_frequency',
    'quote_intensity',
    'rsi_28',
    'roc',
]

# –§–∏—á–∏ —Å –Ω–∞–∏–≤—ã—Å—à–∏–º Fisher Ratio (–ª—É—á—à–∞—è —Å–µ–ø–∞—Ä–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤)
TOP_SEPARATING_FEATURES = [
    'orderbook_volatility',
    'bid_ask_spread_rel',
    'effective_spread',
    'trade_arrival_rate',
    'smart_money_index',
]

# –õ–∞–≥–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è lagged features (–≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ samples)
# –ü—Ä–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ~15s: lag=4 ‚âà 1 –º–∏–Ω—É—Ç–∞ –Ω–∞–∑–∞–¥
LAGS = [1, 2, 4, 8]  # ~15s, 30s, 1min, 2min –Ω–∞–∑–∞–¥


def add_lagged_features(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç lagged –≤–µ—Ä—Å–∏–∏ top-–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∏—á.

    –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –≤–∏–¥–µ—Ç—å –¥–∏–Ω–∞–º–∏–∫—É –∏–∑–º–µ–Ω–µ–Ω–∏–π.

    –í–ê–ñ–ù–û: –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤—ã–∑—ã–≤–∞—Ç—å—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –û–¢–î–ï–õ–¨–ù–û,
    —á—Ç–æ–±—ã shift() –Ω–µ —Å–º–µ—à–∏–≤–∞–ª –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤!

    Args:
        df: DataFrame —Å —Ñ–∏—á–∞–º–∏
        verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—Ü–µ—Å—Å–µ

    Returns:
        DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ lagged —Ñ–∏—á–∞–º–∏
    """
    if verbose:
        print("\nüìä –î–æ–±–∞–≤–ª–µ–Ω–∏–µ Lagged Features...")

    # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∏—á –¥–ª—è –ª–∞–≥–≥–∏–Ω–≥–∞
    features_to_lag = list(set(TOP_CORRELATED_FEATURES + TOP_SEPARATING_FEATURES))

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ —Ñ–∏—á–∏ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
    available_features = [f for f in features_to_lag if f in df.columns]
    if verbose:
        print(f"   –§–∏—á–∏ –¥–ª—è –ª–∞–≥–≥–∏–Ω–≥–∞: {len(available_features)}/{len(features_to_lag)}")

    # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ lagged –∫–æ–ª–æ–Ω–∫–∏ (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫ –Ω–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    existing_lag_cols = [c for c in df.columns if '_lag' in c]
    if existing_lag_cols:
        if verbose:
            print(f"   ‚ö†Ô∏è –£–¥–∞–ª—è–µ–º {len(existing_lag_cols)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö lagged –∫–æ–ª–æ–Ω–æ–∫")
        df = df.drop(columns=existing_lag_cols)

    new_columns = {}

    for feature in available_features:
        for lag in LAGS:
            col_name = f"{feature}_lag{lag}"
            new_columns[col_name] = df[feature].shift(lag).values  # .values –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏

    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∑–∞ —Ä–∞–∑ (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ)
    if new_columns:
        for col_name, values in new_columns.items():
            df[col_name] = values

    # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ –Ω–∞—á–∞–ª–µ (–ø–µ—Ä–≤—ã–µ N —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ shift) –∑–Ω–∞—á–µ–Ω–∏–µ–º forward fill,
    # –∑–∞—Ç–µ–º backward fill –¥–ª—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è NaN
    lag_cols_added = list(new_columns.keys())
    if lag_cols_added:
        df[lag_cols_added] = df[lag_cols_added].fillna(method='bfill')

    n_new_features = len(new_columns)
    if verbose:
        print(f"   ‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ {n_new_features} lagged features")

    return df


def add_derived_features(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ top-–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.

    –°–æ–∑–¥–∞–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Ñ–∏—á, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∏–º–µ—Ç—å –ª—É—á—à—É—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω—É—é —Å–∏–ª—É.

    –í–ê–ñ–ù–û: –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤—ã–∑—ã–≤–∞—Ç—å—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –û–¢–î–ï–õ–¨–ù–û,
    —á—Ç–æ–±—ã diff() –∏ rolling() –Ω–µ —Å–º–µ—à–∏–≤–∞–ª–∏ –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤!

    Args:
        df: DataFrame —Å —Ñ–∏—á–∞–º–∏
        verbose: –í—ã–≤–æ–¥–∏—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—Ü–µ—Å—Å–µ

    Returns:
        DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ derived —Ñ–∏—á–∞–º–∏
    """
    if verbose:
        print("\nüîß –î–æ–±–∞–≤–ª–µ–Ω–∏–µ Derived Features...")

    # –°–ø–∏—Å–æ–∫ derived —Ñ–∏—á, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å
    derived_feature_names = [
        'imbalance_5_change', 'imbalance_5_change_pct', 'imbalance_5_momentum',
        'imbalance_ratio_5_10', 'imbalance_vol_adjusted', 'spread_change',
        'spread_momentum', 'imbalance_volume_weighted', 'rsi_diff', 'rsi_14_momentum',
        'composite_signal', 'smart_money_momentum', 'smart_money_acceleration',
        'trade_quote_ratio', 'volatility_regime'
    ]

    # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ derived –∫–æ–ª–æ–Ω–∫–∏ (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫ –Ω–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    existing_derived_cols = [c for c in df.columns if c in derived_feature_names]
    if existing_derived_cols:
        if verbose:
            print(f"   ‚ö†Ô∏è –£–¥–∞–ª—è–µ–º {len(existing_derived_cols)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö derived –∫–æ–ª–æ–Ω–æ–∫")
        df = df.drop(columns=existing_derived_cols)

    added_count = 0

    # 1. –ò–∑–º–µ–Ω–µ–Ω–∏—è imbalance (momentum of imbalance)
    if 'imbalance_5' in df.columns:
        df['imbalance_5_change'] = df['imbalance_5'].diff().values
        df['imbalance_5_change_pct'] = df['imbalance_5'].pct_change().values
        added_count += 2

        if 'imbalance_5_lag4' in df.columns:
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ 1 –º–∏–Ω—É—Ç—É
            df['imbalance_5_momentum'] = (df['imbalance_5'].values - df['imbalance_5_lag4'].values)
            added_count += 1

    # 2. Ratio —Ñ–∏—á–∏
    if 'imbalance_5' in df.columns and 'imbalance_10' in df.columns:
        # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∫ –¥–ª–∏–Ω–Ω–æ–º—É imbalance
        df['imbalance_ratio_5_10'] = (df['imbalance_5'].values / (df['imbalance_10'].values + 1e-10))
        added_count += 1

    # 3. Volatility-adjusted imbalance
    if 'imbalance_5' in df.columns and 'orderbook_volatility' in df.columns:
        df['imbalance_vol_adjusted'] = (df['imbalance_5'].values / (df['orderbook_volatility'].values + 1e-10))
        added_count += 1

    # 4. Spread momentum
    if 'bid_ask_spread_rel' in df.columns:
        df['spread_change'] = df['bid_ask_spread_rel'].diff().values
        df['spread_momentum'] = df['bid_ask_spread_rel'].diff().rolling(4).mean().values
        added_count += 2

    # 5. Volume-weighted imbalance
    if 'imbalance_5' in df.columns and 'volume' in df.columns:
        df['imbalance_volume_weighted'] = (df['imbalance_5'].values * np.log1p(df['volume'].values))
        added_count += 1

    # 6. RSI momentum
    if 'rsi_14' in df.columns and 'rsi_28' in df.columns:
        df['rsi_diff'] = (df['rsi_14'].values - df['rsi_28'].values)
        df['rsi_14_momentum'] = df['rsi_14'].diff(4).values
        added_count += 2

    # 7. Composite signals
    if all(f in df.columns for f in ['imbalance_5', 'depth_imbalance_ratio', 'volume_delta_5']):
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª –∏–∑ top-3 –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏—á
        df['composite_signal'] = (
            df['imbalance_5'].rank(pct=True).values * 0.4 +
            df['depth_imbalance_ratio'].rank(pct=True).values * 0.4 +
            df['volume_delta_5'].rank(pct=True).values * 0.2
        )
        added_count += 1

    # 8. Orderbook pressure change
    if 'smart_money_index' in df.columns:
        df['smart_money_momentum'] = df['smart_money_index'].diff().values
        df['smart_money_acceleration'] = df['smart_money_index'].diff().diff().values
        added_count += 2

    # 9. Trade intensity ratio
    if 'trade_arrival_rate' in df.columns and 'quote_intensity' in df.columns:
        df['trade_quote_ratio'] = (df['trade_arrival_rate'].values / (df['quote_intensity'].values + 1e-10))
        added_count += 1

    # 10. Volatility regime
    if 'orderbook_volatility' in df.columns:
        vol_ma = df['orderbook_volatility'].rolling(20).mean().values
        df['volatility_regime'] = (df['orderbook_volatility'].values / (vol_ma + 1e-10))
        added_count += 1

    # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ derived features (bfill –¥–ª—è –Ω–∞—á–∞–ª–∞ —Å–µ—Ä–∏–∏)
    existing_derived = [c for c in derived_feature_names if c in df.columns]
    if existing_derived:
        df[existing_derived] = df[existing_derived].fillna(method='bfill')
        # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å NaN (–Ω–∞–ø—Ä. –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN), –∑–∞–ø–æ–ª–Ω—è–µ–º 0
        df[existing_derived] = df[existing_derived].fillna(0)

    if verbose:
        print(f"   ‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} derived features")

    return df


# =============================================================================
# TRIPLE BARRIER LABELING
# =============================================================================

def compute_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç Average True Range –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –±–∞—Ä—å–µ—Ä–æ–≤.

    Args:
        df: DataFrame —Å OHLC –¥–∞–Ω–Ω—ã–º–∏
        period: –ü–µ—Ä–∏–æ–¥ ATR

    Returns:
        Series —Å ATR –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    """
    if 'high' not in df.columns or 'low' not in df.columns:
        # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º close –∫–∞–∫ proxy –¥–ª—è high/low
        if 'close' in df.columns:
            return df['close'] * 0.002  # 0.2% –æ—Ç —Ü–µ–Ω—ã –∫–∞–∫ proxy ATR
        elif 'current_mid_price' in df.columns:
            return df['current_mid_price'] * 0.002
        return None

    high = df['high']
    low = df['low']
    close = df['close'].shift(1) if 'close' in df.columns else df['current_mid_price'].shift(1)

    tr1 = high - low
    tr2 = (high - close).abs()
    tr3 = (low - close).abs()

    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    atr = true_range.rolling(window=period).mean()

    return atr


def apply_triple_barrier_label(
    current_price: float,
    future_price: float,
    atr: float,
    config: LabelingConfig,
    horizon: int = 60
) -> Tuple[int, float]:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç Triple Barrier –ª–æ–≥–∏–∫—É –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è label.

    Args:
        current_price: –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
        future_price: –ë—É–¥—É—â–∞—è —Ü–µ–Ω–∞
        atr: Average True Range –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—Ö–æ–¥–∞
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è labeling
        horizon: –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–¥–ª—è scaling)

    Returns:
        (label, movement) –≥–¥–µ label: 0=SELL, 1=HOLD, 2=BUY
    """
    if current_price <= 0:
        return 1, 0.0

    movement = (future_price - current_price) / current_price
    movement_pct = abs(movement) * 100

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥
    if config.use_fixed_pct:
        # –†–µ–∂–∏–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å horizon scaling
        threshold_pct = config.get_scaled_threshold(horizon)
        threshold = threshold_pct / 100
    elif atr is not None and atr > 0 and not np.isnan(atr):
        # –†–µ–∂–∏–º ATR - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–∞
        # threshold = (ATR / price) * multiplier = relative_volatility * multiplier
        threshold = (atr / current_price) * config.tp_multiplier
    else:
        # Fallback —Å horizon scaling
        threshold_pct = config.get_scaled_threshold(horizon)
        threshold = threshold_pct / 100

    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
    min_threshold = config.min_movement_pct / 100
    threshold = max(threshold, min_threshold)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º label
    if movement > threshold:
        return 2, movement  # BUY
    elif movement < -threshold:
        return 0, movement  # SELL
    else:
        return 1, movement  # HOLD


class TripleBarrierPreprocessor:
    """
    Preprocessing —Å Triple Barrier Method.
    """

    def __init__(
        self,
        config: LabelingConfig = None,
        feature_store_group: str = "training_features",
        start_date: str = None,
        end_date: str = None
    ):
        self.config = config or DEFAULT_CONFIG
        self.feature_store_group = feature_store_group
        self.start_date = start_date
        self.end_date = end_date
        self.feature_store = get_feature_store()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_samples': 0,
            'labeled_samples': 0,
            'label_distribution': {}
        }

    def process_all_data(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n" + "=" * 80)
        print("PREPROCESSING V2 - TRIPLE BARRIER LABELING")
        print("=" * 80)
        print(f"Feature Group: {self.feature_store_group}")
        print(f"–ü–µ—Ä–∏–æ–¥: {self.start_date or '–Ω–∞—á–∞–ª–æ'} ‚Üí {self.end_date or '–∫–æ–Ω–µ—Ü'}")
        print(f"\n–ü–∞—Ä–∞–º–µ—Ç—Ä—ã Triple Barrier:")
        print(f"  ‚Ä¢ –ì–æ—Ä–∏–∑–æ–Ω—Ç—ã: {self.config.horizons} —Å–µ–∫—É–Ω–¥")

        if self.config.use_fixed_pct:
            print(f"  ‚Ä¢ –†–ï–ñ–ò–ú: –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ô –ü–†–û–¶–ï–ù–¢")
            if self.config.use_horizon_scaling:
                print(f"  ‚Ä¢ –ë–∞–∑–æ–≤—ã–π –ø–æ—Ä–æ–≥: {self.config.fixed_threshold_pct}% (–¥–ª—è {self.config.base_horizon}s)")
                print(f"  ‚Ä¢ ‚àöT Scaling: –í–ö–õ–Æ–ß–Å–ù")
                for h in self.config.horizons:
                    scaled = self.config.get_scaled_threshold(h)
                    print(f"    - {h}s ‚Üí {scaled:.3f}%")
            else:
                print(f"  ‚Ä¢ –ü–æ—Ä–æ–≥: {self.config.fixed_threshold_pct}% –¥–ª—è –í–°–ï–• –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤")
        else:
            print(f"  ‚Ä¢ –†–ï–ñ–ò–ú: –ê–î–ê–ü–¢–ò–í–ù–´–ô ATR")
            print(f"  ‚Ä¢ TP –º–Ω–æ–∂–∏—Ç–µ–ª—å: {self.config.tp_multiplier}x ATR")
            print(f"  ‚Ä¢ SL –º–Ω–æ–∂–∏—Ç–µ–ª—å: {self.config.sl_multiplier}x ATR")

        print(f"  ‚Ä¢ Min movement: {self.config.min_movement_pct}%")
        print(f"  ‚Ä¢ –§–∏–ª—å—Ç—Ä –ø–ª–æ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤: HOLD > {self.config.max_hold_pct}%")
        print("=" * 80)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Feature Store...")
        df = self.feature_store.read_offline_features(
            feature_group=self.feature_store_group,
            start_date=self.start_date,
            end_date=self.end_date
        )

        if df is None or df.empty:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ Feature Store!")
            return

        print(f"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} —Å–µ–º–ø–ª–æ–≤")
        print(f"   ‚úì –°–∏–º–≤–æ–ª—ã: {df['symbol'].unique().tolist()}")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è timestamps
        df = self._normalize_timestamps(df)

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        initial_count = len(df)
        df = df.drop_duplicates(subset=['symbol', 'timestamp'], keep='last')
        if len(df) < initial_count:
            print(f"   ‚ö†Ô∏è –£–¥–∞–ª–µ–Ω–æ {initial_count - len(df):,} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        symbols = df['symbol'].unique()
        all_processed = []
        skipped_symbols = []  # –°–∏–º–≤–æ–ª—ã —Å –≤—ã—Å–æ–∫–∏–º HOLD

        for symbol in symbols:
            print(f"\n{'‚îÄ' * 70}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {symbol}")
            print(f"{'‚îÄ' * 70}")

            symbol_df = df[df['symbol'] == symbol].copy()
            processed_df, hold_pct_by_horizon = self._process_symbol(symbol, symbol_df)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–∏–º–≤–æ–ª "–ø–ª–æ—Å–∫–∏–º" (HOLD > max_hold_pct –≤–æ –í–°–ï–• –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—Ö)
            is_flat = all(
                hold_pct > self.config.max_hold_pct
                for hold_pct in hold_pct_by_horizon.values()
            )

            if is_flat:
                min_hold = min(hold_pct_by_horizon.values())
                print(f"\n   ‚ö†Ô∏è –ü–†–û–ü–£–©–ï–ù: HOLD > {self.config.max_hold_pct}% –≤–æ –≤—Å–µ—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—Ö "
                      f"(min HOLD = {min_hold:.1f}%)")
                skipped_symbols.append((symbol, len(symbol_df), hold_pct_by_horizon))
                self.stats['skipped_symbols'] = self.stats.get('skipped_symbols', [])
                self.stats['skipped_symbols'].append(symbol)
            else:
                # –í–ê–ñ–ù–û: –î–æ–±–∞–≤–ª—è–µ–º lagged/derived features –î–û –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–æ–≤,
                # —á—Ç–æ–±—ã shift() —Ä–∞–±–æ—Ç–∞–ª —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
                processed_df = add_lagged_features(processed_df, verbose=False)
                processed_df = add_derived_features(processed_df, verbose=False)
                all_processed.append(processed_df)

        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É –ø–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º —Å–∏–º–≤–æ–ª–∞–º
        if skipped_symbols:
            print(f"\n{'=' * 70}")
            print(f"‚ö†Ô∏è –ü–†–û–ü–£–©–ï–ù–û {len(skipped_symbols)} —Å–∏–º–≤–æ–ª–æ–≤ —Å HOLD > {self.config.max_hold_pct}%:")
            total_skipped = 0
            for sym, count, hold_stats in skipped_symbols:
                holds_str = ", ".join([f"{h}s:{p:.0f}%" for h, p in hold_stats.items()])
                print(f"   ‚Ä¢ {sym}: {count:,} —Å–µ–º–ø–ª–æ–≤ ({holds_str})")
                total_skipped += count
            print(f"   –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {total_skipped:,} —Å–µ–º–ø–ª–æ–≤")
            print(f"{'=' * 70}")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not all_processed:
            print("\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏!")
            return

        final_df = pd.concat(all_processed, ignore_index=True)

        # Lagged –∏ derived features —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
        # –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ: shift() –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ —Å–∏–º–≤–æ–ª–∞!
        n_lag_cols = len([c for c in final_df.columns if '_lag' in c])
        n_derived_cols = len([c for c in final_df.columns if c in [
            'imbalance_5_change', 'imbalance_5_change_pct', 'imbalance_5_momentum',
            'imbalance_ratio_5_10', 'imbalance_vol_adjusted', 'spread_change',
            'spread_momentum', 'imbalance_volume_weighted', 'rsi_diff', 'rsi_14_momentum',
            'composite_signal', 'smart_money_momentum', 'smart_money_acceleration',
            'trade_quote_ratio', 'volatility_regime'
        ]])
        print(f"\nüìä –î–æ–±–∞–≤–ª–µ–Ω–æ Lagged/Derived Features (per-symbol):")
        print(f"   ‚úì {n_lag_cols} lagged features")
        print(f"   ‚úì {n_derived_cols} derived features")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print(f"\n{'=' * 70}")
        print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        print(f"{'=' * 70}")

        self._cleanup_old_files(final_df)

        success = self.feature_store.write_offline_features(
            feature_group=self.feature_store_group,
            features=final_df,
            timestamp_column='timestamp'
        )

        if success:
            print(f"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(final_df):,} —Å–µ–º–ø–ª–æ–≤")
        else:
            print("   ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è!")

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._print_summary()

    def _normalize_timestamps(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç timestamps –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã."""
        print("\nüîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è timestamps...")

        normalized = []
        for ts in df['timestamp']:
            if pd.isna(ts):
                normalized.append(None)
            elif isinstance(ts, (int, np.integer, float, np.floating)):
                normalized.append(int(ts))
            else:
                try:
                    dt = pd.to_datetime(ts)
                    normalized.append(int(dt.timestamp() * 1000))
                except:
                    normalized.append(None)

        df['timestamp'] = normalized
        print("   ‚úì Timestamps –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã")
        return df

    def _process_symbol(self, symbol: str, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[int, float]]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.

        Returns:
            (DataFrame —Å –º–µ—Ç–∫–∞–º–∏, —Å–ª–æ–≤–∞—Ä—å {horizon: hold_pct})
        """
        df = df.sort_values('timestamp').reset_index(drop=True)
        n = len(df)
        print(f"   –°–µ–º–ø–ª–æ–≤: {n:,}")

        # –í—ã—á–∏—Å–ª—è–µ–º ATR –µ—Å–ª–∏ –µ—Å—Ç—å OHLC –¥–∞–Ω–Ω—ã–µ
        atr = compute_atr(df)
        has_atr = atr is not None and not atr.isna().all()
        if has_atr:
            print(f"   ‚úì ATR –≤—ã—á–∏—Å–ª–µ–Ω (mean: {atr.mean():.6f})")
        else:
            print(f"   ‚ö†Ô∏è ATR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fixed threshold")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º price column
        price_col = 'current_mid_price' if 'current_mid_price' in df.columns else 'close'

        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å timestamp -> row –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        timestamp_to_idx = dict(zip(df['timestamp'], range(n)))

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ HOLD% –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        hold_pct_by_horizon = {}

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç
        for horizon in self.config.horizons:
            label_col = f'future_direction_{horizon}s'
            movement_col = f'future_movement_{horizon}s'

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º scaled threshold –µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω scaling
            if self.config.use_fixed_pct and self.config.use_horizon_scaling:
                scaled_thresh = self.config.get_scaled_threshold(horizon)
                print(f"\n   –ì–æ—Ä–∏–∑–æ–Ω—Ç {horizon}s (–ø–æ—Ä–æ–≥: {scaled_thresh:.3f}%):")
            else:
                print(f"\n   –ì–æ—Ä–∏–∑–æ–Ω—Ç {horizon}s:")

            labels = np.full(n, 1, dtype=np.int32)  # Default = HOLD
            movements = np.full(n, 0.0, dtype=np.float64)
            labeled_count = 0

            for idx in range(n):
                current_ts = df.iloc[idx]['timestamp']
                current_price = df.iloc[idx][price_col]
                current_atr = atr.iloc[idx] if has_atr else None

                if pd.isna(current_price) or current_price <= 0:
                    continue

                # –ò—â–µ–º future price
                target_ts = current_ts + (horizon * 1000)
                tolerance = 15000  # ¬±15 —Å–µ–∫—É–Ω–¥

                future_price = None
                for future_idx in range(idx + 1, n):
                    future_ts = df.iloc[future_idx]['timestamp']
                    if abs(future_ts - target_ts) <= tolerance:
                        future_price = df.iloc[future_idx][price_col]
                        break
                    if future_ts > target_ts + tolerance:
                        break

                if future_price is not None and not pd.isna(future_price):
                    label, movement = apply_triple_barrier_label(
                        current_price, future_price, current_atr, self.config, horizon
                    )
                    labels[idx] = label
                    movements[idx] = movement
                    labeled_count += 1

            df[label_col] = labels
            df[movement_col] = movements

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞
            sell = (labels == 0).sum()
            hold = (labels == 1).sum()
            buy = (labels == 2).sum()
            hold_pct = 100 * hold / n if n > 0 else 0

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º HOLD% –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            hold_pct_by_horizon[horizon] = hold_pct

            print(f"      Labeled: {labeled_count:,}/{n:,} ({100*labeled_count/n:.1f}%)")
            print(f"      Distribution: SELL={sell:,} ({100*sell/n:.1f}%) | "
                  f"HOLD={hold:,} ({hold_pct:.1f}%) | BUY={buy:,} ({100*buy/n:.1f}%)")

            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            if horizon == 300:  # –û—Å–Ω–æ–≤–Ω–æ–π –≥–æ—Ä–∏–∑–æ–Ω—Ç –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self.stats['total_samples'] += n
                self.stats['labeled_samples'] += labeled_count
                # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º —Å–∏–º–≤–æ–ª–∞–º (–∞ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º!)
                self.stats['label_distribution']['SELL'] = self.stats['label_distribution'].get('SELL', 0) + sell
                self.stats['label_distribution']['HOLD'] = self.stats['label_distribution'].get('HOLD', 0) + hold
                self.stats['label_distribution']['BUY'] = self.stats['label_distribution'].get('BUY', 0) + buy

        return df, hold_pct_by_horizon

    def _cleanup_old_files(self, df: pd.DataFrame):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ parquet —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é –Ω–æ–≤—ã—Ö."""
        print("\nüóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤...")

        if 'timestamp' not in df.columns:
            return

        dates = pd.to_datetime(df['timestamp'], unit='ms').dt.strftime('%Y-%m-%d').unique()

        feature_store_dir = PROJECT_ROOT / "data" / "feature_store" / "offline" / self.feature_store_group
        deleted = 0

        for date_str in dates:
            partition_dir = feature_store_dir / f"date={date_str}"
            if partition_dir.exists():
                for f in partition_dir.glob("*.parquet"):
                    try:
                        f.unlink()
                        deleted += 1
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {f}: {e}")

        print(f"   ‚úì –£–¥–∞–ª–µ–Ω–æ {deleted} —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤")

    def _print_summary(self):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
        print("\n" + "=" * 80)
        print("üìä –ò–¢–û–ì–ò PREPROCESSING V2")
        print("=" * 80)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–∞—Ö
        skipped = self.stats.get('skipped_symbols', [])
        if skipped:
            print(f"\nüö´ –ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤ (HOLD > {self.config.max_hold_pct}%): {len(skipped)}")

        print(f"\n‚úì –í—Å–µ–≥–æ —Å–µ–º–ø–ª–æ–≤ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏): {self.stats['total_samples']:,}")
        print(f"‚úì –†–∞–∑–º–µ—á–µ–Ω–æ: {self.stats['labeled_samples']:,}")

        dist = self.stats.get('label_distribution', {})
        if dist:
            total = sum(dist.values())
            print(f"\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (–≥–æ—Ä–∏–∑–æ–Ω—Ç 300s):")
            for cls, count in dist.items():
                pct = 100 * count / total if total > 0 else 0
                bar = "‚ñà" * int(pct / 2)
                print(f"   {cls:4}: {bar} {count:,} ({pct:.1f}%)")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ mode collapse —Ä–∏—Å–∫
            hold_pct = 100 * dist.get('HOLD', 0) / total if total > 0 else 0
            if hold_pct > 60:
                print(f"\n‚ö†Ô∏è WARNING: HOLD class = {hold_pct:.1f}%")
                print("   –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ --fixed-pct –∏–ª–∏ –≤–∫–ª—é—á–µ–Ω–∏–µ --no-scaling")
            elif hold_pct > 40:
                print(f"\n‚úì HOLD class = {hold_pct:.1f}% - –ø—Ä–∏–µ–º–ª–µ–º–æ")
            else:
                print(f"\n‚úì HOLD class = {hold_pct:.1f}% - –æ—Ç–ª–∏—á–Ω–æ!")

        print("\n" + "=" * 80)
        print("‚úÖ Preprocessing –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print("=" * 80)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Preprocessing V2 —Å Triple Barrier Labeling"
    )
    parser.add_argument(
        '--feature-group',
        default='training_features',
        help='Feature group –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏'
    )
    parser.add_argument(
        '--start-date',
        default=None,
        help='–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD)'
    )
    parser.add_argument(
        '--end-date',
        default=None,
        help='–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD)'
    )
    parser.add_argument(
        '--tp-mult',
        type=float,
        default=2.0,
        help='Take Profit –º–Ω–æ–∂–∏—Ç–µ–ª—å ATR (default: 2.0)'
    )
    parser.add_argument(
        '--sl-mult',
        type=float,
        default=2.0,
        help='Stop Loss –º–Ω–æ–∂–∏—Ç–µ–ª—å ATR (default: 2.0)'
    )
    parser.add_argument(
        '--min-movement',
        type=float,
        default=0.05,
        help='–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –≤ %% (default: 0.05)'
    )
    parser.add_argument(
        '--fixed-pct',
        type=float,
        default=None,
        help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π %% –ø–æ—Ä–æ–≥ –¥–ª—è –í–°–ï–• —Å–∏–º–≤–æ–ª–æ–≤ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç ATR). '
             '–ù–∞–ø—Ä–∏–º–µ—Ä: --fixed-pct 0.1 = 0.1%% –ø–æ—Ä–æ–≥ (–±–∞–∑–æ–≤—ã–π –¥–ª—è 60s)'
    )
    parser.add_argument(
        '--no-scaling',
        action='store_true',
        help='–û—Ç–∫–ª—é—á–∏—Ç—å ‚àöT scaling –ø–æ—Ä–æ–≥–æ–≤ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º. '
             '–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ—Ä–æ–≥ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è: 180s=√ó‚àö3, 300s=√ó‚àö5'
    )
    parser.add_argument(
        '--max-hold',
        type=float,
        default=85.0,
        help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π %% HOLD –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–∞ (default: 85). '
             '–°–∏–º–≤–æ–ª—ã —Å HOLD > max-hold –≤–æ –í–°–ï–• –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞—Ö –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã'
    )

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    use_fixed = args.fixed_pct is not None
    fixed_threshold = args.fixed_pct if use_fixed else 0.15

    config = LabelingConfig(
        horizons=[60, 180, 300],  # 1, 3, 5 –º–∏–Ω—É—Ç
        tp_multiplier=args.tp_mult,
        sl_multiplier=args.sl_mult,
        min_movement_pct=args.min_movement,
        use_fixed_pct=use_fixed,
        fixed_threshold_pct=fixed_threshold,
        use_horizon_scaling=not args.no_scaling,
        max_hold_pct=args.max_hold
    )

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = TripleBarrierPreprocessor(
        config=config,
        feature_store_group=args.feature_group,
        start_date=args.start_date,
        end_date=args.end_date
    )

    # –ó–∞–ø—É—Å–∫
    processor.process_all_data()


if __name__ == "__main__":
    main()
